
> kc-mvp-server@2.5.3 lint
> eslint ./src --ext .ts --format json

[{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/app.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/auth.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/firebase-admin.service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/jwt-auth.guard.spec.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/jwt-auth.guard.ts","messages":[],"suppressedMessages":[{"ruleId":"@typescript-eslint/no-namespace","severity":2,"message":"ES2015 module syntax is preferred over namespaces.","line":24,"column":3,"nodeType":"TSModuleDeclaration","messageId":"moduleSyntaxIsPreferred","endLine":28,"endColumn":4,"suppressions":[{"kind":"directive","justification":""}]}],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/jwt.service.spec.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":25,"column":48,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":25,"endColumn":51,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[744,747],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[744,747],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Unit tests for JwtService — SEC-001.1 (HMAC-SHA256 signing)\n * Tests: sign, verify, reject tampered tokens, reject expired tokens\n */\nimport { createHmac } from \"crypto\";\n\n// Mock RedisCacheService\nconst mockRedisCache = {\n  get: jest.fn().mockResolvedValue(null),\n  set: jest.fn().mockResolvedValue(undefined),\n  setWithExpiry: jest.fn().mockResolvedValue(undefined),\n  delete: jest.fn().mockResolvedValue(undefined),\n};\n\n// Set JWT_SECRET before importing the service\nprocess.env.JWT_SECRET = \"test-secret-key-for-unit-tests-32chars!\";\n\nimport { JwtService } from \"./jwt.service\";\n\ndescribe(\"JwtService\", () => {\n  let service: JwtService;\n\n  beforeEach(() => {\n    jest.clearAllMocks();\n    service = new JwtService(mockRedisCache as any);\n  });\n\n  describe(\"Token Signing (SEC-001.1)\", () => {\n    it(\"should create a valid JWT with 3 parts\", async () => {\n      const result = await service.createTokenPair({\n        id: \"test-user-id\",\n        email: \"test@example.com\",\n        roles: [\"user\"],\n      });\n\n      expect(result).toHaveProperty(\"accessToken\");\n      expect(result).toHaveProperty(\"refreshToken\");\n\n      // JWT should have 3 parts: header.payload.signature\n      const parts = result.accessToken.split(\".\");\n      expect(parts).toHaveLength(3);\n    });\n\n    it(\"should use HMAC-SHA256 (not plain SHA-256)\", async () => {\n      const result = await service.createTokenPair({\n        id: \"test-user-id\",\n        email: \"test@example.com\",\n        roles: [\"user\"],\n      });\n\n      const [header, payload, signature] = result.accessToken.split(\".\");\n\n      // Verify the signature uses HMAC-SHA256\n      const expectedSignature = createHmac(\"sha256\", process.env.JWT_SECRET!)\n        .update(`${header}.${payload}`)\n        .digest(\"base64url\");\n\n      expect(signature).toBe(expectedSignature);\n    });\n\n    it(\"should include correct claims in the payload\", async () => {\n      const result = await service.createTokenPair({\n        id: \"user-uuid-123\",\n        email: \"user@karma.com\",\n        roles: [\"user\", \"admin\"],\n      });\n\n      const payloadBase64 = result.accessToken.split(\".\")[1];\n      const payload = JSON.parse(\n        Buffer.from(payloadBase64, \"base64url\").toString(),\n      );\n\n      expect(payload.userId).toBe(\"user-uuid-123\");\n      expect(payload.email).toBe(\"user@karma.com\");\n      expect(payload.roles).toEqual([\"user\", \"admin\"]);\n      expect(payload.type).toBe(\"access\");\n      expect(payload).toHaveProperty(\"iat\");\n      expect(payload).toHaveProperty(\"exp\");\n    });\n\n    it(\"should set different expiry for access vs refresh tokens\", async () => {\n      const result = await service.createTokenPair({\n        id: \"user-id\",\n        email: \"user@test.com\",\n        roles: [\"user\"],\n      });\n\n      const accessPayload = JSON.parse(\n        Buffer.from(result.accessToken.split(\".\")[1], \"base64url\").toString(),\n      );\n      const refreshPayload = JSON.parse(\n        Buffer.from(result.refreshToken.split(\".\")[1], \"base64url\").toString(),\n      );\n\n      // Refresh token should expire later than access token\n      expect(refreshPayload.exp).toBeGreaterThan(accessPayload.exp);\n    });\n  });\n\n  describe(\"Token Verification (SEC-001.1)\", () => {\n    it(\"should verify a valid access token\", async () => {\n      const tokens = await service.createTokenPair({\n        id: \"verify-user\",\n        email: \"verify@test.com\",\n        roles: [\"user\"],\n      });\n\n      const payload = await service.verifyToken(tokens.accessToken);\n      expect(payload.userId).toBe(\"verify-user\");\n      expect(payload.email).toBe(\"verify@test.com\");\n      expect(payload.type).toBe(\"access\");\n    });\n\n    it(\"should reject a tampered token\", async () => {\n      const tokens = await service.createTokenPair({\n        id: \"user-original\",\n        email: \"original@test.com\",\n        roles: [\"user\"],\n      });\n\n      // Tamper with the payload (change userId)\n      const parts = tokens.accessToken.split(\".\");\n      const payload = JSON.parse(Buffer.from(parts[1], \"base64url\").toString());\n      payload.userId = \"attacker-user-id\";\n      parts[1] = Buffer.from(JSON.stringify(payload)).toString(\"base64url\");\n      const tamperedToken = parts.join(\".\");\n\n      await expect(service.verifyToken(tamperedToken)).rejects.toThrow();\n    });\n\n    it(\"should reject a token with invalid format\", async () => {\n      await expect(service.verifyToken(\"not-a-valid-token\")).rejects.toThrow();\n      await expect(service.verifyToken(\"\")).rejects.toThrow();\n      await expect(service.verifyToken(\"a.b\")).rejects.toThrow();\n    });\n\n    it(\"should reject an expired token\", async () => {\n      // Create a token that's already expired\n      const header = { alg: \"HS256\", typ: \"JWT\" };\n      const payload = {\n        userId: \"expired-user\",\n        email: \"expired@test.com\",\n        sessionId: \"session-expired\",\n        roles: [\"user\"],\n        type: \"access\",\n        iat: Math.floor(Date.now() / 1000) - 7200,\n        exp: Math.floor(Date.now() / 1000) - 3600, // expired 1 hour ago\n      };\n\n      const encodedHeader = Buffer.from(JSON.stringify(header)).toString(\n        \"base64url\",\n      );\n      const encodedPayload = Buffer.from(JSON.stringify(payload)).toString(\n        \"base64url\",\n      );\n      const signature = createHmac(\"sha256\", process.env.JWT_SECRET!)\n        .update(`${encodedHeader}.${encodedPayload}`)\n        .digest(\"base64url\");\n      const expiredToken = `${encodedHeader}.${encodedPayload}.${signature}`;\n\n      await expect(service.verifyToken(expiredToken)).rejects.toThrow();\n    });\n  });\n});\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/jwt.service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/rate-limit.service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/auth/session.service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/admin-files.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":101,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":101,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2873,2876],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2873,2876],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":144,"column":64,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":144,"endColumn":67,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4184,4187],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4184,4187],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Query,\n  Inject,\n  UseGuards,\n  Request,\n  Logger,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { JwtAuthGuard, AdminAuthGuard } from \"../auth/jwt-auth.guard\";\n\ninterface CreateFileDto {\n  name: string;\n  url: string;\n  mime_type?: string;\n  size?: number;\n  folder_path?: string; // e.g. \"Finance\", \"HR\" or \"/\"\n  uploaded_by?: string;\n}\n\n@Controller(\"/api/admin-files\")\nexport class AdminFilesController {\n  private readonly logger = new Logger(AdminFilesController.name);\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  private async ensureTable() {\n    try {\n      const checkTable = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'general_files'\n        );\n      `);\n\n      if (!checkTable.rows[0].exists) {\n        this.logger.log(\"Creating general_files table...\");\n        await this.pool.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"');\n\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS general_files (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            name VARCHAR(255) NOT NULL,\n            url TEXT NOT NULL,\n            mime_type VARCHAR(100),\n            size BIGINT,\n            folder_path VARCHAR(255) DEFAULT '/',\n            uploaded_by UUID,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          )\n        `);\n\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_general_files_folder ON general_files (folder_path)\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_general_files_created_at ON general_files (created_at DESC)\",\n        );\n\n        this.logger.log(\"general_files table created successfully\");\n      }\n    } catch (error) {\n      this.logger.error(\"Error ensuring general_files table:\", error);\n    }\n  }\n\n  @Get()\n  @UseGuards(JwtAuthGuard)\n  async getFiles(\n    @Query(\"folder\") folder?: string,\n    @Query(\"search\") search?: string,\n  ) {\n    await this.ensureTable();\n\n    // Normalize folder path to ensure it starts/ends correctly if needed.\n    // For now, exact match or strict hierarchy.\n    const targetFolder = folder || \"/\";\n\n    const cacheKey = `admin_files_list_${targetFolder}_${search || \"\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    try {\n      let query = `SELECT * FROM general_files WHERE 1=1`;\n      const params: any[] = [];\n      let paramIndex = 1;\n\n      // Filter by folder if not searching globally\n      if (!search) {\n        query += ` AND folder_path = $${paramIndex}`;\n        params.push(targetFolder);\n        paramIndex++;\n      } else {\n        query += ` AND name ILIKE $${paramIndex}`;\n        params.push(`%${search}%`);\n        paramIndex++;\n      }\n\n      query += ` ORDER BY created_at DESC`;\n\n      const { rows } = await this.pool.query(query, params);\n      await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error fetching admin files:\", error);\n      return { success: false, error: \"Failed to fetch files\", data: [] };\n    }\n  }\n\n  @Get(\"folders\")\n  @UseGuards(JwtAuthGuard)\n  async getFolders() {\n    await this.ensureTable();\n    try {\n      // Get distinct folders\n      const { rows } = await this.pool.query(`\n        SELECT DISTINCT folder_path FROM general_files ORDER BY folder_path\n      `);\n      return { success: true, data: rows.map((r) => r.folder_path) };\n    } catch (_error) {\n      return { success: false, error: \"Failed to fetch folders\", data: [] };\n    }\n  }\n\n  @Post()\n  @UseGuards(JwtAuthGuard, AdminAuthGuard)\n  async uploadFile(@Body() dto: CreateFileDto, @Request() req: any) {\n    await this.ensureTable();\n\n    try {\n      if (!dto.name || !dto.url) {\n        return { success: false, error: \"Name and URL are required\" };\n      }\n\n      // Validate file size if provided (max 10MB)\n      const MAX_FILE_SIZE = 10 * 1024 * 1024; // 10MB\n      if (dto.size && dto.size > MAX_FILE_SIZE) {\n        return {\n          success: false,\n          error: `File size exceeds maximum allowed size of ${MAX_FILE_SIZE / (1024 * 1024)}MB`,\n        };\n      }\n\n      let userId = req.user?.userId;\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!userId || !uuidRegex.test(userId)) {\n        // Try to resolve from body if available and valid\n        if (dto.uploaded_by && uuidRegex.test(dto.uploaded_by)) {\n          userId = dto.uploaded_by;\n        } else {\n          this.logger.warn(\n            `uploadFile: Invalid or missing userId, setting to NULL. Received: ${userId}`,\n          );\n          userId = null;\n        }\n      }\n\n      const { rows } = await this.pool.query(\n        `INSERT INTO general_files (name, url, mime_type, size, folder_path, uploaded_by)\n         VALUES ($1, $2, $3, $4, $5, $6)\n         RETURNING *`,\n        [\n          dto.name,\n          dto.url,\n          dto.mime_type || null,\n          dto.size || 0,\n          dto.folder_path || \"/\",\n          userId,\n        ],\n      );\n\n      await this.redisCache.invalidatePattern(\"admin_files_list_*\");\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error saving file metadata:\", error);\n      return { success: false, error: \"Failed to save file metadata\" };\n    }\n  }\n\n  @Delete(\":id\")\n  @UseGuards(JwtAuthGuard, AdminAuthGuard)\n  async deleteFile(@Param(\"id\") id: string) {\n    await this.ensureTable();\n\n    try {\n      // In a real implementation, we would also delete the file from storage (S3/Firebase).\n      // Here we only delete the metadata record.\n      const { rows } = await this.pool.query(\n        `DELETE FROM general_files WHERE id = $1 RETURNING id`,\n        [id],\n      );\n      if (rows.length === 0) return { success: false, error: \"File not found\" };\n\n      await this.redisCache.invalidatePattern(\"admin_files_list_*\");\n      return { success: true, message: \"File deleted successfully\" };\n    } catch (error) {\n      this.logger.error(\"Error deleting file:\", error);\n      return { success: false, error: \"Failed to delete file\" };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/admin-tables.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":36,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":36,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[999,1002],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[999,1002],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":64,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":64,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1748,1751],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1748,1751],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":70,"column":66,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":70,"endColumn":69,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1919,1922],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1919,1922],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":87,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":87,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2457,2460],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2457,2460],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":96,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":96,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2670,2673],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2670,2673],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":106,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":106,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2965,2968],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2965,2968],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":116,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":116,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3270,3273],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3270,3273],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":141,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":141,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3888,3891],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3888,3891],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":150,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":150,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4110,4113],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4110,4113],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":164,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":164,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4530,4533],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4530,4533],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":174,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":174,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4792,4795],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4792,4795],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":193,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":193,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5260,5263],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5260,5263],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":203,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":203,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5623,5626],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5623,5626],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":13,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: CRUD for Admin Dynamic Tables\n// - Routes: /api/admin/tables (GET, POST), /api/admin/tables/:id (GET, PUT, DELETE), /api/admin/tables/:id/rows (GET, POST), /api/admin/tables/:id/rows/:rowId (PUT, DELETE)\n// - Storage: PostgreSQL tables admin_tables, admin_table_columns, admin_table_rows\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Put,\n  Query,\n  UseGuards,\n  Request,\n} from \"@nestjs/common\";\nimport {\n  AdminTablesService,\n  CreateTableDto,\n  UpdateTableDto,\n  CreateRowDto,\n  UpdateRowDto,\n} from \"../services/admin-tables.service\";\nimport { AdminAuthGuard } from \"../auth/jwt-auth.guard\";\n\n@Controller(\"/api/admin/tables\")\n@UseGuards(AdminAuthGuard)\nexport class AdminTablesController {\n  constructor(private readonly adminTablesService: AdminTablesService) {}\n\n  @Get()\n  async getAllTables() {\n    try {\n      const tables = await this.adminTablesService.getAllTables();\n      return { success: true, data: tables };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה בטעינת טבלאות\" };\n    }\n  }\n\n  @Get(\":id\")\n  async getTableById(\n    @Param(\"id\") id: string,\n    @Query(\"includeRows\") includeRows?: string,\n    @Query(\"page\") page?: string,\n    @Query(\"limit\") limit?: string,\n  ) {\n    try {\n      const includeRowsBool = includeRows === \"true\";\n      const pagination =\n        includeRowsBool && page && limit\n          ? {\n              page: parseInt(page) || 1,\n              limit: parseInt(limit) || 50,\n            }\n          : undefined;\n\n      const table = await this.adminTablesService.getTableById(\n        id,\n        includeRowsBool,\n        pagination,\n      );\n      return { success: true, data: table };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה בטעינת טבלה\" };\n    }\n  }\n\n  @Post()\n  async createTable(@Body() dto: CreateTableDto, @Request() req: any) {\n    try {\n      const userId = req.user?.userId;\n      if (!userId) {\n        return { success: false, error: \"משתמש לא מזוהה\" };\n      }\n\n      if (!dto.name || !dto.name.trim()) {\n        return { success: false, error: \"שם הטבלה הוא חובה\" };\n      }\n\n      if (!dto.columns || dto.columns.length === 0) {\n        return { success: false, error: \"חייב להגדיר לפחות עמודה אחת\" };\n      }\n\n      const table = await this.adminTablesService.createTable(dto, userId);\n      return { success: true, data: table };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה ביצירת טבלה\" };\n    }\n  }\n\n  @Put(\":id\")\n  async updateTable(\n    @Param(\"id\") id: string,\n    @Body() dto: UpdateTableDto,\n    @Request() req: any,\n  ) {\n    try {\n      const userId = req.user?.userId;\n      if (!userId) {\n        return { success: false, error: \"משתמש לא מזוהה\" };\n      }\n\n      const table = await this.adminTablesService.updateTable(id, dto, userId);\n      return { success: true, data: table };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה בעדכון טבלה\" };\n    }\n  }\n\n  @Delete(\":id\")\n  async deleteTable(@Param(\"id\") id: string) {\n    try {\n      await this.adminTablesService.deleteTable(id);\n      return { success: true, message: \"טבלה נמחקה בהצלחה\" };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה במחיקת טבלה\" };\n    }\n  }\n\n  @Get(\":id/rows\")\n  async getTableRows(\n    @Param(\"id\") tableId: string,\n    @Query(\"page\") page?: string,\n    @Query(\"limit\") limit?: string,\n  ) {\n    try {\n      const pagination =\n        page && limit\n          ? {\n              page: parseInt(page) || 1,\n              limit: parseInt(limit) || 50,\n            }\n          : undefined;\n\n      const result = await this.adminTablesService.getTableRows(\n        tableId,\n        pagination,\n      );\n      return { success: true, data: result };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה בטעינת רשומות\" };\n    }\n  }\n\n  @Post(\":id/rows\")\n  async createRow(\n    @Param(\"id\") tableId: string,\n    @Body() dto: CreateRowDto,\n    @Request() req: any,\n  ) {\n    try {\n      const userId = req.user?.userId;\n      if (!userId) {\n        return { success: false, error: \"משתמש לא מזוהה\" };\n      }\n\n      if (!dto.data || typeof dto.data !== \"object\") {\n        return { success: false, error: \"נתונים לא תקינים\" };\n      }\n\n      const row = await this.adminTablesService.createRow(tableId, dto, userId);\n      return { success: true, data: row };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה ביצירת רשומה\" };\n    }\n  }\n\n  @Put(\":id/rows/:rowId\")\n  async updateRow(\n    @Param(\"id\") tableId: string,\n    @Param(\"rowId\") rowId: string,\n    @Body() dto: UpdateRowDto,\n    @Request() req: any,\n  ) {\n    try {\n      const userId = req.user?.userId;\n      if (!userId) {\n        return { success: false, error: \"משתמש לא מזוהה\" };\n      }\n\n      if (!dto.data || typeof dto.data !== \"object\") {\n        return { success: false, error: \"נתונים לא תקינים\" };\n      }\n\n      const row = await this.adminTablesService.updateRow(\n        tableId,\n        rowId,\n        dto,\n        userId,\n      );\n      return { success: true, data: row };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה בעדכון רשומה\" };\n    }\n  }\n\n  @Delete(\":id/rows/:rowId\")\n  async deleteRow(@Param(\"id\") tableId: string, @Param(\"rowId\") rowId: string) {\n    try {\n      await this.adminTablesService.deleteRow(tableId, rowId);\n      return { success: true, message: \"רשומה נמחקה בהצלחה\" };\n    } catch (error: any) {\n      return { success: false, error: error.message || \"שגיאה במחיקת רשומה\" };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/auth.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":168,"column":55,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":168,"endColumn":58,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5225,5228],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5225,5228],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":250,"column":33,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":250,"endColumn":36,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8357,8360],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8357,8360],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":284,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":284,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9580,9583],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9580,9583],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":402,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":402,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13823,13826],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13823,13826],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":490,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":490,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16934,16937],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16934,16937],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":535,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":535,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[18357,18360],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[18357,18360],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":650,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":650,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[22894,22897],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[22894,22897],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":660,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":660,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[23321,23324],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[23321,23324],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":676,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":676,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[23894,23897],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[23894,23897],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":696,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":696,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[24589,24592],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[24589,24592],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":738,"column":22,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":738,"endColumn":25,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[26116,26119],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[26116,26119],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":771,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":771,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[27587,27590],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[27587,27590],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":852,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":852,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[30623,30626],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[30623,30626],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":906,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":906,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[32271,32274],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[32271,32274],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":14,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Authentication endpoints for email/password and Google OAuth with enhanced security.\n// - Reached from: Routes under '/auth'.\n// - Provides: check-email, register, login, google auth endpoints with secure validation.\n// - External deps: argon2 for password hashing, google-auth-library for OAuth verification.\n// - Security: Rate limiting, input validation DTOs, secure logging (no sensitive data).\n//\n// SECURITY IMPROVEMENTS:\n// ✅ Input validation with class-validator DTOs\n// ✅ Password hashing with Argon2 (industry standard)\n// ✅ Secure logging - no tokens or passwords in logs\n// ✅ Proper error handling with appropriate HTTP status codes\n// ✅ Email normalization and validation\n//\n// TODO: Implement JWT token-based authentication instead of returning user objects\n// TODO: Add refresh token mechanism for better security\n// TODO: Add password strength requirements\n// TODO: Add email verification flow\n// TODO: Add 2FA (Two-Factor Authentication) support\n// TODO: Add account lockout after multiple failed attempts\n// TODO: Add audit logging for security events\n// TODO: Implement proper session management\n// TODO: Add rate limiting per user (not just global)\n// TODO: Split into separate services (AuthService, UserService, GoogleAuthService)\nimport {\n  Body,\n  Controller,\n  Get,\n  Post,\n  Query,\n  Logger,\n  BadRequestException,\n  InternalServerErrorException,\n  UseGuards,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport * as argon2 from \"argon2\";\nimport { OAuth2Client } from \"google-auth-library\";\nimport { PG_POOL } from \"../database/database.module\";\nimport {\n  IsString,\n  IsEmail,\n  IsOptional,\n  Length,\n  validate,\n} from \"class-validator\";\nimport { Transform } from \"class-transformer\";\nimport { Throttle, ThrottlerGuard } from \"@nestjs/throttler\";\nimport { JwtService } from \"../auth/jwt.service\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n// DTO for Google Auth with proper validation\n// Ensures tokens are within expected length ranges to prevent malformed data\nclass GoogleAuthDto {\n  @IsString()\n  @IsOptional()\n  @Length(10, 5000, { message: \"ID token length is invalid\" })\n  idToken?: string;\n\n  @IsString()\n  @IsOptional()\n  @Length(10, 2000, { message: \"Access token length is invalid\" })\n  accessToken?: string;\n\n  @IsString()\n  @IsOptional()\n  @Length(1, 200, { message: \"Firebase UID length is invalid\" })\n  firebaseUid?: string; // Firebase UID from Firebase Auth (different from Google ID)\n}\n\n// DTO for token refresh\nclass RefreshTokenDto {\n  @IsString()\n  @Length(10, 2000, { message: \"Refresh token length is invalid\" })\n  refreshToken!: string;\n}\n\n// DTO for login with validation\n// Automatically transforms email to lowercase for consistent storage\nclass LoginDto {\n  @IsEmail({}, { message: \"Invalid email format\" })\n  @Transform(({ value }) => value?.toLowerCase()?.trim())\n  email!: string;\n\n  @IsString()\n  @Length(6, 100, { message: \"Password must be between 6 and 100 characters\" })\n  password!: string;\n}\n\n// DTO for registration - extends LoginDto with optional name field\nclass RegisterDto extends LoginDto {\n  @IsString()\n  @IsOptional()\n  @Length(1, 100, { message: \"Name must be between 1 and 100 characters\" })\n  name?: string;\n}\n\n/**\n * Public user type - excludes sensitive data like password hash\n * This is what gets returned to clients\n */\ntype PublicUser = {\n  id: string;\n  email: string;\n  name?: string;\n  avatar?: string;\n  roles?: string[];\n  settings?: Record<string, unknown>;\n  createdAt?: string;\n  lastActive?: string;\n};\n\n/**\n * Authentication Controller\n *\n * Handles user authentication via email/password and Google OAuth.\n * All sensitive operations are rate-limited to prevent abuse.\n *\n * Security features:\n * - Rate limiting on all endpoints\n * - Input validation with DTOs\n * - Password hashing with Argon2\n * - Secure logging (no sensitive data in logs)\n * - Email normalization\n */\n@Controller(\"auth\")\n@UseGuards(ThrottlerGuard) // Apply rate limiting to all auth endpoints\nexport class AuthController {\n  private readonly logger = new Logger(AuthController.name);\n  private googleClient: OAuth2Client;\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly jwtService: JwtService,\n    private readonly redisCache: RedisCacheService,\n  ) {\n    const clientId =\n      process.env.GOOGLE_CLIENT_ID ||\n      process.env.EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID;\n\n    if (!clientId) {\n      this.logger.error(\n        \"❌ Google Client ID not found in environment variables\",\n      );\n      throw new Error(\"Google authentication is not properly configured\");\n    }\n\n    this.googleClient = new OAuth2Client(clientId);\n    this.logger.log(\"✅ Google OAuth client initialized successfully\");\n  }\n\n  private async tableExists(tableName: string): Promise<boolean> {\n    try {\n      const { rows } = await this.pool.query(\n        `SELECT EXISTS (\n           SELECT 1 FROM information_schema.tables \n           WHERE table_name = $1\n         ) AS exists`,\n        [tableName],\n      );\n      return !!rows?.[0]?.exists;\n    } catch {\n      return false;\n    }\n  }\n\n  private async upsertUserProfileFromLegacy(userData: any): Promise<void> {\n    // Best-effort: keep relational profile in sync when schema exists\n    if (!userData?.email) return;\n    const hasProfiles = await this.tableExists(\"user_profiles\");\n    if (!hasProfiles) return;\n\n    const email = this.normalizeEmail(userData.email);\n    const name = userData.name || email.split(\"@\")[0];\n    const avatar = userData.avatar || null;\n    const now = new Date().toISOString();\n\n    try {\n      const { rows } = await this.pool.query(\n        `SELECT id FROM user_profiles WHERE LOWER(email) = LOWER($1) LIMIT 1`,\n        [email],\n      );\n\n      if (rows.length > 0) {\n        await this.pool.query(\n          `UPDATE user_profiles\n             SET name = COALESCE($1, name),\n                 avatar_url = COALESCE($2, avatar_url),\n                 last_active = NOW(),\n                 email_verified = COALESCE($3, email_verified),\n                 updated_at = NOW()\n           WHERE id = $4`,\n          [name, avatar, !!userData.emailVerified, rows[0].id],\n        );\n      } else {\n        await this.pool.query(\n          `INSERT INTO user_profiles (\n             email, name, avatar_url, bio, karma_points, join_date, is_active,\n             last_active, city, country, interests, roles, posts_count, followers_count,\n             following_count, total_donations_amount, total_volunteer_hours, email_verified, settings\n           ) VALUES (\n             $1,   $2,   $3,         $4,  $5,          $6,       $7,\n             $8,          $9,  $10,    $11,      $12,   $13,         $14,\n             $15,              $16,                    $17,             $18,          $19\n           )`,\n          [\n            email,\n            name,\n            avatar,\n            userData.bio || \"משתמש חדש בקארמה קומיוניטי\",\n            Number(userData.karmaPoints || 0),\n            userData.joinDate ? new Date(userData.joinDate) : new Date(),\n            userData.isActive !== false,\n            now,\n            (userData.location && userData.location.city) || null,\n            (userData.location && userData.location.country) || \"Israel\",\n            Array.isArray(userData.interests) ? userData.interests : [],\n            Array.isArray(userData.roles) ? userData.roles : [\"user\"],\n            Number(userData.postsCount || 0),\n            Number(userData.followersCount || 0),\n            Number(userData.followingCount || 0),\n            Number(userData.total_donations_amount || 0),\n            Number(userData.total_volunteer_hours || 0),\n            !!userData.emailVerified,\n            userData.settings || {\n              language: \"he\",\n              dark_mode: false,\n              notifications_enabled: true,\n              privacy: \"public\",\n            },\n          ],\n        );\n      }\n    } catch (err) {\n      // eslint-disable-next-line no-console\n      this.logger.warn(\n        \"AuthController - upsertUserProfileFromLegacy skipped (schema present but insert/update failed):\",\n        err,\n      );\n    }\n  }\n\n  private normalizeEmail(email: string): string {\n    return String(email || \"\")\n      .trim()\n      .toLowerCase();\n  }\n\n  private toPublicUser(rowData: any): PublicUser {\n    const data = rowData || {};\n    const { password_hash: _pw, ...rest } = data;\n    return rest as PublicUser;\n  }\n\n  /**\n   * Check if an email is already registered in the system\n   *\n   * Security: Rate limited to prevent email enumeration attacks\n   *\n   * @param email - Email address to check\n   * @returns Object with 'exists' boolean\n   */\n  @Get(\"check-email\")\n  @Throttle({ default: { limit: 10, ttl: 60000 } }) // 10 requests per minute\n  async checkEmail(@Query(\"email\") email?: string) {\n    try {\n      const normalized = this.normalizeEmail(email || \"\");\n      if (!normalized || !this.isValidEmail(normalized)) {\n        throw new BadRequestException(\"Invalid email format\");\n      }\n\n      // SECURITY: Log only partial email (first 3 chars + domain) to prevent email leakage\n      const emailParts = normalized.split(\"@\");\n      const safeEmail = emailParts[0].substring(0, 3) + \"***@\" + emailParts[1];\n      this.logger.log(`Email availability check for: ${safeEmail}`);\n\n      const { rows } = await this.pool.query(\n        `SELECT 1 FROM user_profiles WHERE LOWER(email) = $1 LIMIT 1`,\n        [normalized],\n      );\n\n      return { exists: rows.length > 0 };\n    } catch (error: any) {\n      // SECURITY: Don't leak email in error logs\n      this.logger.error(\"Email check failed\", { error: error.message });\n      if (error instanceof BadRequestException) {\n        throw error;\n      }\n      throw new InternalServerErrorException(\n        \"Failed to check email availability\",\n      );\n    }\n  }\n\n  /**\n   * Validate email format according to RFC 5321\n   *\n   * @param email - Email to validate\n   * @returns true if valid, false otherwise\n   */\n  private isValidEmail(email: string): boolean {\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return emailRegex.test(email) && email.length <= 320; // RFC 5321 limit\n  }\n\n  /**\n   * Register a new user with email and password\n   *\n   * Security:\n   * - Rate limited to prevent spam registrations\n   * - Password hashed with Argon2 (industry standard)\n   * - Input validation via DTOs\n   * - No sensitive data in logs\n   *\n   * @param registerDto - User registration data\n   * @returns Success status and public user data\n   */\n  @Post(\"register\")\n  @Throttle({ default: { limit: 5, ttl: 60000 } }) // 5 registrations per minute\n  async register(@Body() registerDto: RegisterDto) {\n    try {\n      // Validate input\n      const errors = await validate(registerDto);\n      if (errors.length > 0) {\n        throw new BadRequestException(\"Invalid input data\");\n      }\n\n      const normalized = this.normalizeEmail(registerDto.email);\n\n      // SECURITY: Log only partial email for privacy\n      const emailParts = normalized.split(\"@\");\n      const safeEmail = emailParts[0].substring(0, 3) + \"***@\" + emailParts[1];\n      this.logger.log(`Registration attempt for: ${safeEmail}`);\n\n      // Check if exists\n      const existRes = await this.pool.query(\n        `SELECT id FROM user_profiles WHERE LOWER(email) = $1 LIMIT 1`,\n        [normalized],\n      );\n      if (existRes.rows.length > 0) {\n        // SECURITY: Don't reveal if email exists to prevent enumeration\n        this.logger.warn(`Registration failed - email already registered`);\n        return { error: \"Email already registered\" };\n      }\n\n      // SECURITY: Hash password with Argon2 (memory-hard algorithm, resistant to GPU attacks)\n      const passwordHash = await argon2.hash(registerDto.password);\n      const nowIso = new Date().toISOString();\n\n      // Insert into user_profiles with UUID\n      const { rows: newUser } = await this.pool.query(\n        `INSERT INTO user_profiles (\n          email, name, phone, avatar_url, bio, password_hash, \n          karma_points, join_date, is_active, last_active, \n          city, country, interests, roles, email_verified, settings\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16)\n        RETURNING id, email, name, avatar_url, roles, settings, created_at, last_active`,\n        [\n          normalized,\n          registerDto.name || normalized.split(\"@\")[0],\n          \"+9720000000\",\n          \"https://i.pravatar.cc/150?img=1\",\n          \"משתמש חדש בקארמה קומיוניטי\",\n          passwordHash,\n          0, // karma_points\n          nowIso, // join_date\n          true, // is_active\n          nowIso, // last_active\n          \"ישראל\", // city\n          \"Israel\", // country\n          [], // interests (empty array)\n          [\"user\"], // roles\n          false, // email_verified\n          JSON.stringify({\n            language: \"he\",\n            darkMode: false,\n            notificationsEnabled: true,\n          }), // settings\n        ],\n      );\n\n      const userId = newUser[0].id;\n      const userData = {\n        id: userId,\n        email: normalized,\n        name: newUser[0].name,\n        avatar: newUser[0].avatar_url,\n        roles: newUser[0].roles,\n        settings: newUser[0].settings,\n        createdAt: newUser[0].created_at,\n        lastActive: newUser[0].last_active,\n      };\n\n      // Clear statistics cache when new user is registered\n      // This ensures totalUsers and other user-related stats are refreshed immediately\n      await this.redisCache.clearStatsCaches();\n\n      // SECURITY: Log success without exposing sensitive data\n      this.logger.log(`✅ User registered successfully (ID: ${userId})`);\n      return { ok: true, user: this.toPublicUser(userData) };\n    } catch (error: any) {\n      // SECURITY: Generic error message, log details separately\n      this.logger.error(\"Registration failed\", { error: error.message });\n      if (error instanceof BadRequestException) {\n        throw error;\n      }\n      throw new InternalServerErrorException(\"Registration failed\");\n    }\n  }\n\n  /**\n   * Login with email and password\n   *\n   * Security:\n   * - Rate limited to prevent brute force attacks\n   * - Password verification with Argon2\n   * - Generic error messages (don't reveal if email exists)\n   * - No sensitive data in logs\n   *\n   * @param loginDto - Login credentials\n   * @returns Success status and public user data\n   */\n  @Post(\"login\")\n  @Throttle({ default: { limit: 5, ttl: 60000 } }) // 5 login attempts per minute\n  async login(@Body() loginDto: LoginDto) {\n    try {\n      // Validate input\n      const errors = await validate(loginDto);\n      if (errors.length > 0) {\n        throw new BadRequestException(\"Invalid input data\");\n      }\n\n      const normalized = this.normalizeEmail(loginDto.email);\n\n      // SECURITY: Log only partial email\n      const emailParts = normalized.split(\"@\");\n      const safeEmail = emailParts[0].substring(0, 3) + \"***@\" + emailParts[1];\n      this.logger.log(`Login attempt for user: ${safeEmail}`);\n\n      const { rows } = await this.pool.query(\n        `SELECT id, email, name, avatar_url, password_hash, roles, settings, created_at, last_active\n         FROM user_profiles WHERE LOWER(email) = $1 LIMIT 1`,\n        [normalized],\n      );\n\n      if (rows.length === 0) {\n        // SECURITY: Generic error - don't reveal if email exists\n        this.logger.warn(`Login failed - invalid credentials`);\n        return { error: \"Invalid email or password\" };\n      }\n\n      const hash = rows[0].password_hash as string | undefined;\n\n      if (!hash) {\n        // SECURITY: Generic error message\n        this.logger.warn(`Login failed - no password hash for user`);\n        return { error: \"User cannot login with password\" };\n      }\n\n      // SECURITY: Verify password with Argon2 (constant-time comparison)\n      const valid = await argon2.verify(hash, loginDto.password);\n      if (!valid) {\n        // SECURITY: Generic error - don't reveal that email exists\n        this.logger.warn(`Login failed - invalid password`);\n        return { error: \"Invalid email or password\" };\n      }\n\n      // Update lastActive\n      await this.pool.query(\n        `UPDATE user_profiles SET last_active = NOW(), updated_at = NOW() WHERE id = $1`,\n        [rows[0].id],\n      );\n\n      // Build user data object\n      const userData = {\n        id: rows[0].id,\n        email: rows[0].email,\n        name: rows[0].name,\n        avatar: rows[0].avatar_url,\n        roles: rows[0].roles || [\"user\"],\n        settings: rows[0].settings || {},\n        createdAt: rows[0].created_at,\n        lastActive: new Date().toISOString(),\n      };\n\n      // SECURITY: Log success without exposing sensitive data\n      this.logger.log(`✅ Successful login for user ID: ${rows[0].id}`);\n      return { ok: true, user: this.toPublicUser(userData) };\n    } catch (error: any) {\n      // SECURITY: Generic error message\n      this.logger.error(\"Login error\", { error: error.message });\n      if (error instanceof BadRequestException) {\n        throw error;\n      }\n      throw new InternalServerErrorException(\"Login failed\");\n    }\n  }\n\n  /**\n   * Authenticate with Google OAuth\n   *\n   * Security:\n   * - Rate limited to prevent abuse\n   * - Server-side token verification (prevents token forgery)\n   * - Email verification required\n   * - No sensitive data in logs (no tokens logged)\n   *\n   * @param googleAuthDto - Google OAuth tokens\n   * @returns Success status and public user data\n   */\n  @Post(\"google\")\n  @Throttle({ default: { limit: 10, ttl: 60000 } }) // 10 Google auth attempts per minute\n  async googleAuth(@Body() googleAuthDto: GoogleAuthDto) {\n    try {\n      // Validate input\n      const errors = await validate(googleAuthDto);\n      if (errors.length > 0) {\n        throw new BadRequestException(\"Invalid token format\");\n      }\n\n      const { idToken, accessToken, firebaseUid } = googleAuthDto;\n\n      if (!idToken && !accessToken) {\n        throw new BadRequestException(\"Missing Google token\");\n      }\n\n      // SECURITY: Log auth attempt without exposing tokens\n      this.logger.log(\"Google authentication attempt\", {\n        hasIdToken: !!idToken,\n        hasAccessToken: !!accessToken,\n        timestamp: new Date().toISOString(),\n      });\n\n      let googleUser: any = null;\n\n      // Verify ID token if provided\n      if (idToken) {\n        try {\n          // SECURITY: Verify token with Google's servers (prevents forgery)\n          const ticket = await this.googleClient.verifyIdToken({\n            idToken,\n            audience:\n              process.env.GOOGLE_CLIENT_ID ||\n              process.env.EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID,\n          });\n          const payload = ticket.getPayload();\n\n          if (!payload || !payload.email) {\n            this.logger.warn(\"Invalid Google ID token payload\");\n            throw new BadRequestException(\"Invalid Google token\");\n          }\n\n          // SECURITY: Email must be verified by Google\n          if (!payload.email_verified) {\n            // SECURITY: Log only domain, not full email\n            const emailDomain = payload.email.split(\"@\")[1];\n            this.logger.warn(\n              `Google account email not verified (domain: ${emailDomain})`,\n            );\n            throw new BadRequestException(\n              \"Google account email must be verified\",\n            );\n          }\n\n          googleUser = {\n            id: payload.sub, // Google ID (sub claim)\n            googleId: payload.sub, // Store Google ID separately\n            email: payload.email,\n            name: payload.name || payload.given_name || \"Google User\",\n            avatar: payload.picture,\n            emailVerified: payload.email_verified,\n          };\n\n          // SECURITY: Log only domain, not full email\n          const emailDomain = payload.email.split(\"@\")[1];\n          this.logger.log(\n            `✅ Google ID token verified successfully (domain: ${emailDomain})`,\n          );\n        } catch (error) {\n          this.logger.warn(\n            `Google ID token verification failed: ${error instanceof Error ? error.message : String(error)}`,\n          );\n          // If we have an access token, we can try to use that instead\n          if (!accessToken) {\n            throw error;\n          }\n          this.logger.log(\"Falling back to access token verification...\");\n        }\n      }\n\n      // If no googleUser yet (either no idToken or verification failed), try access token\n      if (!googleUser && accessToken) {\n        const response = await fetch(\n          \"https://www.googleapis.com/oauth2/v3/userinfo\",\n          {\n            headers: { Authorization: `Bearer ${accessToken}` },\n          },\n        );\n\n        if (!response.ok) {\n          // If we already tried idToken and it failed, and now accessToken also failed\n          if (idToken) {\n            throw new BadRequestException(\n              \"Both ID token and Access token verification failed\",\n            );\n          }\n          return { error: \"Invalid Google access token\" };\n        }\n\n        const profile = await response.json();\n        googleUser = {\n          id: profile.sub, // Google ID (sub claim)\n          googleId: profile.sub, // Store Google ID separately\n          email: profile.email,\n          name: profile.name || profile.given_name || \"Google User\",\n          avatar: profile.picture,\n          emailVerified: true, // Assume verified since it came from Google\n        };\n\n        this.logger.log(\"✅ Google Access token verified successfully\");\n      }\n\n      if (!googleUser || !googleUser.email) {\n        this.logger.error(\"Failed to extract user info from Google response\");\n        throw new BadRequestException(\"Could not get user info from Google\");\n      }\n\n      const normalizedEmail = this.normalizeEmail(googleUser.email);\n      if (!this.isValidEmail(normalizedEmail)) {\n        // SECURITY: Log only domain\n        const emailDomain = normalizedEmail.split(\"@\")[1];\n        this.logger.error(`Invalid email from Google (domain: ${emailDomain})`);\n        throw new BadRequestException(\"Invalid email from Google\");\n      }\n\n      const nowIso = new Date().toISOString();\n\n      // SECURITY: Log only partial email\n      const emailParts = normalizedEmail.split(\"@\");\n      const safeEmail = emailParts[0].substring(0, 3) + \"***@\" + emailParts[1];\n      this.logger.log(`Processing Google auth for user: ${safeEmail}`);\n\n      // Extract Google ID and Firebase UID separately\n      // Firebase UID is the actual UID from Firebase Auth, which is different from Google ID\n      const googleIdToUse = googleUser.googleId || googleUser.id; // Google ID (sub claim)\n      const firebaseUidToUse = firebaseUid; // Only Firebase UID, not Google ID\n\n      // Check if user exists by email, firebase_uid, or google_id\n      let rows: any[];\n      try {\n        const result = await this.pool.query(\n          `SELECT id, email, name, avatar_url, firebase_uid, google_id, roles, settings, created_at, last_active\n           FROM user_profiles \n           WHERE LOWER(email) = $1 OR firebase_uid = $2 OR google_id = $3\n           LIMIT 1`,\n          [normalizedEmail, firebaseUidToUse, googleIdToUse],\n        );\n        rows = result.rows;\n      } catch (error: any) {\n        // If google_id column doesn't exist, try without it\n        if (error.message && error.message.includes(\"google_id\")) {\n          const result = await this.pool.query(\n            `SELECT id, email, name, avatar_url, firebase_uid, roles, settings, created_at, last_active\n             FROM user_profiles \n             WHERE LOWER(email) = $1 OR firebase_uid = $2\n             LIMIT 1`,\n            [normalizedEmail, firebaseUidToUse],\n          );\n          rows = result.rows;\n        } else {\n          throw error;\n        }\n      }\n\n      let userData: any;\n      let userId: string;\n\n      if (rows.length > 0) {\n        // Update existing user\n        userId = rows[0].id;\n        try {\n          await this.pool.query(\n            `UPDATE user_profiles \n             SET name = $1, avatar_url = $2, firebase_uid = $3, google_id = $4, last_active = $5, updated_at = NOW()\n             WHERE id = $6`,\n            [\n              googleUser.name,\n              googleUser.avatar || rows[0].avatar_url,\n              firebaseUidToUse, // Store Firebase UID (from Firebase Auth, not Google ID)\n              googleIdToUse, // Store Google ID separately\n              nowIso,\n              userId,\n            ],\n          );\n        } catch (error: any) {\n          // If google_id column doesn't exist, try without it\n          if (error.message && error.message.includes(\"google_id\")) {\n            await this.pool.query(\n              `UPDATE user_profiles \n               SET name = $1, avatar_url = $2, firebase_uid = $3, last_active = $4, updated_at = NOW()\n               WHERE id = $5`,\n              [\n                googleUser.name,\n                googleUser.avatar || rows[0].avatar_url,\n                firebaseUidToUse, // Store Firebase UID (from Firebase Auth, not Google ID)\n                nowIso,\n                userId,\n              ],\n            );\n          } else {\n            throw error;\n          }\n        }\n\n        // Fetch updated user data\n        const { rows: updatedRows } = await this.pool.query(\n          `SELECT id, email, name, avatar_url, roles, settings, created_at, last_active\n           FROM user_profiles WHERE id = $1`,\n          [userId],\n        );\n\n        userData = {\n          id: updatedRows[0].id,\n          email: updatedRows[0].email,\n          name: updatedRows[0].name,\n          avatar: updatedRows[0].avatar_url,\n          roles: updatedRows[0].roles || [\"user\"],\n          settings: updatedRows[0].settings || {},\n          createdAt: updatedRows[0].created_at,\n          lastActive: updatedRows[0].last_active,\n        };\n\n        // Clear statistics cache when existing user is updated\n        await this.redisCache.clearStatsCaches();\n      } else {\n        // Create new user with UUID\n        let newUser: any;\n        try {\n          const result = await this.pool.query(\n            `INSERT INTO user_profiles (\n              firebase_uid, google_id, email, name, avatar_url, bio, \n              karma_points, join_date, is_active, last_active, \n              city, country, interests, roles, email_verified, settings\n            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::text[], $14::text[], $15, $16::jsonb)\n            RETURNING id, email, name, avatar_url, roles, settings, created_at, last_active`,\n            [\n              firebaseUidToUse, // firebase_uid (from Firebase Auth, not Google ID)\n              googleIdToUse, // google_id (from Google, not Firebase UID)\n              normalizedEmail,\n              googleUser.name,\n              googleUser.avatar || \"https://i.pravatar.cc/150?img=1\",\n              \"משתמש חדש בקארמה קומיוניטי\",\n              0, // karma_points\n              nowIso, // join_date\n              true, // is_active\n              nowIso, // last_active\n              \"ישראל\", // city\n              \"Israel\", // country\n              [], // interests (empty array)\n              [\"user\"], // roles\n              googleUser.emailVerified || false, // email_verified\n              JSON.stringify({\n                language: \"he\",\n                darkMode: false,\n                notificationsEnabled: true,\n              }), // settings\n            ],\n          );\n          newUser = result;\n        } catch (error: any) {\n          // If google_id column doesn't exist, try without it\n          if (error.message && error.message.includes(\"google_id\")) {\n            const result = await this.pool.query(\n              `INSERT INTO user_profiles (\n                firebase_uid, email, name, avatar_url, bio, \n                karma_points, join_date, is_active, last_active, \n                city, country, interests, roles, email_verified, settings\n              ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb)\n              RETURNING id, email, name, avatar_url, roles, settings, created_at, last_active`,\n              [\n                firebaseUidToUse, // firebase_uid (from Firebase Auth, not Google ID)\n                normalizedEmail,\n                googleUser.name,\n                googleUser.avatar || \"https://i.pravatar.cc/150?img=1\",\n                \"משתמש חדש בקארמה קומיוניטי\",\n                0, // karma_points\n                nowIso, // join_date\n                true, // is_active\n                nowIso, // last_active\n                \"ישראל\", // city\n                \"Israel\", // country\n                [], // interests (empty array)\n                [\"user\"], // roles\n                googleUser.emailVerified || false, // email_verified\n                JSON.stringify({\n                  language: \"he\",\n                  darkMode: false,\n                  notificationsEnabled: true,\n                }), // settings\n              ],\n            );\n            newUser = result;\n          } else {\n            throw error;\n          }\n        }\n\n        const { rows: newUserRows } = newUser;\n\n        userId = newUserRows[0].id;\n        userData = {\n          id: newUserRows[0].id,\n          email: newUserRows[0].email,\n          name: newUserRows[0].name,\n          avatar: newUserRows[0].avatar_url,\n          roles: newUserRows[0].roles || [\"user\"],\n          settings: newUserRows[0].settings || {},\n          createdAt: newUserRows[0].created_at,\n          lastActive: newUserRows[0].last_active,\n        };\n\n        // Clear statistics cache when new user is created\n        await this.redisCache.clearStatsCaches();\n      }\n\n      // SECURITY: Log success without exposing sensitive data\n      this.logger.log(\n        `✅ Google authentication successful (user ID: ${userId})`,\n      );\n\n      // Generate JWT tokens for the authenticated user\n      const publicUser = this.toPublicUser(userData);\n\n      const tokenPair = await this.jwtService.createTokenPair({\n        id: publicUser.id,\n        email: publicUser.email,\n        roles: publicUser.roles || [\"user\"],\n      });\n\n      // Return tokens and user data in the format expected by the client\n      return {\n        success: true,\n        tokens: {\n          accessToken: tokenPair.accessToken,\n          refreshToken: tokenPair.refreshToken,\n          expiresIn: tokenPair.expiresIn,\n          refreshExpiresIn: tokenPair.refreshExpiresIn,\n        },\n        user: publicUser,\n      };\n    } catch (error: any) {\n      // SECURITY: Generic error message, log details separately\n      this.logger.error(\"Google authentication failed\", {\n        error: error?.message || String(error),\n        // Only include stack trace in development\n        stack:\n          process.env.NODE_ENV === \"development\" ? error?.stack : undefined,\n      });\n\n      if (error instanceof BadRequestException) {\n        throw error;\n      }\n\n      throw new InternalServerErrorException(\"Google authentication failed\");\n    }\n  }\n\n  /**\n   * Refresh access token using refresh token\n   *\n   * Security:\n   * - Rate limited to prevent abuse\n   * - Validates refresh token before issuing new access token\n   * - No sensitive data in logs\n   *\n   * @param refreshTokenDto - Refresh token data\n   * @returns New access token and expiration time\n   */\n  @Post(\"refresh\")\n  @Throttle({ default: { limit: 20, ttl: 60000 } }) // 20 refresh attempts per minute\n  async refreshToken(@Body() refreshTokenDto: RefreshTokenDto) {\n    try {\n      // Validate input\n      const errors = await validate(refreshTokenDto);\n      if (errors.length > 0) {\n        throw new BadRequestException(\"Invalid refresh token format\");\n      }\n\n      this.logger.log(\"Token refresh attempt\", {\n        timestamp: new Date().toISOString(),\n      });\n\n      // Use JwtService to refresh the token\n      const result = await this.jwtService.refreshAccessToken(\n        refreshTokenDto.refreshToken,\n      );\n\n      this.logger.log(\"Token refreshed successfully\");\n\n      return {\n        success: true,\n        accessToken: result.accessToken,\n        expiresIn: result.expiresIn,\n      };\n    } catch (error: any) {\n      // SECURITY: Generic error message, log details separately\n      this.logger.error(\"Token refresh failed\", {\n        error: error?.message || String(error),\n        // Only include stack trace in development\n        stack:\n          process.env.NODE_ENV === \"development\" ? error?.stack : undefined,\n      });\n\n      if (error instanceof BadRequestException) {\n        throw error;\n      }\n\n      // If it's an UnauthorizedException from JwtService, return as 401\n      if (error?.status === 401 || error?.message?.includes(\"Unauthorized\")) {\n        throw new BadRequestException(\"Invalid or expired refresh token\");\n      }\n\n      throw new InternalServerErrorException(\"Token refresh failed\");\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/challenges.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":178,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":178,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3680,3683],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3680,3683],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":207,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":207,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4512,4515],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4512,4515],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":239,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":239,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5471,5474],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5471,5474],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":269,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":269,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6302,6305],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6302,6305],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":301,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":301,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7226,7229],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7226,7229],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":376,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":376,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9458,9461],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9458,9461],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":446,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":446,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11591,11594],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11591,11594],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":475,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":475,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12456,12459],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12456,12459],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":518,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":518,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13748,13751],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13748,13751],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":543,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":543,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14407,14410],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14407,14410],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":555,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":555,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14719,14722],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14719,14722],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":595,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":595,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[15959,15962],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[15959,15962],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":620,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":620,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16636,16639],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16636,16639],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":632,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":632,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16948,16951],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16948,16951],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":14,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// Challenges Controller - מותאם מ-TimrsApp לשרת KC-MVP\n// מנהל את כל הפעולות הקשורות לאתגרים (Challenges/Timers) למנהלים\nimport {\n  Body,\n  Controller,\n  Get,\n  Post,\n  Put,\n  Delete,\n  Param,\n  Query,\n  Logger,\n  BadRequestException,\n  NotFoundException,\n  InternalServerErrorException,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport {\n  IsString,\n  IsNumber,\n  IsOptional,\n  IsEnum,\n  Min,\n  Max,\n  Length,\n  validate,\n} from \"class-validator\";\n\ntype TimeUnit = \"seconds\" | \"minutes\" | \"hours\" | \"days\" | \"weeks\" | \"months\";\n\n// DTOs for validation\nclass CreateChallengeDto {\n  @IsString()\n  @Length(1, 50, { message: \"שם האתגר חייב להיות בין 1-50 תווים\" })\n  name: string = \"\";\n\n  @IsEnum([\"seconds\", \"minutes\", \"hours\", \"days\", \"weeks\", \"months\"])\n  timeUnit: TimeUnit = \"days\";\n\n  @IsNumber()\n  @Min(1)\n  @Max(1000000)\n  customResetAmount: number = 0;\n\n  @IsString()\n  userId: string = \"\";\n}\n\nclass UpdateChallengeDto {\n  @IsOptional()\n  @IsString()\n  @Length(1, 50)\n  name?: string;\n\n  @IsOptional()\n  @IsEnum([\"seconds\", \"minutes\", \"hours\", \"days\", \"weeks\", \"months\"])\n  timeUnit?: TimeUnit;\n\n  @IsOptional()\n  @IsNumber()\n  @Min(1)\n  @Max(1000000)\n  customResetAmount?: number;\n\n  @IsOptional()\n  @IsNumber()\n  currentValue?: number;\n\n  @IsOptional()\n  @IsNumber()\n  currentStreak?: number;\n\n  @IsOptional()\n  @IsNumber()\n  bestStreak?: number;\n\n  @IsOptional()\n  @IsNumber()\n  resetCount?: number;\n}\n\nclass CreateResetLogDto {\n  @IsString()\n  challengeId: string = \"\";\n\n  @IsString()\n  userId: string = \"\";\n\n  @IsNumber()\n  @Min(1)\n  amountReduced: number = 0;\n\n  @IsString()\n  @Length(1, 500)\n  reason: string = \"\";\n\n  @IsNumber()\n  @Min(1)\n  @Max(5)\n  mood: number = 0;\n\n  @IsNumber()\n  valueBeforeReset: number = 0;\n\n  @IsNumber()\n  valueAfterReset: number = 0;\n}\n\nclass CreateRecordBreakDto {\n  @IsString()\n  challengeId: string = \"\";\n\n  @IsString()\n  userId: string = \"\";\n\n  @IsNumber()\n  oldRecord: number = 0;\n\n  @IsNumber()\n  newRecord: number = 0;\n\n  @IsNumber()\n  improvement: number = 0;\n\n  @IsOptional()\n  @IsString()\n  context?: string;\n\n  @IsOptional()\n  @IsString()\n  reason?: string;\n}\n\n@Controller(\"api/challenges\")\nexport class ChallengesController {\n  private readonly logger = new Logger(ChallengesController.name);\n\n  constructor(@Inject(PG_POOL) private readonly pool: Pool) {}\n\n  @Post()\n  async createChallenge(@Body() createDto: CreateChallengeDto) {\n    this.logger.log(`Creating new challenge for user: ${createDto.userId}`);\n\n    const errors = await validate(createDto);\n    if (errors.length > 0) {\n      throw new BadRequestException(\"Validation failed\");\n    }\n\n    const client = await this.pool.connect();\n    try {\n      const now = Date.now();\n      const result = await client.query(\n        `INSERT INTO challenges \n        (user_id, name, start_date, time_unit, custom_reset_amount, \n         current_value, last_calculated, current_streak, best_streak, \n         reset_count, last_reset_date, created_at, updated_at)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, NOW(), NOW())\n        RETURNING *`,\n        [\n          createDto.userId,\n          createDto.name,\n          now,\n          createDto.timeUnit,\n          createDto.customResetAmount,\n          0, // current_value\n          now, // last_calculated\n          0, // current_streak\n          0, // best_streak\n          0, // reset_count\n          now, // last_reset_date\n        ],\n      );\n\n      this.logger.log(`Challenge created successfully: ${result.rows[0].id}`);\n      return { success: true, data: result.rows[0] };\n    } catch (error: any) {\n      this.logger.error(\"Error creating challenge:\", error);\n      this.logger.error(\"Error details:\", error.message, error.stack);\n      throw new InternalServerErrorException(\n        `Failed to create challenge: ${error.message || \"Unknown error\"}`,\n      );\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get()\n  async getChallenges(@Query(\"userId\") userId: string) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Fetching challenges for user: ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      const result = await client.query(\n        `SELECT * FROM challenges \n         WHERE user_id = $1 \n         ORDER BY created_at DESC`,\n        [userId],\n      );\n\n      return { success: true, data: result.rows };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching challenges:\", error);\n      this.logger.error(\"Error details:\", error.message, error.stack);\n      throw new InternalServerErrorException(\n        `Failed to fetch challenges: ${error.message || \"Unknown error\"}`,\n      );\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\":id\")\n  async getChallenge(@Param(\"id\") id: string, @Query(\"userId\") userId: string) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Fetching challenge: ${id} for user: ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      const result = await client.query(\n        `SELECT * FROM challenges \n         WHERE id = $1 AND user_id = $2`,\n        [id, userId],\n      );\n\n      if (result.rows.length === 0) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      return { success: true, data: result.rows[0] };\n    } catch (error: any) {\n      if (error instanceof NotFoundException) throw error;\n      this.logger.error(\"Error fetching challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Put(\":id\")\n  async updateChallenge(\n    @Param(\"id\") id: string,\n    @Query(\"userId\") userId: string,\n    @Body() updateDto: UpdateChallengeDto,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Updating challenge: ${id}`);\n\n    const errors = await validate(updateDto);\n    if (errors.length > 0) {\n      throw new BadRequestException(\"Validation failed\");\n    }\n\n    const client = await this.pool.connect();\n    try {\n      // Build dynamic update query\n      const updates: string[] = [];\n      const values: any[] = [];\n      let paramCount = 1;\n\n      Object.entries(updateDto).forEach(([key, value]) => {\n        if (value !== undefined) {\n          updates.push(`${this.camelToSnake(key)} = $${paramCount}`);\n          values.push(value);\n          paramCount++;\n        }\n      });\n\n      if (updates.length === 0) {\n        throw new BadRequestException(\"No fields to update\");\n      }\n\n      updates.push(`updated_at = NOW()`);\n      values.push(id, userId);\n\n      const result = await client.query(\n        `UPDATE challenges \n         SET ${updates.join(\", \")}\n         WHERE id = $${paramCount} AND user_id = $${paramCount + 1}\n         RETURNING *`,\n        values,\n      );\n\n      if (result.rows.length === 0) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      this.logger.log(`Challenge updated successfully: ${id}`);\n      return { success: true, data: result.rows[0] };\n    } catch (error: any) {\n      if (\n        error instanceof NotFoundException ||\n        error instanceof BadRequestException\n      )\n        throw error;\n      this.logger.error(\"Error updating challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to update challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Delete(\":id\")\n  async deleteChallenge(\n    @Param(\"id\") id: string,\n    @Query(\"userId\") userId: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Deleting challenge: ${id}`);\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get challenge before deletion\n      const challengeResult = await client.query(\n        \"SELECT * FROM challenges WHERE id = $1 AND user_id = $2\",\n        [id, userId],\n      );\n\n      if (challengeResult.rows.length === 0) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      const challenge = challengeResult.rows[0];\n\n      // Save to deleted_challenges\n      await client.query(\n        `INSERT INTO deleted_challenges \n        (id, user_id, name, start_date, time_unit, custom_reset_amount, \n         current_value, last_calculated, current_streak, best_streak, \n         reset_count, last_reset_date, deleted_at, final_value)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)`,\n        [\n          challenge.id,\n          challenge.user_id,\n          challenge.name,\n          challenge.start_date,\n          challenge.time_unit,\n          challenge.custom_reset_amount,\n          challenge.current_value,\n          challenge.last_calculated,\n          challenge.current_streak,\n          challenge.best_streak,\n          challenge.reset_count,\n          challenge.last_reset_date,\n          Date.now(),\n          challenge.current_value,\n        ],\n      );\n\n      // Delete from challenges\n      await client.query(\n        \"DELETE FROM challenges WHERE id = $1 AND user_id = $2\",\n        [id, userId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      this.logger.log(`Challenge deleted successfully: ${id}`);\n      return { success: true, message: \"Challenge deleted\" };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      if (error instanceof NotFoundException) throw error;\n      this.logger.error(\"Error deleting challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to delete challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Post(\"restore/:id\")\n  async restoreChallenge(\n    @Param(\"id\") id: string,\n    @Query(\"userId\") userId: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Restoring challenge: ${id}`);\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get deleted challenge\n      const deletedResult = await client.query(\n        \"SELECT * FROM deleted_challenges WHERE id = $1 AND user_id = $2\",\n        [id, userId],\n      );\n\n      if (deletedResult.rows.length === 0) {\n        throw new NotFoundException(\"Deleted challenge not found\");\n      }\n\n      const deleted = deletedResult.rows[0];\n\n      // Restore to challenges\n      await client.query(\n        `INSERT INTO challenges \n        (id, user_id, name, start_date, time_unit, custom_reset_amount, \n         current_value, last_calculated, current_streak, best_streak, \n         reset_count, last_reset_date, created_at, updated_at)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, NOW(), NOW())`,\n        [\n          deleted.id,\n          deleted.user_id,\n          deleted.name,\n          deleted.start_date,\n          deleted.time_unit,\n          deleted.custom_reset_amount,\n          deleted.current_value,\n          deleted.last_calculated,\n          deleted.current_streak,\n          deleted.best_streak,\n          deleted.reset_count,\n          deleted.last_reset_date,\n        ],\n      );\n\n      // Delete from deleted_challenges\n      await client.query(\n        \"DELETE FROM deleted_challenges WHERE id = $1 AND user_id = $2\",\n        [id, userId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      this.logger.log(`Challenge restored successfully: ${id}`);\n      return { success: true, message: \"Challenge restored\" };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      if (error instanceof NotFoundException) throw error;\n      this.logger.error(\"Error restoring challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to restore challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"history/deleted\")\n  async getDeletedChallenges(@Query(\"userId\") userId: string) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Fetching deleted challenges for user: ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      const result = await client.query(\n        `SELECT * FROM deleted_challenges \n         WHERE user_id = $1 \n         ORDER BY deleted_at DESC \n         LIMIT 50`,\n        [userId],\n      );\n\n      return { success: true, data: result.rows };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching deleted challenges:\", error);\n      throw new InternalServerErrorException(\n        \"Failed to fetch deleted challenges\",\n      );\n    } finally {\n      client.release();\n    }\n  }\n\n  @Post(\"reset-logs\")\n  async createResetLog(@Body() createDto: CreateResetLogDto) {\n    this.logger.log(\n      `Creating reset log for challenge: ${createDto.challengeId}`,\n    );\n\n    const errors = await validate(createDto);\n    if (errors.length > 0) {\n      throw new BadRequestException(\"Validation failed\");\n    }\n\n    const client = await this.pool.connect();\n    try {\n      const result = await client.query(\n        `INSERT INTO challenge_reset_logs \n        (challenge_id, user_id, timestamp, amount_reduced, reason, mood, \n         value_before_reset, value_after_reset)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\n        RETURNING *`,\n        [\n          createDto.challengeId,\n          createDto.userId,\n          Date.now(),\n          createDto.amountReduced,\n          createDto.reason,\n          createDto.mood,\n          createDto.valueBeforeReset,\n          createDto.valueAfterReset,\n        ],\n      );\n\n      this.logger.log(`Reset log created successfully`);\n      return { success: true, data: result.rows[0] };\n    } catch (error: any) {\n      this.logger.error(\"Error creating reset log:\", error);\n      throw new InternalServerErrorException(\"Failed to create reset log\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"reset-logs/all\")\n  async getResetLogs(\n    @Query(\"userId\") userId: string,\n    @Query(\"challengeId\") challengeId?: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Fetching reset logs for user: ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      let query = `\n        SELECT * FROM challenge_reset_logs \n        WHERE user_id = $1\n      `;\n      const params: any[] = [userId];\n\n      if (challengeId) {\n        query += \" AND challenge_id = $2\";\n        params.push(challengeId);\n      }\n\n      query += \" ORDER BY timestamp DESC LIMIT 200\";\n\n      const result = await client.query(query, params);\n\n      return { success: true, data: result.rows };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching reset logs:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch reset logs\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Post(\"record-breaks\")\n  async createRecordBreak(@Body() createDto: CreateRecordBreakDto) {\n    this.logger.log(\n      `Creating record break for challenge: ${createDto.challengeId}`,\n    );\n\n    const errors = await validate(createDto);\n    if (errors.length > 0) {\n      throw new BadRequestException(\"Validation failed\");\n    }\n\n    const client = await this.pool.connect();\n    try {\n      const result = await client.query(\n        `INSERT INTO challenge_record_breaks \n        (challenge_id, user_id, timestamp, old_record, new_record, improvement, context, reason)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8)\n        RETURNING *`,\n        [\n          createDto.challengeId,\n          createDto.userId,\n          Date.now(),\n          createDto.oldRecord,\n          createDto.newRecord,\n          createDto.improvement,\n          createDto.context,\n          createDto.reason,\n        ],\n      );\n\n      this.logger.log(`Record break created successfully`);\n      return { success: true, data: result.rows[0] };\n    } catch (error: any) {\n      this.logger.error(\"Error creating record break:\", error);\n      throw new InternalServerErrorException(\"Failed to create record break\");\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"record-breaks/all\")\n  async getRecordBreaks(\n    @Query(\"userId\") userId: string,\n    @Query(\"challengeId\") challengeId?: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"userId is required\");\n    }\n\n    this.logger.log(`Fetching record breaks for user: ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      let query = `\n        SELECT * FROM challenge_record_breaks \n        WHERE user_id = $1\n      `;\n      const params: any[] = [userId];\n\n      if (challengeId) {\n        query += \" AND challenge_id = $2\";\n        params.push(challengeId);\n      }\n\n      query += \" ORDER BY timestamp DESC LIMIT 100\";\n\n      const result = await client.query(query, params);\n\n      return { success: true, data: result.rows };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching record breaks:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch record breaks\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Helper: Convert camelCase to snake_case\n   */\n  private camelToSnake(str: string): string {\n    return str.replace(/[A-Z]/g, (letter) => `_${letter.toLowerCase()}`);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/chat.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":82,"column":54,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":82,"endColumn":57,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2306,2309],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2306,2309],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":82,"column":75,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":82,"endColumn":78,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2327,2330],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2327,2330],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":216,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":216,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6360,6363],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6360,6363],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":313,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":313,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9411,9414],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9411,9414],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":409,"column":42,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":409,"endColumn":45,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12230,12233],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12230,12233],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":409,"column":63,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":409,"endColumn":66,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12251,12254],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12251,12254],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":638,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":638,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[19524,19527],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[19524,19527],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":639,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":639,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[19549,19552],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[19549,19552],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":718,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":718,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[21863,21866],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[21863,21866],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":719,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":719,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[21888,21891],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[21888,21891],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  Body,\n  Controller,\n  Get,\n  Param,\n  Post,\n  Query,\n  UseGuards,\n  Request,\n  Inject,\n  Logger,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { OptionalAuthGuard } from \"../auth/jwt-auth.guard\";\nimport { UserResolutionService } from \"../services/user-resolution.service\";\n\n@Controller(\"api/chat\")\n@UseGuards(OptionalAuthGuard)\nexport class ChatController {\n  private readonly logger = new Logger(ChatController.name);\n  private readonly CACHE_TTL = 2 * 60; // 2 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n    private readonly userResolutionService: UserResolutionService,\n  ) {}\n\n  // resolveUserId is now handled by UserResolutionService\n  // This wrapper method maintains backward compatibility\n  private async resolveUserId(userId: string): Promise<string> {\n    // With throwOnNotFound=true, this will never return null\n    return this.userResolutionService.resolveUserId(userId, {\n      throwOnNotFound: true,\n      cacheResult: true,\n    }) as Promise<string>;\n  }\n\n  // --- Utility: Validate UUID ---\n  private isValidUUID(uuid: string): boolean {\n    return this.userResolutionService.isValidUUID(uuid);\n  }\n\n  // --- Utility: Clear Caches ---\n  private async clearChatCaches() {\n    const patterns = [\n      \"user_conversations_*\",\n      \"conversation_messages_*\",\n      \"search_messages_*\",\n      \"chat_stats_summary\",\n    ];\n    for (const pattern of patterns) {\n      try {\n        await this.redisCache.invalidatePattern(pattern);\n      } catch (error) {\n        this.logger.warn(\n          `Failed to invalidate cache pattern ${pattern}:`,\n          error,\n        );\n      }\n    }\n  }\n\n  // --- Utility: Hash String ---\n  private hashStringToInt(str: string): number {\n    let hash = 0;\n    for (let i = 0; i < str.length; i++) {\n      const char = str.charCodeAt(i);\n      hash = (hash << 5) - hash + char;\n      hash = hash & hash;\n    }\n    return Math.abs(hash);\n  }\n\n  // ==========================================\n  // ENDPOINTS\n  // ==========================================\n\n  @Post(\"conversations\")\n  async createConversation(@Body() conversationData: any, @Request() req: any) {\n    if (\n      !conversationData.participants ||\n      !Array.isArray(conversationData.participants)\n    ) {\n      return {\n        success: false,\n        error: \"Participants must be a non-empty array\",\n      };\n    }\n    if (conversationData.participants.length < 2) {\n      return {\n        success: false,\n        error: \"Conversation must have at least 2 participants\",\n      };\n    }\n    if (conversationData.participants.length > 50) {\n      return {\n        success: false,\n        error: \"Conversation cannot have more than 50 participants\",\n      };\n    }\n\n    const authenticatedUserId = req.user?.userId;\n    if (authenticatedUserId && !conversationData.created_by) {\n      conversationData.created_by = authenticatedUserId;\n    }\n\n    const client = await this.pool.connect();\n\n    try {\n      const resolvedCreatedBy = await this.resolveUserId(\n        conversationData.created_by,\n      );\n      const resolvedParticipants = await Promise.all(\n        (conversationData.participants || []).map((p: string) =>\n          this.resolveUserId(p),\n        ),\n      );\n\n      if (!this.isValidUUID(resolvedCreatedBy)) {\n        return {\n          success: false,\n          error: \"Invalid user ID: created_by must be a valid UUID\",\n        };\n      }\n\n      for (const participant of resolvedParticipants) {\n        if (!this.isValidUUID(participant)) {\n          return {\n            success: false,\n            error: `Invalid participant ID: ${participant} must be a valid UUID`,\n          };\n        }\n      }\n\n      // CRITICAL FIX: Sort participants to ensure consistent order\n      // This prevents duplicate conversations when participants arrive in different order\n      const sortedParticipants = [...resolvedParticipants].sort((a, b) =>\n        a.localeCompare(b),\n      );\n\n      await client.query(\"BEGIN\");\n\n      // Check for existing conversation with exact same participants\n      // Use sorted participants to ensure we find existing conversation regardless of order\n      const { rows: existingConvs } = await client.query(\n        `\n        SELECT * FROM chat_conversations\n        WHERE participants @> $1::uuid[]\n          AND participants <@ $1::uuid[]\n          AND array_length(participants, 1) = $2\n        LIMIT 1\n      `,\n        [sortedParticipants, sortedParticipants.length],\n      );\n\n      if (existingConvs.length > 0) {\n        await client.query(\"COMMIT\");\n        client.release();\n        return { success: true, data: existingConvs[0] };\n      }\n\n      // Insert with sorted participants to maintain consistency\n      const { rows } = await client.query(\n        `\n        INSERT INTO chat_conversations (title, type, participants, created_by, metadata)\n        VALUES ($1, $2, $3::uuid[], $4::uuid, $5)\n        RETURNING *\n      `,\n        [\n          conversationData.title || null,\n          conversationData.type || \"direct\",\n          sortedParticipants, // Use sorted participants\n          resolvedCreatedBy,\n          conversationData.metadata\n            ? JSON.stringify(conversationData.metadata)\n            : null,\n        ],\n      );\n\n      const conversation = rows[0];\n\n      await client.query(\n        `\n        INSERT INTO user_activities (user_id, activity_type, activity_data)\n        VALUES ($1::uuid, $2, $3)\n      `,\n        [\n          resolvedCreatedBy,\n          \"conversation_created\",\n          JSON.stringify({\n            conversation_id: conversation.id,\n            participants_count: resolvedParticipants.length,\n          }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n      await this.clearChatCaches();\n\n      return { success: true, data: conversation };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Create conversation error:\", error);\n      return { success: false, error: \"Failed to create conversation\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"conversations/user/:userId\")\n  async getUserConversations(\n    @Param(\"userId\") userId: string,\n    @Request() req: any,\n  ) {\n    this.logger.debug(\"Executing getUserConversations\");\n    try {\n      const authenticatedUserId = req.user?.userId;\n      const resolvedParamUserId = await this.resolveUserId(userId);\n      let resolvedUserId: string;\n\n      if (authenticatedUserId) {\n        const resolvedAuthUserId =\n          await this.resolveUserId(authenticatedUserId);\n        if (resolvedParamUserId !== resolvedAuthUserId) {\n          return {\n            success: false,\n            error: \"Access denied - can only view your own conversations\",\n          };\n        }\n        resolvedUserId = resolvedAuthUserId;\n      } else {\n        resolvedUserId = resolvedParamUserId;\n      }\n\n      if (!this.isValidUUID(resolvedUserId)) {\n        return { success: true, data: [] };\n      }\n\n      const cacheKey = `user_conversations_${resolvedUserId}`;\n      let cached;\n      try {\n        cached = await this.redisCache.get(cacheKey);\n      } catch {\n        /* S108: cache miss is non-fatal */\n      }\n\n      if (cached) {\n        return { success: true, data: cached };\n      }\n\n      // Query using UUID - all fields are now UUID type\n      // Cast both sides explicitly to UUID to avoid type mismatch\n      const { rows } = await this.pool.query(\n        `\n        SELECT \n          cc.*,\n          cm.content as last_message_content,\n          cm.message_type as last_message_type,\n          cm.created_at as last_message_time,\n          CASE \n            WHEN cm.sender_id IS NULL THEN 'ללא שם'\n            ELSE COALESCE(\n              (SELECT name FROM user_profiles WHERE id = cm.sender_id LIMIT 1),\n              'ללא שם'\n            )\n          END as last_sender_name,\n          (\n            SELECT COUNT(*)\n            FROM chat_messages cm2\n            WHERE cm2.conversation_id = cc.id \n              AND cm2.sender_id != $1\n              AND cm2.is_deleted = false\n              AND NOT EXISTS (\n                SELECT 1 \n                FROM message_read_receipts mrr\n                WHERE mrr.message_id = cm2.id \n                AND mrr.user_id = $1\n              )\n          ) as unread_count\n        FROM chat_conversations cc\n        LEFT JOIN chat_messages cm ON cc.last_message_id = cm.id\n        WHERE $1::uuid = ANY(cc.participants::uuid[])\n        ORDER BY cc.last_message_at DESC\n      `,\n        [resolvedUserId],\n      );\n\n      try {\n        await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n      } catch {\n        /* S108: cache set error is non-fatal */\n      }\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Get user conversations error:\", error);\n      return {\n        success: false,\n        error: \"Failed to get user conversations\",\n        message: error instanceof Error ? error.message : \"Unknown error\",\n      };\n    }\n  }\n\n  @Get(\"conversations/:conversationId/messages\")\n  async getConversationMessages(\n    @Param(\"conversationId\") conversationId: string,\n    @Query(\"limit\") limit: string = \"100\",\n    @Query(\"offset\") offset: string = \"0\",\n    @Request() req: any,\n  ) {\n    try {\n      const limitNum = parseInt(limit, 10) || 100;\n      const offsetNum = parseInt(offset, 10) || 0;\n\n      if (!this.isValidUUID(conversationId)) {\n        return { success: false, error: \"Invalid conversation ID\" };\n      }\n\n      const authenticatedUserId = req.user?.userId;\n\n      if (authenticatedUserId) {\n        const resolvedUserId = await this.resolveUserId(authenticatedUserId);\n        if (!this.isValidUUID(resolvedUserId)) {\n          return { success: false, error: \"Invalid user ID\" };\n        }\n\n        const { rows: convCheck } = await this.pool.query(\n          `\n          SELECT id FROM chat_conversations \n          WHERE id = $1::uuid AND $2::uuid = ANY(participants::uuid[])\n        `,\n          [conversationId, resolvedUserId],\n        );\n\n        if (convCheck.length === 0) {\n          return {\n            success: false,\n            error: \"Conversation not found or access denied\",\n          };\n        }\n      } else {\n        const { rows: convCheck } = await this.pool.query(\n          `\n          SELECT id FROM chat_conversations WHERE id = $1::uuid\n        `,\n          [conversationId],\n        );\n        if (convCheck.length === 0) {\n          return { success: false, error: \"Conversation not found\" };\n        }\n      }\n\n      const cacheKey = `conversation_messages_${conversationId}_${limitNum}_${offsetNum}`;\n      let cached;\n      try {\n        cached = await this.redisCache.get(cacheKey);\n        if (cached) {\n          return { success: true, data: cached };\n        }\n      } catch {\n        /* S108: cache miss is non-fatal */\n      }\n\n      const { rows } = await this.pool.query(\n        `\n        SELECT \n          cm.*,\n          COALESCE(\n            (SELECT name FROM user_profiles WHERE id = cm.sender_id LIMIT 1),\n            'ללא שם'\n          ) as sender_name,\n          COALESCE(\n            (SELECT avatar_url FROM user_profiles WHERE id = cm.sender_id LIMIT 1),\n            ''\n          ) as sender_avatar\n        FROM chat_messages cm\n        WHERE cm.conversation_id = $1::uuid\n          AND cm.is_deleted = false\n        ORDER BY cm.created_at DESC\n        LIMIT $2 OFFSET $3\n      `,\n        [conversationId, limitNum, offsetNum],\n      );\n\n      const messages = rows.reverse();\n\n      try {\n        await this.redisCache.set(cacheKey, messages, this.CACHE_TTL);\n      } catch {\n        /* S108: cache set error is non-fatal */\n      }\n\n      return { success: true, data: messages };\n    } catch (error) {\n      this.logger.error(\"Get conversation messages error:\", error);\n      return {\n        success: false,\n        error: \"Failed to get conversation messages\",\n        message: error instanceof Error ? error.message : \"Unknown error\",\n      };\n    }\n  }\n\n  @Post(\"messages\")\n  async sendMessage(@Body() messageData: any, @Request() req: any) {\n    const client = await this.pool.connect();\n    const authenticatedUserId = req.user?.userId;\n    let senderId: string;\n\n    if (authenticatedUserId) {\n      senderId = messageData.sender_id || authenticatedUserId;\n      if (senderId !== authenticatedUserId) {\n        client.release();\n        return { success: false, error: \"Cannot send message as another user\" };\n      }\n    } else {\n      if (!messageData.sender_id) {\n        client.release();\n        return {\n          success: false,\n          error: \"sender_id is required when not authenticated\",\n        };\n      }\n      senderId = messageData.sender_id;\n    }\n\n    const resolvedSenderId = await this.resolveUserId(senderId);\n    if (!this.isValidUUID(resolvedSenderId)) {\n      client.release();\n      return {\n        success: false,\n        error: \"Invalid sender ID: must be a valid UUID\",\n      };\n    }\n\n    let conversationId = messageData.conversation_id;\n    let conversationCreated = false;\n    let transactionStarted = false;\n\n    try {\n      if (!conversationId || !this.isValidUUID(conversationId)) {\n        if (messageData.participants?.length > 0) {\n          const resolvedParticipants = await Promise.all(\n            messageData.participants.map((p: string) => this.resolveUserId(p)),\n          );\n\n          for (const p of resolvedParticipants) {\n            if (!this.isValidUUID(p)) {\n              client.release();\n              return { success: false, error: `Invalid participant ID: ${p}` };\n            }\n          }\n\n          // CRITICAL FIX: Sort participants to ensure consistent order\n          const sortedParticipants = [...resolvedParticipants].sort((a, b) =>\n            a.localeCompare(b),\n          );\n\n          await client.query(\"BEGIN\");\n          transactionStarted = true;\n\n          const participantsHash = sortedParticipants.join(\",\");\n          const lockKey = `conversation_${Buffer.from(participantsHash).toString(\"base64\").slice(0, 16)}`;\n          const lockId = this.hashStringToInt(lockKey);\n          await client.query(\"SELECT pg_advisory_xact_lock($1)\", [lockId]);\n\n          // Check with sorted participants\n          const { rows: existingConvs } = await client.query(\n            `\n              SELECT id FROM chat_conversations\n              WHERE participants @> $1::uuid[]\n                AND participants <@ $1::uuid[]\n                AND array_length(participants, 1) = $2\n              LIMIT 1\n            `,\n            [sortedParticipants, sortedParticipants.length],\n          );\n\n          if (existingConvs.length > 0) {\n            conversationId = existingConvs[0].id;\n          } else {\n            // Insert with sorted participants\n            const { rows: newConvRows } = await client.query(\n              `\n                INSERT INTO chat_conversations (title, type, participants, created_by, metadata)\n                VALUES ($1, $2, $3::uuid[], $4::uuid, $5)\n                RETURNING *\n              `,\n              [\n                null,\n                \"direct\",\n                sortedParticipants,\n                resolvedSenderId,\n                messageData.metadata\n                  ? JSON.stringify(messageData.metadata)\n                  : null,\n              ],\n            );\n            conversationId = newConvRows[0].id;\n            conversationCreated = true;\n          }\n        } else {\n          client.release();\n          return {\n            success: false,\n            error: \"Invalid conversation ID or missing participants\",\n          };\n        }\n      } else {\n        await client.query(\"BEGIN\");\n        transactionStarted = true;\n      }\n\n      let convCheck;\n      if (authenticatedUserId) {\n        const { rows } = await client.query(\n          `\n          SELECT id FROM chat_conversations \n          WHERE id = $1::uuid AND $2::uuid = ANY(participants::uuid[])\n        `,\n          [conversationId, resolvedSenderId],\n        );\n        convCheck = rows;\n      } else {\n        const { rows } = await client.query(\n          `SELECT id FROM chat_conversations WHERE id = $1::uuid`,\n          [conversationId],\n        );\n        convCheck = rows;\n      }\n\n      if (convCheck.length === 0) {\n        if (transactionStarted) await client.query(\"ROLLBACK\");\n        client.release();\n        return {\n          success: false,\n          error: \"Conversation not found or access denied\",\n        };\n      }\n\n      if (!messageData.content && !messageData.file_url) {\n        if (transactionStarted) await client.query(\"ROLLBACK\");\n        client.release();\n        return {\n          success: false,\n          error: \"Message must have content or file_url\",\n        };\n      }\n\n      if (messageData.content && messageData.content.length > 10000) {\n        if (transactionStarted) await client.query(\"ROLLBACK\");\n        client.release();\n        return { success: false, error: \"Message content too long\" };\n      }\n\n      if (messageData.file_url) {\n        try {\n          new URL(messageData.file_url);\n        } catch {\n          if (transactionStarted) await client.query(\"ROLLBACK\");\n          client.release();\n          return { success: false, error: \"Invalid file_url format\" };\n        }\n      }\n\n      const { rows } = await client.query(\n        `\n        INSERT INTO chat_messages (\n          conversation_id, sender_id, content, message_type, \n          file_url, file_name, file_size, file_type, metadata, reply_to_id\n        ) VALUES ($1::uuid, $2::uuid, $3, $4, $5, $6, $7, $8, $9, $10::uuid)\n        RETURNING *\n      `,\n        [\n          conversationId,\n          resolvedSenderId,\n          messageData.content || null,\n          messageData.message_type || \"text\",\n          messageData.file_url || null,\n          messageData.file_name || null,\n          messageData.file_size || null,\n          messageData.file_type || null,\n          messageData.metadata ? JSON.stringify(messageData.metadata) : null,\n          messageData.reply_to_id || null,\n        ],\n      );\n\n      const message = rows[0];\n\n      await client.query(\n        `\n        UPDATE chat_conversations \n        SET last_message_id = $1, last_message_at = NOW(), updated_at = NOW()\n        WHERE id = $2\n      `,\n        [message.id, conversationId],\n      );\n\n      await client.query(\"COMMIT\");\n      await this.clearChatCaches();\n\n      client.release();\n      return {\n        success: true,\n        data: message,\n        conversation_id:\n          conversationCreated || conversationId !== messageData.conversation_id\n            ? conversationId\n            : undefined,\n        conversation_created:\n          conversationCreated || conversationId !== messageData.conversation_id,\n      };\n    } catch (error) {\n      if (transactionStarted) {\n        try {\n          await client.query(\"ROLLBACK\");\n        } catch {\n          // ignore rollback errors\n        }\n      }\n      client.release();\n      this.logger.error(\"Send message error:\", error);\n      return {\n        success: false,\n        error: \"Failed to send message\",\n        message: error instanceof Error ? error.message : \"Unknown error\",\n      };\n    }\n  }\n\n  @Post(\"conversations/:conversationId/read-all\")\n  async markAllMessagesAsRead(\n    @Param(\"conversationId\") conversationId: string,\n    @Body() body: any,\n    @Request() req: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const authenticatedUserId = req.user?.userId || body?.user_id;\n      if (!authenticatedUserId) {\n        client.release();\n        return { success: false, error: \"Authentication required\" };\n      }\n\n      const resolvedUserId = await this.resolveUserId(authenticatedUserId);\n      if (\n        !this.isValidUUID(resolvedUserId) ||\n        !this.isValidUUID(conversationId)\n      ) {\n        client.release();\n        return { success: false, error: \"Invalid ID\" };\n      }\n\n      const { rows: convCheck } = await this.pool.query(\n        `\n        SELECT id FROM chat_conversations \n        WHERE id = $1::uuid AND $2::uuid = ANY(participants)\n      `,\n        [conversationId, resolvedUserId],\n      );\n\n      if (convCheck.length === 0) {\n        client.release();\n        return {\n          success: false,\n          error: \"Conversation not found or access denied\",\n        };\n      }\n\n      await client.query(\"BEGIN\");\n      const { rows: unreadMessages } = await client.query(\n        `\n        SELECT id FROM chat_messages\n        WHERE conversation_id = $1::uuid\n          AND sender_id != $2\n          AND is_deleted = false\n          AND NOT EXISTS (\n            SELECT 1 FROM message_read_receipts \n            WHERE message_id = chat_messages.id AND user_id = $2\n          )\n      `,\n        [conversationId, resolvedUserId],\n      );\n\n      if (unreadMessages.length > 0) {\n        const insertPromises = unreadMessages.map((msg) =>\n          client.query(\n            `\n            INSERT INTO message_read_receipts (message_id, user_id)\n            VALUES ($1::uuid, $2)\n            ON CONFLICT (message_id, user_id) DO NOTHING\n          `,\n            [msg.id, resolvedUserId],\n          ),\n        );\n        await Promise.all(insertPromises);\n      }\n\n      await client.query(\"COMMIT\");\n      await this.clearChatCaches();\n\n      client.release();\n      return { success: true, data: { marked_read: unreadMessages.length } };\n    } catch (_error) {\n      await client.query(\"ROLLBACK\");\n      client.release();\n      return { success: false, error: \"Failed to mark messages read\" };\n    }\n  }\n\n  @Post(\"messages/:messageId/read\")\n  async markMessageAsRead(\n    @Param(\"messageId\") messageId: string,\n    @Body() body: any,\n    @Request() req: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const authenticatedUserId = req.user?.userId || body?.user_id;\n      if (!authenticatedUserId) {\n        client.release();\n        return { success: false, error: \"Authentication required\" };\n      }\n      const resolvedUserId = await this.resolveUserId(authenticatedUserId);\n\n      if (!this.isValidUUID(resolvedUserId) || !this.isValidUUID(messageId)) {\n        client.release();\n        return { success: false, error: \"Invalid ID\" };\n      }\n\n      const { rows: messageCheck } = await this.pool.query(\n        `\n            SELECT cm.id, cm.conversation_id, cm.sender_id\n            FROM chat_messages cm\n            JOIN chat_conversations cc ON cm.conversation_id = cc.id\n            WHERE cm.id = $1::uuid\n            AND $2::uuid = ANY(cc.participants::uuid[])\n            AND cm.is_deleted = false\n        `,\n        [messageId, resolvedUserId],\n      );\n\n      if (messageCheck.length === 0) {\n        client.release();\n        return { success: false, error: \"Message not found or access denied\" };\n      }\n\n      if (messageCheck[0].sender_id === resolvedUserId) {\n        client.release();\n        return { success: true, data: { already_read: true } };\n      }\n\n      await client.query(\"BEGIN\");\n      await client.query(\n        `\n            INSERT INTO message_read_receipts (message_id, user_id)\n            VALUES ($1::uuid, $2)\n            ON CONFLICT (message_id, user_id) DO NOTHING\n        `,\n        [messageId, resolvedUserId],\n      );\n      await client.query(\"COMMIT\");\n      await this.clearChatCaches();\n\n      client.release();\n      return { success: true, data: { marked_read: true } };\n    } catch (_error) {\n      await client.query(\"ROLLBACK\");\n      client.release();\n      return { success: false, error: \"Failed to mark message as read\" };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/community-group-challenges.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":152,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":152,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4431,4434],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4431,4434],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":181,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":181,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5251,5254],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5251,5254],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":241,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":241,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6974,6977],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6974,6977],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":334,"column":43,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":334,"endColumn":46,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9616,9619],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9616,9619],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":359,"column":28,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":359,"endColumn":31,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10518,10521],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10518,10521],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":435,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":435,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12951,12954],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12951,12954],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":499,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":499,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14574,14577],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14574,14577],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":580,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":580,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16696,16699],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16696,16699],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":721,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":721,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[20948,20951],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[20948,20951],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":765,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":765,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[22194,22197],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[22194,22197],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":825,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":825,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[23785,23788],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[23785,23788],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":872,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":872,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[24986,24989],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[24986,24989],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":950,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":950,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[27025,27028],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[27025,27028],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1009,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1009,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[28552,28555],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[28552,28555],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":14,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// Community Group Challenges Controller\n// Handles all operations for community challenges: create, list, join, track entries, statistics\nimport {\n  Body,\n  Controller,\n  Get,\n  Post,\n  Put,\n  Delete,\n  Param,\n  Query,\n  Logger,\n  BadRequestException,\n  NotFoundException,\n  InternalServerErrorException,\n  Inject,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { validate } from \"class-validator\";\nimport {\n  CreateCommunityGroupChallengeDto,\n  UpdateCommunityGroupChallengeDto,\n  JoinChallengeDto,\n  CreateChallengeEntryDto,\n  GetChallengesFilterDto,\n} from \"./dto/community-challenge.dto\";\n\n@Controller(\"api/community-challenges\")\nexport class CommunityGroupChallengesController {\n  private readonly logger = new Logger(CommunityGroupChallengesController.name);\n\n  constructor(@Inject(PG_POOL) private readonly pool: Pool) {}\n\n  /**\n   * Create a new community challenge\n   * Also creates a post automatically in the feed\n   */\n  @Post()\n  async createChallenge(@Body() dto: CreateCommunityGroupChallengeDto) {\n    this.logger.log(`Creating new community challenge: ${dto.title}`);\n\n    const errors = await validate(dto);\n    if (errors.length > 0) {\n      this.logger.warn(\"Validation failed\", errors);\n      throw new BadRequestException(\"Validation failed\");\n    }\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // 1. Create the challenge - simple approach without image_url column\n      this.logger.log(`🔍 Creating challenge: ${dto.title}`);\n      this.logger.log(\n        `📊 Challenge data: ${JSON.stringify({\n          creator_id: dto.creator_id,\n          title: dto.title,\n          type: dto.type,\n          frequency: dto.frequency,\n          difficulty: dto.difficulty,\n        })}`,\n      );\n\n      const {\n        rows: [challenge],\n      } = await client.query(\n        `\n        INSERT INTO community_group_challenges \n        (creator_id, title, description, type, frequency, goal_value, deadline, difficulty, category)\n        VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n        RETURNING *\n      `,\n        [\n          dto.creator_id,\n          dto.title,\n          dto.description || null,\n          dto.type,\n          dto.frequency,\n          dto.goal_value || null,\n          dto.deadline || null,\n          dto.difficulty || null,\n          dto.category || null,\n        ],\n      );\n\n      this.logger.log(`✅ Challenge created with ID: ${challenge.id}`);\n\n      // 2. Auto-create a corresponding post\n      try {\n        const postTitle = challenge.title;\n        const postDescription =\n          challenge.description || `אתגר קהילתי חדש: ${challenge.title}`;\n\n        await client.query(\n          `\n          INSERT INTO posts \n          (author_id, community_challenge_id, title, description, post_type, metadata)\n          VALUES ($1, $2, $3, $4, $5, $6)\n        `,\n          [\n            dto.creator_id,\n            challenge.id,\n            postTitle,\n            postDescription,\n            \"community_challenge\",\n            JSON.stringify({\n              challenge_id: challenge.id,\n              type: challenge.type,\n              frequency: challenge.frequency,\n              difficulty: challenge.difficulty,\n              category: challenge.category,\n              goal_value: challenge.goal_value,\n              deadline: challenge.deadline,\n            }),\n          ],\n        );\n\n        this.logger.log(`✅ Auto-created post for challenge: ${challenge.id}`);\n      } catch (postError) {\n        this.logger.error(\n          \"⚠️ Failed to auto-create post (continuing anyway)\",\n          postError,\n        );\n        // Don't fail challenge creation if post creation fails\n      }\n\n      // 3. Auto-join the creator to their own challenge\n      await client.query(\n        `\n        INSERT INTO community_challenge_participants \n        (challenge_id, user_id, joined_at)\n        VALUES ($1, $2, NOW())\n      `,\n        [challenge.id, dto.creator_id],\n      );\n\n      // Update participants count\n      await client.query(\n        `\n        UPDATE community_group_challenges \n        SET participants_count = 1 \n        WHERE id = $1\n      `,\n        [challenge.id],\n      );\n\n      await client.query(\"COMMIT\");\n\n      this.logger.log(`✅ Challenge created successfully: ${challenge.id}`);\n      return { success: true, data: challenge };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Error creating challenge:\", error);\n      throw new InternalServerErrorException(\n        `Failed to create challenge: ${error.message || \"Unknown error\"}`,\n      );\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get list of challenges with optional filters\n   */\n  @Get()\n  async getChallenges(@Query() filters: GetChallengesFilterDto) {\n    this.logger.log(\"Fetching challenges with filters:\", filters);\n\n    const client = await this.pool.connect();\n    try {\n      let query = `\n        SELECT \n          c.*,\n          u.name as creator_name,\n          u.avatar_url as creator_avatar\n        FROM community_group_challenges c\n        LEFT JOIN user_profiles u ON c.creator_id = u.id\n        WHERE 1=1\n      `;\n      const params: any[] = [];\n      let paramCount = 1;\n\n      // Apply filters\n      if (filters.type) {\n        query += ` AND c.type = $${paramCount}`;\n        params.push(filters.type);\n        paramCount++;\n      }\n\n      if (filters.frequency) {\n        query += ` AND c.frequency = $${paramCount}`;\n        params.push(filters.frequency);\n        paramCount++;\n      }\n\n      if (filters.difficulty) {\n        query += ` AND c.difficulty = $${paramCount}`;\n        params.push(filters.difficulty);\n        paramCount++;\n      }\n\n      if (filters.category) {\n        query += ` AND c.category = $${paramCount}`;\n        params.push(filters.category);\n        paramCount++;\n      }\n\n      if (filters.is_active !== undefined) {\n        query += ` AND c.is_active = $${paramCount}`;\n        params.push(filters.is_active);\n        paramCount++;\n      }\n\n      if (filters.creator_id) {\n        query += ` AND c.creator_id = $${paramCount}`;\n        params.push(filters.creator_id);\n        paramCount++;\n      }\n\n      if (filters.search) {\n        query += ` AND (c.title ILIKE $${paramCount} OR c.description ILIKE $${paramCount})`;\n        params.push(`%${filters.search}%`);\n        paramCount++;\n      }\n\n      // Sorting\n      const sortBy = filters.sort_by || \"created_at\";\n      const sortOrder = filters.sort_order || \"DESC\";\n      query += ` ORDER BY c.${sortBy} ${sortOrder}`;\n\n      // Pagination\n      const limit = filters.limit || 50;\n      const offset = filters.offset || 0;\n      query += ` LIMIT $${paramCount} OFFSET $${paramCount + 1}`;\n      params.push(limit, offset);\n\n      const { rows } = await client.query(query, params);\n\n      return { success: true, data: rows, count: rows.length };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching challenges:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch challenges\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get daily tracker data - all DAILY challenges user participates in with entries\n   * Query params: user_id, start_date (YYYY-MM-DD), end_date (YYYY-MM-DD)\n   */\n  @Get(\"daily-tracker\")\n  async getDailyTrackerData(\n    @Query(\"user_id\") userId: string,\n    @Query(\"start_date\") startDate?: string,\n    @Query(\"end_date\") endDate?: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"user_id is required\");\n    }\n\n    this.logger.log(\n      `Fetching daily tracker for user ${userId}, range: ${startDate} - ${endDate}`,\n    );\n\n    const client = await this.pool.connect();\n    try {\n      // Default to current week if not specified\n      const today = new Date().toISOString().split(\"T\")[0];\n      const start =\n        startDate ||\n        new Date(Date.now() - 6 * 24 * 60 * 60 * 1000)\n          .toISOString()\n          .split(\"T\")[0];\n      const end = endDate || today;\n\n      // Get all DAILY challenges the user participates in\n      const { rows: challenges } = await client.query(\n        `\n        SELECT \n          c.*,\n          p.current_streak,\n          p.best_streak,\n          p.total_entries,\n          p.last_entry_date,\n          p.id as participant_id\n        FROM community_group_challenges c\n        INNER JOIN community_challenge_participants p ON c.id = p.challenge_id\n        WHERE p.user_id = $1 \n          AND c.frequency = 'DAILY'\n          AND c.is_active = true\n        ORDER BY c.title\n      `,\n        [userId],\n      );\n\n      if (challenges.length === 0) {\n        return {\n          success: true,\n          data: {\n            challenges: [],\n            entries_by_date: {},\n            stats: {\n              total_success_rate: null,\n              total_days_tracked: 0,\n            },\n          },\n        };\n      }\n\n      const challengeIds = challenges.map((c) => c.id);\n\n      // Get all entries for these challenges in the date range\n      const { rows: entries } = await client.query(\n        `\n        SELECT \n          challenge_id,\n          entry_date,\n          value,\n          notes,\n          created_at\n        FROM community_challenge_entries\n        WHERE user_id = $1 \n          AND challenge_id = ANY($2)\n          AND entry_date >= $3 \n          AND entry_date <= $4\n        ORDER BY entry_date DESC\n      `,\n        [userId, challengeIds, start, end],\n      );\n\n      // Helper function to calculate entry status\n      const calculateStatus = (challenge: any, value: number): string => {\n        if (challenge.type === \"BOOLEAN\") {\n          const numValue = Number(value);\n          const result = numValue === 1 ? \"success\" : \"failed\";\n          this.logger.log(\n            `BOOLEAN status calc: challenge=${challenge.id}, value=${value} (type=${typeof value}), numValue=${numValue}, result=${result}`,\n          );\n          return result;\n        }\n\n        // NUMERIC or DURATION\n        if (!challenge.goal_value || !challenge.goal_direction) {\n          return \"neutral\";\n        }\n\n        if (challenge.goal_direction === \"maximize\") {\n          return value >= challenge.goal_value ? \"success\" : \"failed\";\n        } else if (challenge.goal_direction === \"minimize\") {\n          return value < challenge.goal_value ? \"success\" : \"failed\";\n        }\n\n        return \"neutral\";\n      };\n\n      // Organize entries by date\n      const entriesByDate: any = {};\n      let totalSuccess = 0;\n      let totalFailed = 0;\n\n      entries.forEach((entry) => {\n        const raw = entry.entry_date;\n        let dateKey: string;\n        if (typeof raw === \"string\") {\n          dateKey = raw.split(\"T\")[0];\n        } else if (raw instanceof Date) {\n          const d = raw;\n          dateKey = `${d.getUTCFullYear()}-${String(d.getUTCMonth() + 1).padStart(2, \"0\")}-${String(d.getUTCDate()).padStart(2, \"0\")}`;\n          this.logger.log(\n            `Date conversion: raw=${raw.toISOString()}, dateKey=${dateKey}`,\n          );\n        } else {\n          dateKey = String(raw).split(\"T\")[0];\n        }\n        if (!entriesByDate[dateKey]) {\n          entriesByDate[dateKey] = {};\n        }\n\n        const challenge = challenges.find((c) => c.id === entry.challenge_id);\n        const status = calculateStatus(challenge, entry.value);\n\n        if (status === \"success\") totalSuccess++;\n        else if (status === \"failed\") totalFailed++;\n\n        entriesByDate[dateKey][entry.challenge_id] = {\n          value: entry.value,\n          notes: entry.notes,\n          status,\n          created_at: entry.created_at,\n        };\n      });\n\n      // Calculate stats\n      const totalEntries = totalSuccess + totalFailed;\n      const successRate =\n        totalEntries > 0 ? (totalSuccess / totalEntries) * 100 : null;\n\n      // Format challenges with participant data\n      const formattedChallenges = challenges.map((c) => ({\n        id: c.id,\n        title: c.title,\n        description: c.description,\n        image_url: c.image_url,\n        type: c.type,\n        frequency: c.frequency,\n        goal_value: c.goal_value,\n        goal_direction: c.goal_direction,\n        difficulty: c.difficulty,\n        category: c.category,\n        participant_data: {\n          current_streak: c.current_streak,\n          best_streak: c.best_streak,\n          total_entries: c.total_entries,\n          last_entry_date: c.last_entry_date,\n        },\n      }));\n\n      this.logger.log(\n        `✅ Fetched tracker data: ${challenges.length} challenges, ${entries.length} entries`,\n      );\n\n      return {\n        success: true,\n        data: {\n          challenges: formattedChallenges,\n          entries_by_date: entriesByDate,\n          stats: {\n            total_success_rate: successRate,\n            total_days_tracked: Object.keys(entriesByDate).length,\n          },\n        },\n      };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching daily tracker:\", error);\n      throw new InternalServerErrorException(\n        \"Failed to fetch daily tracker data\",\n      );\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get a specific challenge by ID with full details\n   */\n  @Get(\":id\")\n  async getChallengeById(@Param(\"id\") id: string) {\n    this.logger.log(`Fetching challenge: ${id}`);\n\n    const client = await this.pool.connect();\n    try {\n      // Get challenge with creator info and post_id\n      const {\n        rows: [challenge],\n      } = await client.query(\n        `\n        SELECT \n          c.*,\n          u.name as creator_name,\n          u.avatar_url as creator_avatar,\n          p.id as post_id\n        FROM community_group_challenges c\n        LEFT JOIN user_profiles u ON c.creator_id = u.id\n        LEFT JOIN posts p ON p.community_challenge_id = c.id\n        WHERE c.id = $1\n      `,\n        [id],\n      );\n\n      if (!challenge) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      // Get participants (top 10)\n      const { rows: participants } = await client.query(\n        `\n        SELECT \n          p.*,\n          u.name as user_name,\n          u.avatar_url as user_avatar\n        FROM community_challenge_participants p\n        LEFT JOIN user_profiles u ON p.user_id = u.id\n        WHERE p.challenge_id = $1\n        ORDER BY p.best_streak DESC, p.joined_at ASC\n        LIMIT 10\n      `,\n        [id],\n      );\n\n      return {\n        success: true,\n        data: {\n          ...challenge,\n          participants,\n        },\n      };\n    } catch (error: any) {\n      if (error instanceof NotFoundException) throw error;\n      this.logger.error(\"Error fetching challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Join a challenge\n   */\n  @Post(\":id/join\")\n  async joinChallenge(\n    @Param(\"id\") challengeId: string,\n    @Body() dto: JoinChallengeDto,\n  ) {\n    this.logger.log(`User ${dto.user_id} joining challenge ${challengeId}`);\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Check if challenge exists and is active\n      const {\n        rows: [challenge],\n      } = await client.query(\n        `\n        SELECT id, is_active FROM community_group_challenges WHERE id = $1\n      `,\n        [challengeId],\n      );\n\n      if (!challenge) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      if (!challenge.is_active) {\n        throw new BadRequestException(\"Challenge is not active\");\n      }\n\n      // Check if already joined\n      const { rows: existing } = await client.query(\n        `\n        SELECT id FROM community_challenge_participants \n        WHERE challenge_id = $1 AND user_id = $2\n      `,\n        [challengeId, dto.user_id],\n      );\n\n      if (existing.length > 0) {\n        throw new BadRequestException(\"Already joined this challenge\");\n      }\n\n      // Join the challenge\n      const {\n        rows: [participant],\n      } = await client.query(\n        `\n        INSERT INTO community_challenge_participants \n        (challenge_id, user_id, joined_at)\n        VALUES ($1, $2, NOW())\n        RETURNING *\n      `,\n        [challengeId, dto.user_id],\n      );\n\n      // Increment participants count\n      await client.query(\n        `\n        UPDATE community_group_challenges \n        SET participants_count = participants_count + 1 \n        WHERE id = $1\n      `,\n        [challengeId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      this.logger.log(`✅ User joined challenge successfully`);\n      return { success: true, data: participant };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      if (\n        error instanceof NotFoundException ||\n        error instanceof BadRequestException\n      )\n        throw error;\n      this.logger.error(\"Error joining challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to join challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Add a challenge entry (daily progress)\n   * Also calculates and updates streak\n   */\n  @Post(\":id/entries\")\n  async addChallengeEntry(\n    @Param(\"id\") challengeId: string,\n    @Body() dto: CreateChallengeEntryDto,\n  ) {\n    this.logger.log(\n      `Adding entry for challenge ${challengeId}, user ${dto.user_id}, date=${dto.entry_date ?? \"today\"}, value=${dto.value}`,\n    );\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Check if user is a participant\n      const {\n        rows: [participant],\n      } = await client.query(\n        `\n        SELECT * FROM community_challenge_participants \n        WHERE challenge_id = $1 AND user_id = $2\n      `,\n        [challengeId, dto.user_id],\n      );\n\n      if (!participant) {\n        this.logger.warn(\n          `Entry rejected: user ${dto.user_id} is not participant of challenge ${challengeId}`,\n        );\n        throw new BadRequestException(\n          \"User is not a participant of this challenge\",\n        );\n      }\n\n      // Determine entry date (today if not specified)\n      const entryDate =\n        dto.entry_date || new Date().toISOString().split(\"T\")[0];\n      this.logger.log(\n        `Entry date resolved to: ${entryDate} (received: ${dto.entry_date}, value: ${dto.value}, type: ${typeof dto.value})`,\n      );\n\n      // Check if entry already exists (to avoid incrementing total_entries on update)\n      const {\n        rows: [existingEntry],\n      } = await client.query(\n        `\n        SELECT 1 FROM community_challenge_entries \n        WHERE challenge_id = $1 AND user_id = $2 AND entry_date = $3\n      `,\n        [challengeId, dto.user_id, entryDate],\n      );\n\n      const isNewEntry = !existingEntry;\n      this.logger.log(\n        `Entry ${isNewEntry ? \"create\" : \"update\"} for ${challengeId}, date=${entryDate}, value=${dto.value}`,\n      );\n\n      // Insert or update entry\n      await client.query(\n        `\n        INSERT INTO community_challenge_entries \n        (challenge_id, user_id, entry_date, value, notes)\n        VALUES ($1, $2, $3, $4, $5)\n        ON CONFLICT (challenge_id, user_id, entry_date) \n        DO UPDATE SET value = $4, notes = $5\n      `,\n        [challengeId, dto.user_id, entryDate, dto.value, dto.notes || null],\n      );\n\n      // Calculate streak using SQL window function\n      const { rows } = await client.query(\n        `\n        WITH daily_entries AS (\n          SELECT entry_date::date\n          FROM community_challenge_entries\n          WHERE challenge_id = $1 AND user_id = $2\n          ORDER BY entry_date DESC\n        ),\n        streak_calc AS (\n          SELECT \n            entry_date,\n            entry_date - (ROW_NUMBER() OVER (ORDER BY entry_date DESC))::int AS grp\n          FROM daily_entries\n        )\n        SELECT COUNT(*) as current_streak\n        FROM streak_calc\n        WHERE grp = (SELECT grp FROM streak_calc LIMIT 1)\n      `,\n        [challengeId, dto.user_id],\n      );\n\n      const currentStreak = rows[0]?.current_streak || 0;\n\n      // Update participant stats (only increment total_entries if new entry)\n      await client.query(\n        `\n        UPDATE community_challenge_participants\n        SET \n          current_streak = $3,\n          best_streak = GREATEST(best_streak, $3),\n          total_entries = total_entries + $4,\n          last_entry_date = $5\n        WHERE challenge_id = $1 AND user_id = $2\n      `,\n        [\n          challengeId,\n          dto.user_id,\n          currentStreak,\n          isNewEntry ? 1 : 0,\n          entryDate,\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n\n      this.logger.log(`✅ Entry added successfully. Streak: ${currentStreak}`);\n      return {\n        success: true,\n        data: {\n          entry_date: entryDate,\n          value: dto.value,\n          current_streak: currentStreak,\n        },\n      };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      if (error instanceof BadRequestException) throw error;\n      this.logger.error(\"Error adding entry:\", error);\n      throw new InternalServerErrorException(\"Failed to add entry\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get entries history for a challenge and user\n   */\n  @Get(\":id/entries\")\n  async getChallengeEntries(\n    @Param(\"id\") challengeId: string,\n    @Query(\"user_id\") userId: string,\n    @Query(\"limit\") limit?: number,\n    @Query(\"offset\") offset?: number,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"user_id is required\");\n    }\n\n    this.logger.log(\n      `Fetching entries for challenge ${challengeId}, user ${userId}`,\n    );\n\n    const client = await this.pool.connect();\n    try {\n      const actualLimit = limit || 100;\n      const actualOffset = offset || 0;\n\n      const { rows } = await client.query(\n        `\n        SELECT * FROM community_challenge_entries\n        WHERE challenge_id = $1 AND user_id = $2\n        ORDER BY entry_date DESC\n        LIMIT $3 OFFSET $4\n      `,\n        [challengeId, userId, actualLimit, actualOffset],\n      );\n\n      return { success: true, data: rows, count: rows.length };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching entries:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch entries\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get user statistics across all challenges\n   */\n  @Get(\"user/:userId/stats\")\n  async getUserStatistics(@Param(\"userId\") userId: string) {\n    this.logger.log(`Fetching statistics for user ${userId}`);\n\n    const client = await this.pool.connect();\n    try {\n      // Overall stats\n      const {\n        rows: [overallStats],\n      } = await client.query(\n        `\n        SELECT \n          COUNT(DISTINCT challenge_id) as active_challenges,\n          SUM(total_entries) as total_entries,\n          MAX(best_streak) as best_streak_overall,\n          AVG(current_streak) as avg_current_streak\n        FROM community_challenge_participants\n        WHERE user_id = $1\n      `,\n        [userId],\n      );\n\n      // Per-challenge stats\n      const { rows: challengeStats } = await client.query(\n        `\n        SELECT \n          p.*,\n          c.title,\n          c.type,\n          c.frequency,\n          c.difficulty,\n          c.category,\n          c.goal_value,\n          c.deadline\n        FROM community_challenge_participants p\n        LEFT JOIN community_group_challenges c ON p.challenge_id = c.id\n        WHERE p.user_id = $1\n        ORDER BY p.current_streak DESC, p.joined_at DESC\n      `,\n        [userId],\n      );\n\n      return {\n        success: true,\n        data: {\n          overall: overallStats,\n          challenges: challengeStats,\n        },\n      };\n    } catch (error: any) {\n      this.logger.error(\"Error fetching user statistics:\", error);\n      throw new InternalServerErrorException(\"Failed to fetch statistics\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Update a challenge (creator only)\n   */\n  @Put(\":id\")\n  async updateChallenge(\n    @Param(\"id\") challengeId: string,\n    @Body() dto: UpdateCommunityGroupChallengeDto,\n    @Query(\"user_id\") userId: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"user_id is required\");\n    }\n\n    this.logger.log(`Updating challenge ${challengeId}`);\n\n    const client = await this.pool.connect();\n    try {\n      // Verify user is the creator\n      const {\n        rows: [challenge],\n      } = await client.query(\n        `\n        SELECT creator_id FROM community_group_challenges WHERE id = $1\n      `,\n        [challengeId],\n      );\n\n      if (!challenge) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      if (challenge.creator_id !== userId) {\n        throw new BadRequestException(\n          \"Only the creator can update this challenge\",\n        );\n      }\n\n      // Build dynamic update query\n      const updates: string[] = [];\n      const values: any[] = [];\n      let paramCount = 1;\n\n      if (dto.title !== undefined) {\n        updates.push(`title = $${paramCount}`);\n        values.push(dto.title);\n        paramCount++;\n      }\n\n      if (dto.description !== undefined) {\n        updates.push(`description = $${paramCount}`);\n        values.push(dto.description);\n        paramCount++;\n      }\n\n      if (dto.image_url !== undefined) {\n        updates.push(`image_url = $${paramCount}`);\n        values.push(dto.image_url);\n        paramCount++;\n      }\n\n      if (dto.goal_value !== undefined) {\n        updates.push(`goal_value = $${paramCount}`);\n        values.push(dto.goal_value);\n        paramCount++;\n      }\n\n      if (dto.deadline !== undefined) {\n        updates.push(`deadline = $${paramCount}`);\n        values.push(dto.deadline);\n        paramCount++;\n      }\n\n      if (dto.difficulty !== undefined) {\n        updates.push(`difficulty = $${paramCount}`);\n        values.push(dto.difficulty);\n        paramCount++;\n      }\n\n      if (dto.category !== undefined) {\n        updates.push(`category = $${paramCount}`);\n        values.push(dto.category);\n        paramCount++;\n      }\n\n      if (dto.is_active !== undefined) {\n        updates.push(`is_active = $${paramCount}`);\n        values.push(dto.is_active);\n        paramCount++;\n      }\n\n      if (dto.goal_direction !== undefined) {\n        updates.push(`goal_direction = $${paramCount}`);\n        values.push(dto.goal_direction);\n        paramCount++;\n      }\n\n      if (updates.length === 0) {\n        throw new BadRequestException(\"No fields to update\");\n      }\n\n      updates.push(`updated_at = NOW()`);\n      values.push(challengeId);\n\n      const {\n        rows: [updated],\n      } = await client.query(\n        `\n        UPDATE community_group_challenges \n        SET ${updates.join(\", \")}\n        WHERE id = $${paramCount}\n        RETURNING *\n      `,\n        values,\n      );\n\n      this.logger.log(`✅ Challenge updated successfully`);\n      return { success: true, data: updated };\n    } catch (error: any) {\n      if (\n        error instanceof NotFoundException ||\n        error instanceof BadRequestException\n      )\n        throw error;\n      this.logger.error(\"Error updating challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to update challenge\");\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Delete a challenge (creator only)\n   */\n  @Delete(\":id\")\n  async deleteChallenge(\n    @Param(\"id\") challengeId: string,\n    @Query(\"user_id\") userId: string,\n  ) {\n    if (!userId) {\n      throw new BadRequestException(\"user_id is required\");\n    }\n\n    this.logger.log(`Deleting challenge ${challengeId}`);\n\n    const client = await this.pool.connect();\n    try {\n      // Verify user is the creator\n      const {\n        rows: [challenge],\n      } = await client.query(\n        `\n        SELECT creator_id FROM community_group_challenges WHERE id = $1\n      `,\n        [challengeId],\n      );\n\n      if (!challenge) {\n        throw new NotFoundException(\"Challenge not found\");\n      }\n\n      if (challenge.creator_id !== userId) {\n        throw new BadRequestException(\n          \"Only the creator can delete this challenge\",\n        );\n      }\n\n      // Delete cascade will handle participants and entries\n      await client.query(\n        `\n        DELETE FROM community_group_challenges WHERE id = $1\n      `,\n        [challengeId],\n      );\n\n      this.logger.log(`✅ Challenge deleted successfully`);\n      return { success: true, message: \"Challenge deleted\" };\n    } catch (error: any) {\n      if (\n        error instanceof NotFoundException ||\n        error instanceof BadRequestException\n      )\n        throw error;\n      this.logger.error(\"Error deleting challenge:\", error);\n      throw new InternalServerErrorException(\"Failed to delete challenge\");\n    } finally {\n      client.release();\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/community-members.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":30,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":30,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[799,802],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[799,802],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":43,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":43,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1024,1027],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1024,1027],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":215,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":215,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6173,6176],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6173,6176],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":360,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":360,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9843,9846],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9843,9846],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: CRUD עבור ניהול אנשים בקהילה - רשומות של אנשים והתפקיד/התרומה שלהם\n// - Routes: /api/community-members (GET, POST), /api/community-members/:id (GET, PATCH, DELETE)\n// - Storage: PostgreSQL טבלת community_members (schema.sql)\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Patch,\n  Post,\n  Query,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\ntype MemberStatus = \"active\" | \"inactive\";\n\ninterface CreateMemberDto {\n  name: string;\n  role: string; // התפקיד/התרומה שלו לקהילה\n  description?: string;\n  contact_info?: {\n    email?: string;\n    phone?: string;\n    [key: string]: any;\n  };\n  status?: MemberStatus;\n  created_by?: string;\n}\n\ninterface UpdateMemberDto {\n  name?: string;\n  role?: string;\n  description?: string;\n  contact_info?: {\n    email?: string;\n    phone?: string;\n    [key: string]: any;\n  };\n  status?: MemberStatus;\n}\n\n@Controller(\"/api/community-members\")\nexport class CommunityMembersController {\n  private readonly logger = new Logger(CommunityMembersController.name);\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  /**\n   * Resolve any user identifier (email, firebase_uid, UUID string) to UUID\n   * This ensures all user IDs are converted to UUID format before use\n   * NOTE: We only use our own UUID (user_profiles.id) for user identification\n   */\n  private async resolveUserIdToUUID(userId: string): Promise<string | null> {\n    if (!userId) {\n      return null;\n    }\n\n    // Check if it's already a valid UUID\n    const uuidRegex =\n      /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n    if (uuidRegex.test(userId)) {\n      // Verify it exists in user_profiles\n      const result = await this.pool.query(\n        `SELECT id FROM user_profiles WHERE id = $1::uuid LIMIT 1`,\n        [userId],\n      );\n      if (result.rows.length > 0) {\n        return userId;\n      }\n    }\n\n    // Try to find user by email or firebase_uid ONLY\n    const result = await this.pool.query(\n      `SELECT id FROM user_profiles \n       WHERE LOWER(email) = LOWER($1) \n          OR firebase_uid = $1 \n          OR id::text = $1\n       LIMIT 1`,\n      [userId],\n    );\n\n    if (result.rows.length > 0) {\n      return result.rows[0].id;\n    }\n\n    return null;\n  }\n\n  /**\n   * Ensure community_members table exists, create it if missing\n   */\n  private async ensureTable() {\n    try {\n      const checkTable = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'community_members'\n        );\n      `);\n\n      const tableExists = checkTable.rows[0].exists;\n\n      if (!tableExists) {\n        this.logger.log(\"📋 Creating community_members table...\");\n\n        // Create extension if needed\n        try {\n          await this.pool.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"');\n        } catch (extError) {\n          this.logger.warn(\n            \"⚠️ Could not create uuid-ossp extension:\",\n            extError,\n          );\n        }\n\n        // Create the table\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS community_members (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            name VARCHAR(255) NOT NULL,\n            role VARCHAR(255) NOT NULL,\n            description TEXT,\n            contact_info JSONB,\n            status VARCHAR(20) DEFAULT 'active',\n            created_by UUID, -- REFERENCES user_profiles(id), -- UUID to match user_profiles.id type\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          )\n        `);\n\n        // Create indexes\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_community_members_name ON community_members (name)\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_community_members_role ON community_members (role)\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_community_members_status ON community_members (status)\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_community_members_created_at ON community_members (created_at DESC)\",\n        );\n\n        // Create trigger function if it doesn't exist\n        await this.pool.query(`\n          CREATE OR REPLACE FUNCTION update_updated_at_column()\n          RETURNS TRIGGER AS $$\n          BEGIN\n            NEW.updated_at = NOW();\n            RETURN NEW;\n          END;\n          $$ language 'plpgsql'\n        `);\n\n        // Create trigger\n        await this.pool.query(\n          \"DROP TRIGGER IF EXISTS update_community_members_updated_at ON community_members\",\n        );\n        await this.pool.query(`\n          CREATE TRIGGER update_community_members_updated_at \n          BEFORE UPDATE ON community_members \n          FOR EACH ROW \n          EXECUTE FUNCTION update_updated_at_column()\n        `);\n\n        this.logger.log(\"✅ community_members table created successfully\");\n      }\n    } catch (error) {\n      this.logger.error(\"❌ Error ensuring community_members table:\", error);\n      // Don't throw - let the query fail naturally if table doesn't exist\n    }\n  }\n\n  @Get()\n  async getAllMembers(\n    @Query(\"status\") status?: string,\n    @Query(\"search\") search?: string,\n  ) {\n    await this.ensureTable();\n\n    const cacheKey = `community_members_list_${status || \"all\"}_${search || \"\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    try {\n      let query = `\n        SELECT \n          id,\n          name,\n          role,\n          description,\n          contact_info,\n          status,\n          created_by,\n          created_at,\n          updated_at\n        FROM community_members\n        WHERE 1=1\n      `;\n      const params: any[] = [];\n      let paramIndex = 1;\n\n      if (status) {\n        query += ` AND status = $${paramIndex}`;\n        params.push(status);\n        paramIndex++;\n      }\n\n      if (search) {\n        query += ` AND (name ILIKE $${paramIndex} OR role ILIKE $${paramIndex} OR description ILIKE $${paramIndex})`;\n        params.push(`%${search}%`);\n        paramIndex++;\n      }\n\n      query += ` ORDER BY created_at DESC`;\n\n      const { rows } = await this.pool.query(query, params);\n\n      await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error fetching community members:\", error);\n      return {\n        success: false,\n        error: \"Failed to fetch community members\",\n        data: [],\n      };\n    }\n  }\n\n  @Get(\":id\")\n  async getMemberById(@Param(\"id\") id: string) {\n    await this.ensureTable();\n\n    const cacheKey = `community_member_${id}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    try {\n      const { rows } = await this.pool.query(\n        `SELECT \n          id,\n          name,\n          role,\n          description,\n          contact_info,\n          status,\n          created_by,\n          created_at,\n          updated_at\n        FROM community_members \n        WHERE id = $1`,\n        [id],\n      );\n\n      if (rows.length === 0) {\n        return {\n          success: false,\n          error: \"Member not found\",\n        };\n      }\n\n      await this.redisCache.set(cacheKey, rows[0], this.CACHE_TTL);\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error fetching community member:\", error);\n      return {\n        success: false,\n        error: \"Failed to fetch community member\",\n      };\n    }\n  }\n\n  @Post()\n  async createMember(@Body() dto: CreateMemberDto) {\n    await this.ensureTable();\n\n    try {\n      // Validate required fields\n      if (!dto.name || !dto.role) {\n        return {\n          success: false,\n          error: \"Name and role are required\",\n        };\n      }\n\n      // Resolve created_by to UUID if provided\n      let createdByUuid: string | null = null;\n      if (dto.created_by) {\n        createdByUuid = await this.resolveUserIdToUUID(dto.created_by);\n        if (!createdByUuid) {\n          this.logger.warn(\n            `⚠️ Could not resolve created_by user: ${dto.created_by}`,\n          );\n        }\n      }\n\n      const { rows } = await this.pool.query(\n        `INSERT INTO community_members (name, role, description, contact_info, status, created_by)\n         VALUES ($1, $2, $3, $4, $5, $6::UUID)\n         RETURNING \n           id,\n           name,\n           role,\n           description,\n           contact_info,\n           status,\n           created_by,\n           created_at,\n           updated_at`,\n        [\n          dto.name,\n          dto.role,\n          dto.description || null,\n          dto.contact_info ? JSON.stringify(dto.contact_info) : null,\n          dto.status || \"active\",\n          createdByUuid,\n        ],\n      );\n\n      // Invalidate cache\n      await this.redisCache.invalidatePattern(\"community_members_list_*\");\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error creating community member:\", error);\n      return {\n        success: false,\n        error: \"Failed to create community member\",\n      };\n    }\n  }\n\n  @Patch(\":id\")\n  async updateMember(@Param(\"id\") id: string, @Body() dto: UpdateMemberDto) {\n    await this.ensureTable();\n\n    try {\n      const updates: string[] = [];\n      const params: any[] = [];\n      let paramIndex = 1;\n\n      if (dto.name !== undefined) {\n        updates.push(`name = $${paramIndex}`);\n        params.push(dto.name);\n        paramIndex++;\n      }\n\n      if (dto.role !== undefined) {\n        updates.push(`role = $${paramIndex}`);\n        params.push(dto.role);\n        paramIndex++;\n      }\n\n      if (dto.description !== undefined) {\n        updates.push(`description = $${paramIndex}`);\n        params.push(dto.description);\n        paramIndex++;\n      }\n\n      if (dto.contact_info !== undefined) {\n        updates.push(`contact_info = $${paramIndex}`);\n        params.push(JSON.stringify(dto.contact_info));\n        paramIndex++;\n      }\n\n      if (dto.status !== undefined) {\n        updates.push(`status = $${paramIndex}`);\n        params.push(dto.status);\n        paramIndex++;\n      }\n\n      if (updates.length === 0) {\n        return {\n          success: false,\n          error: \"No fields to update\",\n        };\n      }\n\n      params.push(id);\n      const { rows } = await this.pool.query(\n        `UPDATE community_members \n         SET ${updates.join(\", \")}\n         WHERE id = $${paramIndex}\n         RETURNING \n           id,\n           name,\n           role,\n           description,\n           contact_info,\n           status,\n           created_by,\n           created_at,\n           updated_at`,\n        params,\n      );\n\n      if (rows.length === 0) {\n        return {\n          success: false,\n          error: \"Member not found\",\n        };\n      }\n\n      // Invalidate cache\n      await this.redisCache.delete(`community_member_${id}`);\n      await this.redisCache.invalidatePattern(\"community_members_list_*\");\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error updating community member:\", error);\n      return {\n        success: false,\n        error: \"Failed to update community member\",\n      };\n    }\n  }\n\n  @Delete(\":id\")\n  async deleteMember(@Param(\"id\") id: string) {\n    await this.ensureTable();\n\n    try {\n      const { rows } = await this.pool.query(\n        `DELETE FROM community_members \n         WHERE id = $1\n         RETURNING id`,\n        [id],\n      );\n\n      if (rows.length === 0) {\n        return {\n          success: false,\n          error: \"Member not found\",\n        };\n      }\n\n      // Invalidate cache\n      await this.redisCache.delete(`community_member_${id}`);\n      await this.redisCache.invalidatePattern(\"community_members_list_*\");\n\n      return { success: true, message: \"Member deleted successfully\" };\n    } catch (error) {\n      this.logger.error(\"Error deleting community member:\", error);\n      return {\n        success: false,\n        error: \"Failed to delete community member\",\n      };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/crm.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":122,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":122,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3394,3397],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3394,3397],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":191,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":191,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5552,5555],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5552,5555],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Patch,\n  Post,\n  Query,\n  Inject,\n  Logger,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\ninterface CreateContactDto {\n  name: string;\n  capabilities?: string;\n  desire?: string;\n  time_availability?: string;\n  source?: string; // Where they came from\n  referrer?: string; // Who brought them\n  status?: \"active\" | \"inactive\";\n  created_by?: string;\n}\n\ninterface UpdateContactDto {\n  name?: string;\n  capabilities?: string;\n  desire?: string;\n  time_availability?: string;\n  source?: string;\n  referrer?: string;\n  status?: \"active\" | \"inactive\";\n}\n\n@Controller(\"/api/crm\")\nexport class CrmController {\n  private readonly logger = new Logger(CrmController.name);\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  private async ensureTable() {\n    try {\n      const checkTable = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'crm_contacts'\n        );\n      `);\n\n      if (!checkTable.rows[0].exists) {\n        this.logger.log(\"📋 Creating crm_contacts table...\");\n        await this.pool.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"');\n\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS crm_contacts (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            name VARCHAR(255) NOT NULL,\n            capabilities TEXT,\n            desire TEXT,\n            time_availability TEXT,\n            source VARCHAR(255),\n            referrer VARCHAR(255),\n            status VARCHAR(20) DEFAULT 'active',\n            created_by UUID,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          )\n        `);\n\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_crm_contacts_name ON crm_contacts (name)\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_crm_contacts_status ON crm_contacts (status)\",\n        );\n\n        // Trigger for updated_at\n        await this.pool.query(`\n           DO $$\n           BEGIN\n               IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_crm_contacts_updated_at') THEN\n                   CREATE TRIGGER update_crm_contacts_updated_at \n                   BEFORE UPDATE ON crm_contacts \n                   FOR EACH ROW \n                   EXECUTE FUNCTION update_updated_at_column();\n               END IF;\n           END\n           $$;\n        `);\n\n        this.logger.log(\"✅ crm_contacts table created successfully\");\n      }\n    } catch (error) {\n      this.logger.error(\"❌ Error ensuring crm_contacts table:\", error);\n    }\n  }\n\n  @Get()\n  async getAllContacts(\n    @Query(\"status\") status?: string,\n    @Query(\"search\") search?: string,\n  ) {\n    await this.ensureTable();\n\n    const cacheKey = `crm_contacts_list_${status || \"all\"}_${search || \"\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    try {\n      let query = `SELECT * FROM crm_contacts WHERE 1=1`;\n      const params: any[] = [];\n      let paramIndex = 1;\n\n      if (status) {\n        query += ` AND status = $${paramIndex}`;\n        params.push(status);\n        paramIndex++;\n      }\n\n      if (search) {\n        query += ` AND (name ILIKE $${paramIndex} OR capabilities ILIKE $${paramIndex} OR source ILIKE $${paramIndex})`;\n        params.push(`%${search}%`);\n        paramIndex++;\n      }\n\n      query += ` ORDER BY created_at DESC`;\n\n      const { rows } = await this.pool.query(query, params);\n      await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error fetching CRM contacts:\", error);\n      return { success: false, error: \"Failed to fetch contacts\", data: [] };\n    }\n  }\n\n  @Post()\n  async createContact(@Body() dto: CreateContactDto) {\n    await this.ensureTable();\n\n    try {\n      if (!dto.name) {\n        return { success: false, error: \"Name is required\" };\n      }\n\n      // Simple handling for created_by - assuming it's passed as UUID or handled by frontend\n      // In a real scenario, we'd validate the user UUID.\n\n      const { rows } = await this.pool.query(\n        `INSERT INTO crm_contacts (name, capabilities, desire, time_availability, source, referrer, status, created_by)\n         VALUES ($1, $2, $3, $4, $5, $6, $7, $8::UUID)\n         RETURNING *`,\n        [\n          dto.name,\n          dto.capabilities || null,\n          dto.desire || null,\n          dto.time_availability || null,\n          dto.source || null,\n          dto.referrer || null,\n          dto.status || \"active\",\n          dto.created_by || null, // Assuming UUID string or null\n        ],\n      );\n\n      await this.redisCache.invalidatePattern(\"crm_contacts_list_*\");\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error creating CRM contact:\", error);\n      return { success: false, error: \"Failed to create contact\" };\n    }\n  }\n\n  @Patch(\":id\")\n  async updateContact(@Param(\"id\") id: string, @Body() dto: UpdateContactDto) {\n    await this.ensureTable();\n\n    try {\n      const updates: string[] = [];\n      const params: any[] = [];\n      let paramIndex = 1;\n\n      if (dto.name !== undefined) {\n        updates.push(`name = $${paramIndex}`);\n        params.push(dto.name);\n        paramIndex++;\n      }\n      if (dto.capabilities !== undefined) {\n        updates.push(`capabilities = $${paramIndex}`);\n        params.push(dto.capabilities);\n        paramIndex++;\n      }\n      if (dto.desire !== undefined) {\n        updates.push(`desire = $${paramIndex}`);\n        params.push(dto.desire);\n        paramIndex++;\n      }\n      if (dto.time_availability !== undefined) {\n        updates.push(`time_availability = $${paramIndex}`);\n        params.push(dto.time_availability);\n        paramIndex++;\n      }\n      if (dto.source !== undefined) {\n        updates.push(`source = $${paramIndex}`);\n        params.push(dto.source);\n        paramIndex++;\n      }\n      if (dto.referrer !== undefined) {\n        updates.push(`referrer = $${paramIndex}`);\n        params.push(dto.referrer);\n        paramIndex++;\n      }\n      if (dto.status !== undefined) {\n        updates.push(`status = $${paramIndex}`);\n        params.push(dto.status);\n        paramIndex++;\n      }\n\n      if (updates.length === 0)\n        return { success: false, error: \"No fields to update\" };\n\n      params.push(id);\n      const { rows } = await this.pool.query(\n        `UPDATE crm_contacts SET ${updates.join(\", \")} WHERE id = $${paramIndex} RETURNING *`,\n        params,\n      );\n\n      if (rows.length === 0)\n        return { success: false, error: \"Contact not found\" };\n\n      await this.redisCache.invalidatePattern(\"crm_contacts_list_*\");\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error updating CRM contact:\", error);\n      return { success: false, error: \"Failed to update contact\" };\n    }\n  }\n\n  @Delete(\":id\")\n  async deleteContact(@Param(\"id\") id: string) {\n    await this.ensureTable();\n\n    try {\n      const { rows } = await this.pool.query(\n        `DELETE FROM crm_contacts WHERE id = $1 RETURNING id`,\n        [id],\n      );\n      if (rows.length === 0)\n        return { success: false, error: \"Contact not found\" };\n\n      await this.redisCache.invalidatePattern(\"crm_contacts_list_*\");\n      return { success: true, message: \"Contact deleted successfully\" };\n    } catch (error) {\n      this.logger.error(\"Error deleting CRM contact:\", error);\n      return { success: false, error: \"Failed to delete contact\" };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/donations.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":109,"column":46,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":109,"endColumn":49,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3826,3829],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3826,3829],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":233,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":233,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7801,7804],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7801,7804],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":329,"column":69,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":329,"endColumn":72,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10284,10287],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10284,10287],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":460,"column":13,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":460,"endColumn":16,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14203,14206],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14203,14206],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Donations API for categories, CRUD, listing, and stats; updates community/user stats and caches.\n// - Reached from: Routes under '/api/donations'.\n// - Provides: Create/update/delete donation, list with filters, per-user donations, category endpoints, summary stats.\n// - Storage: `donations`, `donation_categories`, `user_profiles`, `community_stats`; Redis caches with TTL.\n\n// TODO: CRITICAL - This file is long (292+ lines). Split into specialized services:\n//   - DonationsCategoryService for category operations\n//   - DonationsService for CRUD operations\n//   - DonationsStatsService for analytics\n//   - DonationsCacheService for cache management\n// TODO: Add comprehensive DTO validation for all endpoints with class-validator\n// TODO: Implement proper pagination with cursor-based approach\n// TODO: Add comprehensive error handling with proper HTTP status codes\n// TODO: Implement proper authorization and access control\n// TODO: Add comprehensive logging and monitoring for all operations\n// TODO: Remove hardcoded cache TTL and make it configurable\n// TODO: Add comprehensive unit tests for all donation operations\n// TODO: Implement proper data sanitization and validation\n// TODO: Add comprehensive API documentation with Swagger decorators\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Put,\n  Query,\n  UseGuards,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { JwtAuthGuard } from \"../auth/jwt-auth.guard\";\n\n@Controller(\"api/donations\")\nexport class DonationsController {\n  private readonly logger = new Logger(DonationsController.name);\n  // TODO: Move cache TTL to configuration service\n  // TODO: Implement different TTL values for different types of data\n  // TODO: Add cache invalidation strategies\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  /**\n   * Get all donation categories with caching\n   * Cache TTL: 30 minutes (categories are static data that rarely changes)\n   */\n  @Get(\"categories\")\n  async getCategories() {\n    const cacheKey = \"donation_categories_all\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(`\n      SELECT id, slug, name_he, name_en, description_he, description_en, \n             icon, color, is_active, sort_order\n      FROM donation_categories \n      WHERE is_active = true \n      ORDER BY sort_order ASC, name_he ASC\n    `);\n\n    // Cache for 30 minutes - categories are static data\n    await this.redisCache.set(cacheKey, rows, 30 * 60);\n    return { success: true, data: rows };\n  }\n\n  /**\n   * Get a single donation category by slug with caching\n   * Cache TTL: 30 minutes (categories are static data)\n   */\n  @Get(\"categories/:slug\")\n  async getCategoryBySlug(@Param(\"slug\") slug: string) {\n    const cacheKey = `donation_category_${slug}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT * FROM donation_categories WHERE slug = $1 AND is_active = true\n    `,\n      [slug],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Category not found\" };\n    }\n\n    // Cache for 30 minutes - categories are static data\n    await this.redisCache.set(cacheKey, rows[0], 30 * 60);\n    return { success: true, data: rows[0] };\n  }\n\n  @Post()\n  @UseGuards(JwtAuthGuard)\n  async createDonation(@Body() donationData: any) {\n    // TODO: Replace 'any' with proper CreateDonationDTO interface\n    // TODO: Add comprehensive input validation and sanitization\n    // TODO: Add proper authentication and authorization checks\n    // TODO: Implement rate limiting for donation creation\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Insert donation\n      const isRecurring =\n        donationData.is_recurring ?? donationData.isRecurring ?? false;\n\n      const { rows } = await client.query(\n        `\n        INSERT INTO donations (\n          donor_id, recipient_id, organization_id, category_id, \n          title, description, amount, currency, type, status,\n          is_recurring, location, images, tags, metadata, expires_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16)\n        RETURNING *\n      `,\n        [\n          donationData.donor_id,\n          donationData.recipient_id || null,\n          donationData.organization_id || null,\n          donationData.category_id,\n          donationData.title,\n          donationData.description,\n          donationData.amount || null,\n          donationData.currency || \"ILS\",\n          donationData.type,\n          \"active\",\n          isRecurring,\n          donationData.location ? JSON.stringify(donationData.location) : null,\n          donationData.images || [],\n          donationData.tags || [],\n          donationData.metadata ? JSON.stringify(donationData.metadata) : null,\n          donationData.expires_at || null,\n        ],\n      );\n\n      const donation = rows[0];\n\n      // Update user stats\n      if (donationData.type === \"money\" && donationData.amount) {\n        await client.query(\n          `\n          UPDATE user_profiles \n          SET total_donations_amount = total_donations_amount + $1,\n              updated_at = NOW()\n          WHERE id = $2\n        `,\n          [donationData.amount, donationData.donor_id],\n        );\n      }\n\n      // Update community stats\n      await this.updateCommunityStats(\n        client,\n        donationData.type,\n        donationData.amount || 1,\n      );\n\n      // Track user activity\n      await client.query(\n        `\n        INSERT INTO user_activities (user_id, activity_type, activity_data)\n        VALUES ($1, $2, $3)\n      `,\n        [\n          donationData.donor_id,\n          \"donation_created\",\n          JSON.stringify({\n            donation_id: donation.id,\n            type: donationData.type,\n            amount: donationData.amount,\n          }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear relevant caches\n      await this.clearDonationCaches();\n      await this.clearCommunityStatsCaches();\n\n      return { success: true, data: donation };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Create donation error:\", error);\n      return { success: false, error: \"Failed to create donation\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get()\n  async getDonations(\n    @Query(\"type\") type?: string,\n    @Query(\"category\") category?: string,\n    @Query(\"city\") city?: string,\n    @Query(\"status\") status?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n    @Query(\"search\") search?: string,\n  ) {\n    const cacheKey = `donations_${type || \"all\"}_${category || \"all\"}_${city || \"all\"}_${status || \"active\"}_${limit || \"50\"}_${offset || \"0\"}_${search || \"\"}`;\n\n    // Try cache first\n    const cached = await this.redisCache.get(cacheKey);\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    let query = `\n      SELECT d.*, dc.name_he as category_name, dc.icon as category_icon,\n             up.name as donor_name, up.city as donor_city, up.avatar_url as donor_avatar\n      FROM donations d\n      LEFT JOIN donation_categories dc ON d.category_id = dc.id\n      LEFT JOIN user_profiles up ON d.donor_id = up.id\n      WHERE 1=1\n    `;\n\n    const params: any[] = [];\n    let paramCount = 0;\n\n    if (type) {\n      paramCount++;\n      query += ` AND d.type = $${paramCount}`;\n      params.push(type);\n    }\n\n    if (category) {\n      paramCount++;\n      query += ` AND dc.slug = $${paramCount}`;\n      params.push(category);\n    }\n\n    if (city) {\n      paramCount++;\n      query += ` AND (d.location->>'city' = $${paramCount} OR up.city = $${paramCount})`;\n      params.push(city);\n    }\n\n    if (status) {\n      paramCount++;\n      query += ` AND d.status = $${paramCount}`;\n      params.push(status);\n    } else {\n      query += ` AND d.status = 'active'`;\n    }\n\n    if (search) {\n      paramCount++;\n      query += ` AND (d.title ILIKE $${paramCount} OR d.description ILIKE $${paramCount})`;\n      params.push(`%${search}%`);\n    }\n\n    query += ` ORDER BY d.created_at DESC`;\n\n    if (limit) {\n      paramCount++;\n      query += ` LIMIT $${paramCount}`;\n      params.push(parseInt(limit));\n    } else {\n      query += ` LIMIT 50`;\n    }\n\n    if (offset) {\n      paramCount++;\n      query += ` OFFSET $${paramCount}`;\n      params.push(parseInt(offset));\n    }\n\n    const { rows } = await this.pool.query(query, params);\n\n    // Cache for 5 minutes\n    await this.redisCache.set(cacheKey, rows, 5 * 60);\n\n    return { success: true, data: rows };\n  }\n\n  /**\n   * Get a single donation by ID with caching\n   * Cache TTL: 15 minutes (donations are relatively static but can be updated)\n   */\n  @Get(\":id\")\n  async getDonationById(@Param(\"id\") id: string) {\n    const cacheKey = `donation_${id}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT d.*, dc.name_he as category_name, dc.icon as category_icon,\n             up.name as donor_name, up.city as donor_city, up.avatar_url as donor_avatar,\n             up.phone as donor_phone, up.email as donor_email\n      FROM donations d\n      LEFT JOIN donation_categories dc ON d.category_id = dc.id\n      LEFT JOIN user_profiles up ON d.donor_id = up.id\n      WHERE d.id = $1\n    `,\n      [id],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Donation not found\" };\n    }\n\n    // Cache for 15 minutes\n    await this.redisCache.set(cacheKey, rows[0], 15 * 60);\n    return { success: true, data: rows[0] };\n  }\n\n  @Put(\":id\")\n  @UseGuards(JwtAuthGuard)\n  async updateDonation(@Param(\"id\") id: string, @Body() updateData: any) {\n    const { rows } = await this.pool.query(\n      `\n      UPDATE donations \n      SET title = COALESCE($1, title),\n          description = COALESCE($2, description),\n          amount = COALESCE($3, amount),\n          status = COALESCE($4, status),\n          is_recurring = COALESCE($5, is_recurring),\n          location = COALESCE($6, location),\n          images = COALESCE($7, images),\n          tags = COALESCE($8, tags),\n          metadata = COALESCE($9, metadata),\n          expires_at = COALESCE($10, expires_at),\n          updated_at = NOW()\n      WHERE id = $11\n      RETURNING *\n    `,\n      [\n        updateData.title,\n        updateData.description,\n        updateData.amount,\n        updateData.status,\n        updateData.is_recurring ?? updateData.isRecurring ?? null,\n        updateData.location ? JSON.stringify(updateData.location) : null,\n        updateData.images,\n        updateData.tags,\n        updateData.metadata ? JSON.stringify(updateData.metadata) : null,\n        updateData.expires_at,\n        id,\n      ],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Donation not found\" };\n    }\n\n    // Clear specific donation cache\n    await this.redisCache.delete(`donation_${id}`);\n    await this.clearDonationCaches();\n    return { success: true, data: rows[0] };\n  }\n\n  @Delete(\":id\")\n  @UseGuards(JwtAuthGuard)\n  async deleteDonation(@Param(\"id\") id: string) {\n    // First check if donation exists\n    const { rows } = await this.pool.query(\n      `\n      SELECT id, status FROM donations WHERE id = $1\n    `,\n      [id],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Donation not found\" };\n    }\n\n    // Delete from database\n    const { rowCount } = await this.pool.query(\n      `\n      DELETE FROM donations WHERE id = $1\n    `,\n      [id],\n    );\n\n    if (rowCount === 0) {\n      return { success: false, error: \"Failed to delete donation\" };\n    }\n\n    // Clear specific donation cache\n    await this.redisCache.delete(`donation_${id}`);\n    // Clear all related caches\n    await this.clearDonationCaches();\n    await this.clearCommunityStatsCaches();\n\n    return { success: true, message: \"Donation deleted successfully\" };\n  }\n\n  @Get(\"user/:userId\")\n  async getUserDonations(@Param(\"userId\") userId: string) {\n    const cacheKey = `user_donations_${userId}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT d.*, dc.name_he as category_name, dc.icon as category_icon\n      FROM donations d\n      LEFT JOIN donation_categories dc ON d.category_id = dc.id\n      WHERE d.donor_id = $1\n      ORDER BY d.created_at DESC\n    `,\n      [userId],\n    );\n\n    await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n    return { success: true, data: rows };\n  }\n\n  @Get(\"stats/summary\")\n  async getDonationStats() {\n    const cacheKey = \"donation_stats_summary\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(`\n      SELECT \n        COUNT(*) as total_donations,\n        COUNT(DISTINCT donor_id) as unique_donors,\n        SUM(CASE WHEN type = 'money' THEN amount ELSE 0 END) as total_money,\n        COUNT(CASE WHEN type = 'time' THEN 1 END) as time_donations,\n        COUNT(CASE WHEN type = 'trump' THEN 1 END) as ride_donations,\n        COUNT(CASE WHEN status = 'active' THEN 1 END) as active_donations,\n        COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_donations\n      FROM donations\n      WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'\n    `);\n\n    const stats = rows[0];\n    await this.redisCache.set(cacheKey, stats, this.CACHE_TTL);\n    return { success: true, data: stats };\n  }\n\n  private async updateCommunityStats(\n    client: any,\n    type: string,\n    amount: number,\n  ) {\n    const statType =\n      type === \"money\"\n        ? \"money_donations\"\n        : type === \"time\"\n          ? \"volunteer_hours\"\n          : type === \"trump\"\n            ? \"rides_completed\"\n            : \"other_donations\";\n\n    await client.query(\n      `\n      INSERT INTO community_stats (stat_type, stat_value, date_period)\n      VALUES ($1, $2, CURRENT_DATE)\n      ON CONFLICT (stat_type, city, date_period) \n      DO UPDATE SET stat_value = community_stats.stat_value + $2, updated_at = NOW()\n    `,\n      [statType, amount],\n    );\n  }\n\n  /**\n   * Clear all donation-related caches\n   * Called after create/update/delete operations to ensure data consistency\n   * Uses invalidatePattern for efficient batch deletion\n   */\n  private async clearDonationCaches() {\n    const patterns = [\n      \"donations_*\", // All donation lists with filters\n      \"user_donations_*\", // User-specific donation lists\n      \"donation_stats_*\", // Donation statistics\n      \"donation_*\", // Individual donation cache\n      \"donation_category_*\", // Individual category cache\n    ];\n\n    for (const pattern of patterns) {\n      await this.redisCache.invalidatePattern(pattern);\n    }\n\n    // Clear categories cache explicitly\n    await this.redisCache.delete(\"donation_categories_all\");\n  }\n\n  private async clearCommunityStatsCaches() {\n    // Use invalidatePattern for better performance\n    const patterns = [\n      \"community_stats_*\",\n      \"community_trends_*\",\n      \"dashboard_stats\",\n      \"real_time_stats\",\n    ];\n    for (const pattern of patterns) {\n      await this.redisCache.invalidatePattern(pattern);\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/dto/community-challenge.dto.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/dto/items.dto.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":34,"column":14,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":34,"endColumn":17,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[606,609],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[606,609],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: DTOs for Items Delivery API endpoints with validation\n// - Used by: ItemsDeliveryController for creating, updating, and filtering items\nimport {\n  IsString,\n  IsOptional,\n  IsNumber,\n  IsEnum,\n  IsArray,\n  IsObject,\n  Min,\n} from \"class-validator\";\nimport { Type, Transform } from \"class-transformer\";\n\nexport class CreateItemDto {\n  @IsString()\n  owner_id!: string;\n\n  @IsString()\n  title!: string;\n\n  @IsOptional()\n  @IsString()\n  description?: string;\n\n  @IsString()\n  category!: string;\n\n  @IsOptional()\n  @IsString()\n  condition?: string;\n\n  @IsOptional()\n  location?: any;\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) =>\n    value === null || value === undefined ? undefined : Number(value),\n  )\n  price?: number;\n\n  @IsOptional()\n  @IsArray()\n  images?: string[];\n\n  @IsOptional()\n  @IsArray()\n  tags?: string[];\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) =>\n    value === null || value === undefined ? undefined : Number(value),\n  )\n  quantity?: number;\n\n  @IsOptional()\n  @IsString()\n  delivery_method?: string;\n\n  @IsOptional()\n  metadata?: Record<string, unknown>;\n\n  @IsOptional()\n  @IsString()\n  expires_at?: string;\n}\n\nexport class UpdateItemDto {\n  @IsOptional()\n  @IsString()\n  title?: string;\n\n  @IsOptional()\n  @IsString()\n  description?: string;\n\n  @IsOptional()\n  @IsString()\n  @IsEnum([\n    \"furniture\",\n    \"clothes\",\n    \"electronics\",\n    \"general\",\n    \"books\",\n    \"toys\",\n    \"sports\",\n    \"kitchen\",\n    \"other\",\n  ])\n  category?: string;\n\n  @IsOptional()\n  @IsEnum([\"new\", \"like_new\", \"used\", \"for_parts\"])\n  condition?: string;\n\n  @IsOptional()\n  @IsObject()\n  location?: {\n    city?: string;\n    address?: string;\n    coordinates?: { lat: number; lng: number };\n  };\n\n  @IsOptional()\n  @IsNumber()\n  @Min(0)\n  price?: number;\n\n  @IsOptional()\n  @IsArray()\n  @IsString({ each: true })\n  images?: string[];\n\n  @IsOptional()\n  @IsArray()\n  @IsString({ each: true })\n  tags?: string[];\n\n  @IsOptional()\n  @IsNumber()\n  @Min(1)\n  quantity?: number;\n\n  @IsOptional()\n  @IsEnum([\"available\", \"reserved\", \"delivered\", \"expired\", \"cancelled\"])\n  status?: string;\n\n  @IsOptional()\n  @IsEnum([\"pickup\", \"delivery\", \"shipping\"])\n  delivery_method?: string;\n\n  @IsOptional()\n  @IsObject()\n  metadata?: Record<string, unknown>;\n\n  @IsOptional()\n  @IsString()\n  expires_at?: string;\n}\n\nexport class ItemFiltersDto {\n  @IsOptional()\n  @IsString()\n  category?: string;\n\n  @IsOptional()\n  @IsString()\n  condition?: string;\n\n  @IsOptional()\n  @IsString()\n  status?: string;\n\n  @IsOptional()\n  @IsString()\n  city?: string;\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) => {\n    if (\n      value === \"\" ||\n      value === null ||\n      value === undefined ||\n      value === \"undefined\" ||\n      value === \"null\"\n    ) {\n      return undefined;\n    }\n    const num = Number(value);\n    return isNaN(num) ? undefined : num;\n  })\n  min_price?: number;\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) => {\n    if (\n      value === \"\" ||\n      value === null ||\n      value === undefined ||\n      value === \"undefined\" ||\n      value === \"null\"\n    ) {\n      return undefined;\n    }\n    const num = Number(value);\n    return isNaN(num) ? undefined : num;\n  })\n  max_price?: number;\n\n  @IsOptional()\n  @IsString()\n  search?: string; // Full-text search query\n\n  @IsOptional()\n  @IsString()\n  owner_id?: string;\n\n  @IsOptional()\n  @IsString()\n  sort_by?: string;\n\n  @IsOptional()\n  @IsString()\n  sort_order?: string;\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) => {\n    if (\n      value === \"\" ||\n      value === null ||\n      value === undefined ||\n      value === \"undefined\" ||\n      value === \"null\"\n    ) {\n      return undefined;\n    }\n    const num = Number(value);\n    return isNaN(num) ? undefined : num;\n  })\n  limit?: number;\n\n  @IsOptional()\n  @Type(() => Number)\n  @Transform(({ value }) => {\n    if (\n      value === \"\" ||\n      value === null ||\n      value === undefined ||\n      value === \"undefined\" ||\n      value === \"null\"\n    ) {\n      return undefined;\n    }\n    const num = Number(value);\n    return isNaN(num) ? undefined : num;\n  })\n  offset?: number;\n}\n\nexport class CreateItemRequestDto {\n  @IsString()\n  item_id!: string;\n\n  @IsString()\n  requester_id!: string;\n\n  @IsOptional()\n  @IsString()\n  message?: string;\n\n  @IsOptional()\n  @IsString()\n  proposed_time?: string;\n\n  @IsOptional()\n  @IsEnum([\"pickup\", \"delivery\", \"shipping\"])\n  delivery_method?: string;\n\n  @IsOptional()\n  @IsObject()\n  meeting_location?: {\n    address?: string;\n    city?: string;\n    coordinates?: { lat: number; lng: number };\n  };\n}\n\nexport class UpdateItemRequestDto {\n  @IsOptional()\n  @IsEnum([\n    \"pending\",\n    \"approved\",\n    \"rejected\",\n    \"scheduled\",\n    \"completed\",\n    \"cancelled\",\n  ])\n  status?: string;\n\n  @IsOptional()\n  @IsString()\n  message?: string;\n\n  @IsOptional()\n  @IsString()\n  proposed_time?: string;\n\n  @IsOptional()\n  @IsString()\n  owner_response?: string;\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/health.controller.spec.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/health.controller.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/items-delivery.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":33,"column":34,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":33,"endColumn":37,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[895,898],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[895,898],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Items Delivery API for creating, listing, updating, and managing item delivery requests\n// - Reached from: Routes under '/api/items'\n// - Provides: CRUD for items, search with filters, and item request workflow management\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Put,\n  Query,\n  Logger,\n} from \"@nestjs/common\";\nimport { ItemsDeliveryService } from \"./items-delivery.service\";\nimport {\n  CreateItemDto,\n  UpdateItemDto,\n  ItemFiltersDto,\n  CreateItemRequestDto,\n  UpdateItemRequestDto,\n} from \"./dto/items.dto\";\n\n@Controller(\"api/items-delivery\")\nexport class ItemsDeliveryController {\n  private readonly logger = new Logger(ItemsDeliveryController.name);\n  constructor(private readonly itemsDeliveryService: ItemsDeliveryService) {}\n\n  // ==================== Items CRUD ====================\n\n  @Post()\n  async createItem(@Body() body: any) {\n    try {\n      // Manual validation and transformation\n      const createItemDto: CreateItemDto = {\n        owner_id: body.owner_id,\n        title: body.title,\n        description: body.description || undefined,\n        category: body.category,\n        condition: body.condition || undefined,\n        location: body.location || undefined,\n        price:\n          body.price !== undefined && body.price !== null\n            ? Number(body.price)\n            : undefined,\n        images: body.images || [],\n        tags: body.tags || [],\n        quantity:\n          body.quantity !== undefined && body.quantity !== null\n            ? Number(body.quantity)\n            : undefined,\n        delivery_method: body.delivery_method || undefined,\n        metadata: body.metadata || undefined,\n        expires_at: body.expires_at || undefined,\n      };\n\n      // Basic validation\n      if (\n        !createItemDto.owner_id ||\n        !createItemDto.title ||\n        !createItemDto.category\n      ) {\n        return {\n          success: false,\n          error:\n            \"Missing required fields: owner_id, title, and category are required\",\n        };\n      }\n\n      return this.itemsDeliveryService.createItem(createItemDto);\n    } catch (error) {\n      this.logger.error(\"Error in createItem:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to create item\",\n      };\n    }\n  }\n\n  @Get(\"search\")\n  async searchItems(\n    @Query(\"category\") category?: string,\n    @Query(\"condition\") condition?: string,\n    @Query(\"status\") status?: string,\n    @Query(\"city\") city?: string,\n    @Query(\"min_price\") min_price?: string,\n    @Query(\"max_price\") max_price?: string,\n    @Query(\"search\") search?: string,\n    @Query(\"owner_id\") owner_id?: string,\n    @Query(\"sort_by\") sort_by?: string,\n    @Query(\"sort_order\") sort_order?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n  ) {\n    const validatedFilters: ItemFiltersDto = {\n      category: category || undefined,\n      condition: condition || undefined,\n      status: status || undefined,\n      city: city || undefined,\n      min_price: min_price ? Number(min_price) : undefined,\n      max_price: max_price ? Number(max_price) : undefined,\n      search: search || undefined,\n      owner_id: owner_id || undefined,\n      sort_by: sort_by || undefined,\n      sort_order: sort_order || undefined,\n      limit: limit ? Number(limit) : undefined,\n      offset: offset ? Number(offset) : undefined,\n    };\n    try {\n      return await this.itemsDeliveryService.listItems(validatedFilters);\n    } catch (error) {\n      this.logger.error(\"Error in searchItems:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to search items\",\n      };\n    }\n  }\n\n  @Get(\"user/:userId\")\n  async getUserItems(\n    @Param(\"userId\") userId: string,\n    @Query(\"category\") category?: string,\n    @Query(\"status\") status?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n  ) {\n    const validatedFilters: ItemFiltersDto = {\n      category: category || undefined,\n      status: status || undefined,\n      owner_id: userId,\n      limit: limit ? Number(limit) : undefined,\n      offset: offset ? Number(offset) : undefined,\n    };\n    return this.itemsDeliveryService.listItems(validatedFilters);\n  }\n\n  @Get()\n  async listItems(\n    @Query(\"category\") category?: string,\n    @Query(\"condition\") condition?: string,\n    @Query(\"status\") status?: string,\n    @Query(\"city\") city?: string,\n    @Query(\"min_price\") min_price?: string,\n    @Query(\"max_price\") max_price?: string,\n    @Query(\"search\") search?: string,\n    @Query(\"owner_id\") owner_id?: string,\n    @Query(\"sort_by\") sort_by?: string,\n    @Query(\"sort_order\") sort_order?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n  ) {\n    try {\n      const validatedFilters: ItemFiltersDto = {\n        category: category || undefined,\n        condition: condition || undefined,\n        status: status || undefined,\n        city: city || undefined,\n        min_price: min_price ? Number(min_price) : undefined,\n        max_price: max_price ? Number(max_price) : undefined,\n        search: search || undefined,\n        owner_id: owner_id || undefined,\n        sort_by: sort_by || undefined,\n        sort_order: sort_order || undefined,\n        limit: limit ? Number(limit) : undefined,\n        offset: offset ? Number(offset) : undefined,\n      };\n      return this.itemsDeliveryService.listItems(validatedFilters);\n    } catch (error) {\n      this.logger.error(\"Error in listItems:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to list items\",\n      };\n    }\n  }\n\n  @Get(\":id\")\n  async getItemById(@Param(\"id\") id: string) {\n    return this.itemsDeliveryService.getItemById(id);\n  }\n\n  @Put(\":id\")\n  async updateItem(\n    @Param(\"id\") id: string,\n    @Body() updateItemDto: UpdateItemDto,\n  ) {\n    return this.itemsDeliveryService.updateItem(id, updateItemDto);\n  }\n\n  @Delete(\":id\")\n  async deleteItem(@Param(\"id\") id: string) {\n    return this.itemsDeliveryService.deleteItem(id);\n  }\n\n  // ==================== Item Requests ====================\n\n  @Post(\":id/reserve\")\n  async reserveItem(\n    @Param(\"id\") itemId: string,\n    @Body() createRequestDto: Omit<CreateItemRequestDto, \"item_id\">,\n  ) {\n    return this.itemsDeliveryService.createItemRequest({\n      ...createRequestDto,\n      item_id: itemId,\n    });\n  }\n\n  @Post(\"requests\")\n  async createItemRequest(@Body() createRequestDto: CreateItemRequestDto) {\n    return this.itemsDeliveryService.createItemRequest(createRequestDto);\n  }\n\n  @Get(\"requests\")\n  async getItemRequests(\n    @Query(\"itemId\") itemId?: string,\n    @Query(\"userId\") userId?: string,\n    @Query(\"role\") role: \"owner\" | \"requester\" = \"requester\",\n  ) {\n    return this.itemsDeliveryService.getItemRequests(itemId, userId, role);\n  }\n\n  @Put(\"requests/:requestId\")\n  async updateItemRequest(\n    @Param(\"requestId\") requestId: string,\n    @Body() updateRequestDto: UpdateItemRequestDto,\n    @Query(\"userId\") userId: string,\n  ) {\n    if (!userId) {\n      return { success: false, error: \"userId query parameter is required\" };\n    }\n    return this.itemsDeliveryService.updateItemRequest(\n      requestId,\n      updateRequestDto,\n      userId,\n    );\n  }\n\n  @Post(\":id/deliver\")\n  async markAsDelivered(\n    @Param(\"id\") itemId: string,\n    @Body() body: { userId: string; requestId?: string },\n  ) {\n    // Mark item as delivered\n    const updateResult = await this.itemsDeliveryService.updateItem(itemId, {\n      status: \"delivered\",\n    });\n\n    // If there's a requestId, mark it as completed\n    if (body.requestId) {\n      await this.itemsDeliveryService.updateItemRequest(\n        body.requestId,\n        { status: \"completed\" },\n        body.userId,\n      );\n    }\n\n    return updateResult;\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/items-delivery.service.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":38,"column":38,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":38,"endColumn":41,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1397,1400],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1397,1400],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":220,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":220,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7560,7563],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7560,7563],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":318,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":318,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10228,10231],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10228,10231],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":544,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":544,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[17376,17379],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[17376,17379],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":609,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":609,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[19055,19058],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[19055,19058],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Service for Items Delivery operations with database queries and Redis caching\n// - Used by: ItemsDeliveryController\n// - Provides: CRUD operations for items, search with filters, and item requests management\nimport { Inject, Injectable, Logger } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport {\n  CreateItemDto,\n  UpdateItemDto,\n  ItemFiltersDto,\n  CreateItemRequestDto,\n  UpdateItemRequestDto,\n} from \"./dto/items.dto\";\nimport { randomBytes } from \"crypto\";\n\n@Injectable()\nexport class ItemsDeliveryService {\n  private readonly logger = new Logger(ItemsDeliveryService.name);\n  private readonly CACHE_TTL = 5 * 60; // 5 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  // ==================== Items CRUD ====================\n\n  async createItem(createItemDto: CreateItemDto) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Generate ID if not provided or if provided ID is a timestamp\n      // This ensures we always have a proper ID format like \"item_1234567890_abc123\"\n      // Similar to how rides work - the backend generates the ID, not the frontend\n      let itemId = (createItemDto as any).id;\n      if (!itemId || /^\\d{10,13}$/.test(itemId)) {\n        // If ID is missing or is a timestamp (only digits, 10-13 chars), generate a proper ID\n        // S2245: Use crypto.randomBytes instead of Math.random for ID generation\n        itemId = `item_${Date.now()}_${randomBytes(6).toString(\"hex\")}`;\n        this.logger.log(\n          `Generated new item ID (was timestamp or missing): ${itemId}`,\n        );\n      } else {\n        this.logger.log(`Using provided item ID: ${itemId}`);\n      }\n\n      // Verify ID format before using\n      if (!itemId || itemId.length < 10) {\n        throw new Error(\n          \"Invalid item ID format - ID must be at least 10 characters\",\n        );\n      }\n\n      this.logger.log(\n        `Creating item with ID: ${itemId}, Type: ${typeof itemId}`,\n      );\n\n      const { rows } = await client.query(\n        `\n        INSERT INTO items (\n          id, owner_id, title, description, category, condition, location,\n          price, images, tags, quantity, delivery_method, metadata, expires_at\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)\n        RETURNING *\n      `,\n        [\n          itemId,\n          createItemDto.owner_id,\n          createItemDto.title,\n          createItemDto.description || null,\n          createItemDto.category,\n          createItemDto.condition || null,\n          createItemDto.location\n            ? JSON.stringify(createItemDto.location)\n            : null,\n          createItemDto.price ?? 0,\n          createItemDto.images || [],\n          createItemDto.tags || [],\n          createItemDto.quantity || 1,\n          createItemDto.delivery_method || null,\n          createItemDto.metadata\n            ? JSON.stringify(createItemDto.metadata)\n            : null,\n          createItemDto.expires_at ? new Date(createItemDto.expires_at) : null,\n        ],\n      );\n\n      const createdItem = rows[0];\n      this.logger.log(`Created item - ID: ${createdItem.id}`);\n\n      // CRITICAL: Verify the ID is correct before using it\n      if (!createdItem.id || createdItem.id.length < 10) {\n        this.logger.error(\"CRITICAL: Item ID is invalid!\", createdItem);\n        throw new Error(\n          \"Failed to create item - invalid ID returned from database\",\n        );\n      }\n\n      // Auto-create a corresponding post for this item\n      // This allows likes/comments to work on items in the feed\n      try {\n        const price = createItemDto.price ?? 0;\n        const postType = price > 0 ? \"item\" : \"donation\";\n        const postTitle = createItemDto.title;\n        const postDescription = createItemDto.description || \"\";\n\n        // Ensure item_id is the full item ID, not just timestamp\n        const itemIdForPost = createdItem.id;\n        this.logger.log(`Creating post with item_id: ${itemIdForPost}`);\n\n        await client.query(\n          `\n          INSERT INTO posts (author_id, item_id, title, description, images, post_type, metadata)\n          VALUES ($1, $2, $3, $4, $5, $6, $7)\n        `,\n          [\n            createItemDto.owner_id,\n            itemIdForPost, // Use the full item ID\n            postTitle,\n            postDescription,\n            createItemDto.images || [],\n            postType,\n            JSON.stringify({\n              item_id: itemIdForPost, // Store full ID in metadata too\n              category: createItemDto.category,\n              price: price,\n              condition: createItemDto.condition,\n            }),\n          ],\n        );\n\n        // Verify the post was created correctly\n        const { rows: verifyRows } = await client.query(\n          `\n          SELECT id, item_id, post_type FROM posts \n          WHERE item_id = $1 AND post_type = $2\n          ORDER BY created_at DESC LIMIT 1\n        `,\n          [itemIdForPost, postType],\n        );\n\n        if (verifyRows.length > 0) {\n          this.logger.log(\n            `Verified post created with item_id: ${verifyRows[0].item_id}`,\n          );\n        } else {\n          this.logger.error(\"Failed to verify post creation - post not found!\");\n        }\n\n        this.logger.log(`Auto-created post for item: ${createdItem.id}`);\n      } catch (postError) {\n        this.logger.warn(\n          `Failed to auto-create post for item (continuing): ${postError}`,\n        );\n        // Don't fail the item creation if post creation fails\n      }\n\n      await client.query(\"COMMIT\");\n\n      // Invalidate cache\n      await this.invalidateItemCaches();\n\n      return { success: true, data: createdItem };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Create item error:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to create item\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  async getItemById(id: string) {\n    const cacheKey = `item:${id}`;\n    const cached = await this.redisCache.get(cacheKey);\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT i.*, up.name as owner_name, up.avatar_url as owner_avatar, up.city as owner_city\n      FROM items i\n      LEFT JOIN user_profiles up ON (i.owner_id::text = up.id::text OR i.owner_id::text = up.firebase_uid)\n      WHERE i.id = $1\n    `,\n      [id],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Item not found\" };\n    }\n\n    await this.redisCache.set(cacheKey, rows[0], this.CACHE_TTL);\n    return { success: true, data: rows[0] };\n  }\n\n  async listItems(filters: ItemFiltersDto) {\n    // Build cache key from filters\n    const cacheKey = `items_list:${JSON.stringify(filters)}`;\n    const cached = await this.redisCache.get(cacheKey);\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // Build query\n    // Note: owner_id can be either UUID (id) or Firebase UID (firebase_uid)\n    let query = `\n      SELECT i.*, up.name as owner_name, up.avatar_url as owner_avatar\n      FROM items i\n      LEFT JOIN user_profiles up ON (i.owner_id::text = up.id::text OR i.owner_id::text = up.firebase_uid)\n      WHERE 1=1\n    `;\n    const params: any[] = [];\n    let paramCount = 0;\n\n    if (filters.status) {\n      paramCount++;\n      query += ` AND i.status = $${paramCount}`;\n      params.push(filters.status);\n    } else {\n      query += ` AND i.status = 'available'`;\n    }\n\n    if (filters.category) {\n      paramCount++;\n      query += ` AND i.category = $${paramCount}`;\n      params.push(filters.category);\n    }\n\n    if (filters.condition) {\n      paramCount++;\n      query += ` AND i.condition = $${paramCount}`;\n      params.push(filters.condition);\n    }\n\n    if (filters.city) {\n      paramCount++;\n      query += ` AND (i.location->>'city' = $${paramCount} OR up.city = $${paramCount})`;\n      params.push(filters.city);\n    }\n\n    if (filters.min_price !== undefined) {\n      paramCount++;\n      query += ` AND i.price >= $${paramCount}`;\n      params.push(filters.min_price);\n    }\n\n    if (filters.max_price !== undefined) {\n      paramCount++;\n      query += ` AND i.price <= $${paramCount}`;\n      params.push(filters.max_price);\n    }\n\n    if (filters.owner_id) {\n      paramCount++;\n      query += ` AND i.owner_id::text = $${paramCount}`;\n      params.push(filters.owner_id);\n    }\n\n    // Full-text search\n    if (filters.search) {\n      paramCount++;\n      query += ` AND (\n        i.title ILIKE $${paramCount} OR\n        i.description ILIKE $${paramCount} OR\n        EXISTS (\n          SELECT 1 FROM unnest(i.tags) AS tag\n          WHERE tag ILIKE $${paramCount}\n        )\n      )`;\n      params.push(`%${filters.search}%`);\n    }\n\n    // Sorting\n    // S2077: Whitelist sortBy/sortOrder to prevent SQL injection\n    const sortBy = filters.sort_by || \"created_at\";\n    const sortOrder = filters.sort_order || \"desc\";\n    const allowedSortColumns = [\n      \"created_at\",\n      \"price\",\n      \"title\",\n      \"quantity\",\n      \"updated_at\",\n    ];\n    const safeSortBy = allowedSortColumns.includes(sortBy)\n      ? sortBy\n      : \"created_at\";\n    const safeSortOrder = sortOrder.toUpperCase() === \"ASC\" ? \"ASC\" : \"DESC\";\n    query += ` ORDER BY i.${safeSortBy} ${safeSortOrder}`;\n\n    // Pagination\n    const limit = filters.limit || 50;\n    const offset = filters.offset || 0;\n    paramCount++;\n    query += ` LIMIT $${paramCount}`;\n    params.push(limit);\n    paramCount++;\n    query += ` OFFSET $${paramCount}`;\n    params.push(offset);\n\n    const { rows } = await this.pool.query(query, params);\n\n    await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n    return { success: true, data: rows };\n  }\n\n  async updateItem(id: string, updateItemDto: UpdateItemDto) {\n    const client = await this.pool.connect();\n    try {\n      const updateFields: string[] = [];\n      const params: any[] = [];\n      let paramCount = 0;\n\n      if (updateItemDto.title !== undefined) {\n        paramCount++;\n        updateFields.push(`title = $${paramCount}`);\n        params.push(updateItemDto.title);\n      }\n      if (updateItemDto.description !== undefined) {\n        paramCount++;\n        updateFields.push(`description = $${paramCount}`);\n        params.push(updateItemDto.description);\n      }\n      if (updateItemDto.category !== undefined) {\n        paramCount++;\n        updateFields.push(`category = $${paramCount}`);\n        params.push(updateItemDto.category);\n      }\n      if (updateItemDto.condition !== undefined) {\n        paramCount++;\n        updateFields.push(`condition = $${paramCount}`);\n        params.push(updateItemDto.condition);\n      }\n      if (updateItemDto.location !== undefined) {\n        paramCount++;\n        updateFields.push(`location = $${paramCount}::jsonb`);\n        params.push(JSON.stringify(updateItemDto.location));\n      }\n      if (updateItemDto.price !== undefined) {\n        paramCount++;\n        updateFields.push(`price = $${paramCount}`);\n        params.push(updateItemDto.price);\n      }\n      if (updateItemDto.images !== undefined) {\n        paramCount++;\n        updateFields.push(`images = $${paramCount}`);\n        params.push(updateItemDto.images);\n      }\n      if (updateItemDto.tags !== undefined) {\n        paramCount++;\n        updateFields.push(`tags = $${paramCount}`);\n        params.push(updateItemDto.tags);\n      }\n      if (updateItemDto.quantity !== undefined) {\n        paramCount++;\n        updateFields.push(`quantity = $${paramCount}`);\n        params.push(updateItemDto.quantity);\n      }\n      if (updateItemDto.status !== undefined) {\n        paramCount++;\n        updateFields.push(`status = $${paramCount}`);\n        params.push(updateItemDto.status);\n      }\n      if (updateItemDto.delivery_method !== undefined) {\n        paramCount++;\n        updateFields.push(`delivery_method = $${paramCount}`);\n        params.push(updateItemDto.delivery_method);\n      }\n      if (updateItemDto.metadata !== undefined) {\n        paramCount++;\n        updateFields.push(`metadata = $${paramCount}::jsonb`);\n        params.push(JSON.stringify(updateItemDto.metadata));\n      }\n      if (updateItemDto.expires_at !== undefined) {\n        paramCount++;\n        updateFields.push(`expires_at = $${paramCount}`);\n        params.push(\n          updateItemDto.expires_at ? new Date(updateItemDto.expires_at) : null,\n        );\n      }\n\n      if (updateFields.length === 0) {\n        return { success: false, error: \"No fields to update\" };\n      }\n\n      paramCount++;\n      updateFields.push(`updated_at = NOW()`);\n      params.push(id);\n\n      const { rows } = await client.query(\n        `\n        UPDATE items\n        SET ${updateFields.join(\", \")}\n        WHERE id = $${paramCount}\n        RETURNING *\n      `,\n        params,\n      );\n\n      if (rows.length === 0) {\n        return { success: false, error: \"Item not found\" };\n      }\n\n      await this.invalidateItemCaches();\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Update item error:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to update item\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  async deleteItem(id: string) {\n    const client = await this.pool.connect();\n    try {\n      const { rowCount } = await client.query(\n        `\n        DELETE FROM items WHERE id = $1\n      `,\n        [id],\n      );\n\n      if (rowCount === 0) {\n        return { success: false, error: \"Item not found\" };\n      }\n\n      await this.invalidateItemCaches();\n      return { success: true, message: \"Item deleted successfully\" };\n    } catch (error) {\n      this.logger.error(\"Delete item error:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to delete item\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ==================== Item Requests ====================\n\n  async createItemRequest(createRequestDto: CreateItemRequestDto) {\n    const client = await this.pool.connect();\n    try {\n      // Check if item exists and is available\n      const itemCheck = await client.query(\n        `\n        SELECT id, status, owner_id FROM items WHERE id = $1\n      `,\n        [createRequestDto.item_id],\n      );\n\n      if (itemCheck.rows.length === 0) {\n        return { success: false, error: \"Item not found\" };\n      }\n\n      if (itemCheck.rows[0].status !== \"available\") {\n        return { success: false, error: \"Item is not available\" };\n      }\n\n      // Check if requester is not the owner\n      if (itemCheck.rows[0].owner_id === createRequestDto.requester_id) {\n        return { success: false, error: \"Cannot request your own item\" };\n      }\n\n      // Check for existing pending request\n      const existingRequest = await client.query(\n        `\n        SELECT id FROM item_requests\n        WHERE item_id = $1 AND requester_id = $2 AND status = 'pending'\n      `,\n        [createRequestDto.item_id, createRequestDto.requester_id],\n      );\n\n      if (existingRequest.rows.length > 0) {\n        return {\n          success: false,\n          error: \"You already have a pending request for this item\",\n        };\n      }\n\n      const { rows } = await client.query(\n        `\n        INSERT INTO item_requests (\n          item_id, requester_id, message, proposed_time,\n          delivery_method, meeting_location\n        ) VALUES ($1, $2, $3, $4, $5, $6)\n        RETURNING *\n      `,\n        [\n          createRequestDto.item_id,\n          createRequestDto.requester_id,\n          createRequestDto.message || null,\n          createRequestDto.proposed_time\n            ? new Date(createRequestDto.proposed_time)\n            : null,\n          createRequestDto.delivery_method || null,\n          createRequestDto.meeting_location\n            ? JSON.stringify(createRequestDto.meeting_location)\n            : null,\n        ],\n      );\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Create item request error:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to create request\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  async getItemRequests(\n    itemId?: string,\n    userId?: string,\n    role: \"owner\" | \"requester\" = \"requester\",\n  ) {\n    let query = `\n      SELECT ir.*, \n             i.title as item_title, i.owner_id,\n             up_requester.name as requester_name, up_requester.avatar_url as requester_avatar,\n             up_owner.name as owner_name, up_owner.avatar_url as owner_avatar\n      FROM item_requests ir\n      JOIN items i ON ir.item_id = i.id\n      LEFT JOIN user_profiles up_requester ON (ir.requester_id::text = up_requester.id::text OR ir.requester_id::text = up_requester.firebase_uid)\n      LEFT JOIN user_profiles up_owner ON (i.owner_id::text = up_owner.id::text OR i.owner_id::text = up_owner.firebase_uid)\n      WHERE 1=1\n    `;\n    const params: any[] = [];\n    let paramCount = 0;\n\n    if (itemId) {\n      paramCount++;\n      query += ` AND ir.item_id = $${paramCount}`;\n      params.push(itemId);\n    }\n\n    if (userId) {\n      if (role === \"owner\") {\n        paramCount++;\n        query += ` AND i.owner_id = $${paramCount}`;\n        params.push(userId);\n      } else {\n        paramCount++;\n        query += ` AND ir.requester_id = $${paramCount}`;\n        params.push(userId);\n      }\n    }\n\n    query += ` ORDER BY ir.created_at DESC`;\n\n    const { rows } = await this.pool.query(query, params);\n    return { success: true, data: rows };\n  }\n\n  async updateItemRequest(\n    requestId: string,\n    updateRequestDto: UpdateItemRequestDto,\n    userId: string,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get the request with item info\n      const requestCheck = await client.query(\n        `\n        SELECT ir.*, i.owner_id, i.status as item_status\n        FROM item_requests ir\n        JOIN items i ON ir.item_id = i.id\n        WHERE ir.id = $1\n      `,\n        [requestId],\n      );\n\n      if (requestCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Request not found\" };\n      }\n\n      const request = requestCheck.rows[0];\n\n      // Check permissions\n      const isOwner = request.owner_id === userId;\n      const isRequester = request.requester_id === userId;\n\n      if (!isOwner && !isRequester) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Unauthorized\" };\n      }\n\n      // Build update query\n      const updateFields: string[] = [];\n      const params: any[] = [];\n      let paramCount = 0;\n\n      if (updateRequestDto.status !== undefined) {\n        // Only owner can approve/reject, requester can cancel\n        if (\n          updateRequestDto.status === \"approved\" ||\n          updateRequestDto.status === \"rejected\"\n        ) {\n          if (!isOwner) {\n            await client.query(\"ROLLBACK\");\n            return {\n              success: false,\n              error: \"Only owner can approve/reject requests\",\n            };\n          }\n        } else if (updateRequestDto.status === \"cancelled\") {\n          if (!isRequester) {\n            await client.query(\"ROLLBACK\");\n            return {\n              success: false,\n              error: \"Only requester can cancel their request\",\n            };\n          }\n        }\n\n        paramCount++;\n        updateFields.push(`status = $${paramCount}`);\n        params.push(updateRequestDto.status);\n\n        // If approved, mark item as reserved\n        if (updateRequestDto.status === \"approved\") {\n          await client.query(\n            `\n            UPDATE items SET status = 'reserved' WHERE id = $1\n          `,\n            [request.item_id],\n          );\n        }\n\n        // If completed, mark item as delivered\n        if (updateRequestDto.status === \"completed\") {\n          await client.query(\n            `\n            UPDATE items SET status = 'delivered' WHERE id = $1\n          `,\n            [request.item_id],\n          );\n        }\n\n        // If rejected or cancelled, mark item as available again\n        if (\n          updateRequestDto.status === \"rejected\" ||\n          updateRequestDto.status === \"cancelled\"\n        ) {\n          await client.query(\n            `\n            UPDATE items SET status = 'available' WHERE id = $1\n          `,\n            [request.item_id],\n          );\n        }\n      }\n\n      if (updateRequestDto.message !== undefined) {\n        paramCount++;\n        updateFields.push(`message = $${paramCount}`);\n        params.push(updateRequestDto.message);\n      }\n\n      if (updateRequestDto.proposed_time !== undefined) {\n        paramCount++;\n        updateFields.push(`proposed_time = $${paramCount}`);\n        params.push(\n          updateRequestDto.proposed_time\n            ? new Date(updateRequestDto.proposed_time)\n            : null,\n        );\n      }\n\n      if (updateRequestDto.owner_response !== undefined) {\n        if (!isOwner) {\n          await client.query(\"ROLLBACK\");\n          return { success: false, error: \"Only owner can set response\" };\n        }\n        paramCount++;\n        updateFields.push(`owner_response = $${paramCount}`);\n        params.push(updateRequestDto.owner_response);\n      }\n\n      if (updateFields.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"No fields to update\" };\n      }\n\n      paramCount++;\n      updateFields.push(`updated_at = NOW()`);\n      params.push(requestId);\n\n      const { rows } = await client.query(\n        `\n        UPDATE item_requests\n        SET ${updateFields.join(\", \")}\n        WHERE id = $${paramCount}\n        RETURNING *\n      `,\n        params,\n      );\n\n      await client.query(\"COMMIT\");\n      await this.invalidateItemCaches();\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Update item request error:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to update request\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ==================== Cache Management ====================\n\n  private async invalidateItemCaches() {\n    const patterns = [\"items_list:*\", \"item:*\"];\n    for (const pattern of patterns) {\n      const keys = await this.redisCache.getKeys(pattern);\n      for (const key of keys) {\n        await this.redisCache.delete(key);\n      }\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/notifications.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":35,"column":43,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":35,"endColumn":46,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[931,934],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[931,934],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  Controller,\n  Get,\n  Post,\n  Put,\n  Delete,\n  Param,\n  UseGuards,\n  Inject,\n  Query,\n  Req,\n  UnauthorizedException,\n  Logger,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { ThrottlerGuard } from \"@nestjs/throttler\";\nimport { JwtAuthGuard } from \"../auth/jwt-auth.guard\";\nimport { Request } from \"express\";\n\n@Controller(\"api/notifications\")\n@UseGuards(ThrottlerGuard, JwtAuthGuard) // H3/SEC-003.2: Auth required\nexport class NotificationsController {\n  private readonly logger = new Logger(NotificationsController.name);\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  /**\n   * Ensure user_notifications table exists\n   * Creates it if missing (idempotent)\n   */\n  private async ensureTableExists(client: any): Promise<void> {\n    try {\n      // Ensure uuid-ossp extension exists (required for uuid_generate_v4)\n      await client.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";');\n\n      // Check if table exists\n      const checkResult = await client.query(`\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_schema = 'public' \n                    AND table_name = 'user_notifications'\n                );\n            `);\n\n      if (!checkResult.rows[0]?.exists) {\n        this.logger.log(\"Creating user_notifications table...\");\n        await client.query(`\n                    CREATE TABLE user_notifications (\n                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                        user_id UUID,\n                        title VARCHAR(255),\n                        content TEXT,\n                        notification_type VARCHAR(50),\n                        related_id UUID,\n                        is_read BOOLEAN DEFAULT false,\n                        read_at TIMESTAMPTZ,\n                        metadata JSONB,\n                        created_at TIMESTAMPTZ DEFAULT NOW()\n                    );\n                `);\n\n        // Create indexes for better performance\n        await client.query(`\n                    CREATE INDEX IF NOT EXISTS idx_user_notifications_user_id \n                    ON user_notifications(user_id);\n                `);\n        await client.query(`\n                    CREATE INDEX IF NOT EXISTS idx_user_notifications_created_at \n                    ON user_notifications(created_at DESC);\n                `);\n        await client.query(`\n                    CREATE INDEX IF NOT EXISTS idx_user_notifications_is_read \n                    ON user_notifications(user_id, is_read) \n                    WHERE is_read = false;\n                `);\n\n        this.logger.log(\"user_notifications table created successfully\");\n      }\n    } catch (error) {\n      this.logger.error(\"Error ensuring user_notifications table:\", error);\n      throw error;\n    }\n  }\n\n  /**\n   * SEC-003.2: Validate that the authenticated user owns the resource\n   * Admins can access any user's notifications\n   */\n  private validateOwnership(req: Request, userId: string): void {\n    const authUser = req.user;\n    if (!authUser) {\n      throw new UnauthorizedException(\"Authentication required\");\n    }\n    const isOwner = authUser.userId === userId;\n    const isAdmin =\n      authUser.roles?.includes(\"admin\") ||\n      authUser.roles?.includes(\"super_admin\");\n    if (!isOwner && !isAdmin) {\n      throw new UnauthorizedException(\n        \"You can only access your own notifications\",\n      );\n    }\n  }\n\n  @Get(\":userId\")\n  async getUserNotifications(\n    @Param(\"userId\") userId: string,\n    @Query(\"limit\") limit = \"50\",\n    @Query(\"offset\") offset = \"0\",\n    @Req() req: Request,\n  ) {\n    this.validateOwnership(req, userId);\n    this.logger.debug(`getUserNotifications for userId: ${userId}`);\n\n    // Validate UUID format to prevent 500 errors\n    const uuidRegex =\n      /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n    if (!uuidRegex.test(userId)) {\n      this.logger.warn(`Invalid UUID provided: ${userId}`);\n      return { success: false, error: \"Invalid user ID format\" };\n    }\n\n    try {\n      const client = await this.pool.connect();\n      try {\n        await this.ensureTableExists(client);\n        const query = `\n          SELECT \n            id,\n            user_id as \"userId\",\n            title,\n            content as body,\n            notification_type as type,\n            related_id as \"relatedId\",\n            is_read as read,\n            metadata as data,\n            created_at as timestamp\n          FROM user_notifications\n          WHERE user_id = $1\n          ORDER BY created_at DESC\n          LIMIT $2 OFFSET $3\n        `;\n\n        const { rows } = await client.query(query, [\n          userId,\n          parseInt(limit),\n          parseInt(offset),\n        ]);\n\n        return {\n          success: true,\n          data: rows.map((row) => ({\n            ...row,\n            // Ensure data includes type for frontend compatibility\n            data: {\n              ...(row.data || {}),\n              type: row.type,\n              relatedId: row.relatedId,\n            },\n          })),\n        };\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"Error fetching notifications:\", error);\n      return { success: false, error: \"Failed to fetch notifications\" };\n    }\n  }\n\n  @Post(\":userId/read-all\")\n  async markAllAsRead(@Param(\"userId\") userId: string, @Req() req: Request) {\n    this.validateOwnership(req, userId);\n    try {\n      const client = await this.pool.connect();\n      try {\n        await this.ensureTableExists(client);\n        await client.query(\n          \"UPDATE user_notifications SET is_read = true, read_at = NOW() WHERE user_id = $1\",\n          [userId],\n        );\n        return { success: true };\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"Error marking all notifications as read:\", error);\n      return { success: false, error: \"Failed to mark notifications as read\" };\n    }\n  }\n\n  @Put(\":userId/:notificationId/read\")\n  async markAsRead(\n    @Param(\"userId\") userId: string,\n    @Param(\"notificationId\") notificationId: string,\n    @Req() req: Request,\n  ) {\n    this.validateOwnership(req, userId);\n    try {\n      const client = await this.pool.connect();\n      try {\n        await this.ensureTableExists(client);\n        await client.query(\n          \"UPDATE user_notifications SET is_read = true, read_at = NOW() WHERE id = $1 AND user_id = $2\",\n          [notificationId, userId],\n        );\n        return { success: true };\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"Error marking notification as read:\", error);\n      return { success: false, error: \"Failed to mark notification as read\" };\n    }\n  }\n\n  @Delete(\":userId/:notificationId\")\n  async deleteNotification(\n    @Param(\"userId\") userId: string,\n    @Param(\"notificationId\") notificationId: string,\n    @Req() req: Request,\n  ) {\n    this.validateOwnership(req, userId);\n    try {\n      const client = await this.pool.connect();\n      try {\n        await this.ensureTableExists(client);\n        await client.query(\n          \"DELETE FROM user_notifications WHERE id = $1 AND user_id = $2\",\n          [notificationId, userId],\n        );\n        return { success: true };\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"Error deleting notification:\", error);\n      return { success: false, error: \"Failed to delete notification\" };\n    }\n  }\n\n  @Delete(\":userId\")\n  async clearAllNotifications(\n    @Param(\"userId\") userId: string,\n    @Req() req: Request,\n  ) {\n    this.validateOwnership(req, userId);\n    try {\n      const client = await this.pool.connect();\n      try {\n        await this.ensureTableExists(client);\n        await client.query(\n          \"DELETE FROM user_notifications WHERE user_id = $1\",\n          [userId],\n        );\n        return { success: true };\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"Error clearing notifications:\", error);\n      return { success: false, error: \"Failed to clear notifications\" };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/places.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":43,"column":45,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":43,"endColumn":48,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1496,1499],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1496,1499],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":73,"column":45,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":73,"endColumn":48,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2397,2400],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2397,2400],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Places autocomplete and details via Google Places API, with Redis caching and simple analytics.\n// - Reached from: Routes '/autocomplete', '/place-details', '/search-stats'.\n// - Env inputs: GOOGLE_API_KEY; language fixed to he-IL and country IL.\n// - Provides: Caching for autocomplete results, simple Redis-based search metrics.\nimport { Controller, Get, Query } from \"@nestjs/common\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n@Controller()\nexport class PlacesController {\n  constructor(private readonly redisCache: RedisCacheService) {}\n\n  @Get(\"autocomplete\")\n  async autocomplete(@Query(\"input\") input?: string) {\n    if (!input) {\n      return { error: \"Missing input parameter\" };\n    }\n\n    // Check cache first\n    const cacheKey = `places:autocomplete:${input.toLowerCase()}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      // Track search activity\n      await this.trackSearchActivity(input, \"cached\");\n      return {\n        predictions: cached,\n        cached: true,\n        source: \"redis\",\n      };\n    }\n\n    const apiKey = process.env.GOOGLE_API_KEY;\n    if (!apiKey) {\n      return { error: \"Missing GOOGLE_API_KEY\" };\n    }\n\n    const url = `https://maps.googleapis.com/maps/api/place/autocomplete/json?input=${encodeURIComponent(\n      input,\n    )}&key=${apiKey}&language=he&components=country:il`;\n\n    const response = await fetch(url);\n    const data = (await response.json()) as any;\n\n    if (data.status !== \"OK\") {\n      return { error: data.status, message: data.error_message };\n    }\n\n    // Cache the results for 10 minutes\n    await this.redisCache.set(cacheKey, data.predictions, 10 * 60);\n\n    // Track search activity\n    await this.trackSearchActivity(input, \"api\");\n\n    return {\n      predictions: data.predictions,\n      cached: false,\n      source: \"google_api\",\n    };\n  }\n\n  @Get(\"place-details\")\n  async placeDetails(@Query(\"place_id\") placeId?: string) {\n    if (!placeId) {\n      return { error: \"Missing place_id parameter\" };\n    }\n    const apiKey = process.env.GOOGLE_API_KEY;\n    if (!apiKey) {\n      return { error: \"Missing GOOGLE_API_KEY\" };\n    }\n    const url = `https://maps.googleapis.com/maps/api/place/details/json?place_id=${placeId}&key=${apiKey}&language=he`;\n    const response = await fetch(url);\n    const data = (await response.json()) as any;\n    if (data.status !== \"OK\") {\n      return { error: data.status, message: data.error_message };\n    }\n    return data.result;\n  }\n\n  @Get(\"search-stats\")\n  async getSearchStats() {\n    try {\n      const stats = await this.getPlacesStats();\n      return {\n        success: true,\n        stats,\n        message: \"Places search statistics from Redis\",\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  private async trackSearchActivity(\n    searchTerm: string,\n    source: \"cached\" | \"api\",\n  ) {\n    const searchKey = `search_activity:${searchTerm.toLowerCase()}`;\n    const globalKey = \"global_search_stats\";\n\n    // Track individual search\n    await this.redisCache.increment(searchKey);\n\n    // Track global stats\n    const globalStats = (await this.redisCache.get(globalKey)) || {\n      totalSearches: 0,\n      cacheHits: 0,\n      apiCalls: 0,\n      lastUpdated: new Date().toISOString(),\n    };\n\n    globalStats.totalSearches++;\n    if (source === \"cached\") {\n      globalStats.cacheHits++;\n    } else {\n      globalStats.apiCalls++;\n    }\n    globalStats.lastUpdated = new Date().toISOString();\n\n    await this.redisCache.set(globalKey, globalStats, 24 * 60 * 60); // 24 hours\n  }\n\n  private async getPlacesStats() {\n    const searchKeys = await this.redisCache.getKeys(\"search_activity:*\");\n    const cacheKeys = await this.redisCache.getKeys(\"places:autocomplete:*\");\n    const globalStats = (await this.redisCache.get(\"global_search_stats\")) || {\n      totalSearches: 0,\n      cacheHits: 0,\n      apiCalls: 0,\n    };\n\n    const popularSearches = [];\n    for (const key of searchKeys.slice(0, 10)) {\n      // Top 10\n      const searchTerm = key.replace(\"search_activity:\", \"\");\n      const count = (await this.redisCache.get<number>(key)) || 0;\n      popularSearches.push({ searchTerm, count });\n    }\n\n    popularSearches.sort((a, b) => b.count - a.count);\n\n    return {\n      ...globalStats,\n      cachedResults: cacheKeys.length,\n      uniqueSearches: searchKeys.length,\n      popularSearches: popularSearches.slice(0, 5),\n      cacheHitRate:\n        globalStats.totalSearches > 0\n          ? Math.round(\n              (globalStats.cacheHits / globalStats.totalSearches) * 100,\n            )\n          : 0,\n    };\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/posts.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":174,"column":67,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":174,"endColumn":70,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6428,6431],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6428,6431],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":672,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":672,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[27828,27831],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[27828,27831],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1785,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1785,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[62319,62322],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[62319,62322],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1824,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1824,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[63392,63395],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[63392,63395],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1922,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1922,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[66048,66051],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[66048,66051],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2005,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2005,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[68316,68319],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[68316,68319],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2095,"column":65,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2095,"endColumn":68,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[71017,71020],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[71017,71020],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":7,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import {\n  Controller,\n  Get,\n  Post,\n  Put,\n  Delete,\n  Param,\n  Query,\n  Body,\n  Inject,\n  UseGuards,\n  Req,\n  Logger,\n} from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { JwtAuthGuard } from \"../auth/jwt-auth.guard\";\n\ninterface LikeBody {\n  user_id: string;\n}\n\ninterface CommentBody {\n  user_id: string;\n  text: string;\n}\n\ninterface UpdateCommentBody {\n  user_id: string;\n  text: string;\n}\n\n@Controller(\"api/posts\")\nexport class PostsController {\n  private readonly logger = new Logger(PostsController.name);\n  private readonly CACHE_TTL = 5 * 60; // 5 minutes cache\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {\n    this.logger.log(\"🔄 PostsController initialized\");\n  }\n\n  /**\n   * Ensure posts table exists with correct schema, create/migrate if needed\n   */\n  private async ensurePostsTable() {\n    try {\n      // Ensure uuid-ossp extension exists (required for uuid_generate_v4)\n      await this.pool.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";');\n\n      // Check if posts table exists\n      const tableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'posts' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (tableCheck.rows[0]?.exists) {\n        // Check for critical columns\n        const columnsCheck = await this.pool.query(`\n                    SELECT column_name \n                    FROM information_schema.columns \n                    WHERE table_name = 'posts' AND table_schema = 'public'\n                `);\n\n        const columns = columnsCheck.rows.map((r) => r.column_name);\n\n        // If id or author_id is missing, the table structure is fundamentally wrong (legacy)\n        // We can't add id column later since it's the primary key\n        if (!columns.includes(\"id\") || !columns.includes(\"author_id\")) {\n          this.logger.log(\n            \"⚠️  Detected legacy posts table structure - recreating...\",\n          );\n          this.logger.log(`   - Has id column: ${columns.includes(\"id\")}`);\n          this.logger.log(\n            `   - Has author_id column: ${columns.includes(\"author_id\")}`,\n          );\n          await this.pool.query(\"DROP TABLE IF EXISTS posts CASCADE;\");\n        } else {\n          // Check for new columns and add them if missing\n          if (!columns.includes(\"post_type\")) {\n            this.logger.log(\"📝 Adding post_type column to posts table...\");\n            await this.pool.query(\n              \"ALTER TABLE posts ADD COLUMN post_type VARCHAR(50) DEFAULT 'task_completion';\",\n            );\n            await this.pool.query(\n              \"CREATE INDEX IF NOT EXISTS idx_posts_post_type ON posts(post_type);\",\n            );\n          }\n\n          if (!columns.includes(\"task_id\")) {\n            this.logger.log(\"📝 Adding task_id column to posts table...\");\n            await this.pool.query(\n              \"ALTER TABLE posts ADD COLUMN task_id UUID REFERENCES tasks(id) ON DELETE SET NULL;\",\n            );\n            await this.pool.query(\n              \"CREATE INDEX IF NOT EXISTS idx_posts_task_id ON posts(task_id);\",\n            );\n          }\n\n          if (!columns.includes(\"ride_id\")) {\n            this.logger.log(\"📝 Adding ride_id column to posts table...\");\n            await this.pool.query(\n              \"ALTER TABLE posts ADD COLUMN ride_id UUID REFERENCES rides(id) ON DELETE CASCADE;\",\n            );\n            await this.pool.query(\n              \"CREATE INDEX IF NOT EXISTS idx_posts_ride_id ON posts(ride_id);\",\n            );\n\n            // Migrate existing ride posts from metadata to ride_id column\n            this.logger.log(\n              \"📝 Migrating existing ride posts to use ride_id column...\",\n            );\n            await this.pool.query(`\n                            UPDATE posts \n                            SET ride_id = (metadata->>'ride_id')::uuid \n                            WHERE post_type = 'ride' \n                            AND metadata->>'ride_id' IS NOT NULL\n                            AND ride_id IS NULL;\n                        `);\n          }\n\n          if (!columns.includes(\"item_id\")) {\n            this.logger.log(\"📝 Adding item_id column to posts table...\");\n            // item_id must be TEXT because items.id is TEXT (to support various ID formats)\n            await this.pool.query(\"ALTER TABLE posts ADD COLUMN item_id TEXT;\");\n            await this.pool.query(\n              \"CREATE INDEX IF NOT EXISTS idx_posts_item_id ON posts(item_id);\",\n            );\n\n            // Migrate existing item/donation posts from metadata to item_id column\n            this.logger.log(\n              \"📝 Migrating existing item/donation posts to use item_id column...\",\n            );\n            await this.pool.query(`\n                            UPDATE posts \n                            SET item_id = metadata->>'item_id'\n                            WHERE post_type IN ('item', 'donation') \n                            AND metadata->>'item_id' IS NOT NULL\n                            AND item_id IS NULL;\n                        `);\n          }\n\n          if (!columns.includes(\"metadata\")) {\n            this.logger.log(\"📝 Adding metadata column to posts table...\");\n            await this.pool.query(\n              \"ALTER TABLE posts ADD COLUMN metadata JSONB DEFAULT '{}'::jsonb;\",\n            );\n          }\n\n          if (!columns.includes(\"status\")) {\n            this.logger.log(\"📝 Adding status column to posts table...\");\n            await this.pool.query(\n              \"ALTER TABLE posts ADD COLUMN status VARCHAR(50) DEFAULT 'active';\",\n            );\n            await this.pool.query(\n              \"CREATE INDEX IF NOT EXISTS idx_posts_status ON posts(status);\",\n            );\n          }\n\n          // Ensure item_id is TEXT (fix for previous failed migrations)\n          try {\n            await this.pool.query(\n              \"ALTER TABLE posts DROP CONSTRAINT IF EXISTS posts_item_id_fkey;\",\n            );\n            await this.pool.query(\n              \"ALTER TABLE posts ALTER COLUMN item_id TYPE TEXT;\",\n            );\n          } catch (e) {\n            this.logger.log(\"ℹ️  Note: item_id fix check:\", (e as any).message);\n          }\n\n          // Table exists and is patched\n          return;\n        }\n      }\n\n      // Create posts table with correct schema (if dropped or didn't exist)\n      await this.pool.query(`\n                CREATE TABLE IF NOT EXISTS posts (\n                    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                    author_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                    task_id UUID REFERENCES tasks(id) ON DELETE SET NULL,\n                    ride_id UUID REFERENCES rides(id) ON DELETE CASCADE,\n                    item_id TEXT, -- No FK to items table as it uses composite PK and text IDs\n                    title VARCHAR(255) NOT NULL,\n                    description TEXT,\n                    images TEXT[],\n                    likes INTEGER DEFAULT 0,\n                    comments INTEGER DEFAULT 0,\n                    post_type VARCHAR(50) DEFAULT 'task_completion',\n                    status VARCHAR(50) DEFAULT 'active',\n                    metadata JSONB DEFAULT '{}'::jsonb,\n                    created_at TIMESTAMPTZ DEFAULT NOW(),\n                    updated_at TIMESTAMPTZ DEFAULT NOW()\n                )\n            `);\n\n      // SEC-002.4: Create indexes individually — no string interpolation in SQL\n      const indexQueries = [\n        \"CREATE INDEX IF NOT EXISTS idx_posts_author_id ON posts(author_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_task_id ON posts(task_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_ride_id ON posts(ride_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_item_id ON posts(item_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_created_at ON posts(created_at DESC)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_post_type ON posts(post_type)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_status ON posts(status)\",\n      ];\n\n      for (const q of indexQueries) {\n        try {\n          await this.pool.query(q);\n        } catch {\n          // index may already exist\n        }\n      }\n\n      // Create trigger for updated_at\n      try {\n        await this.pool.query(`\n                    DROP TRIGGER IF EXISTS update_posts_updated_at ON posts;\n                    CREATE TRIGGER update_posts_updated_at \n                        BEFORE UPDATE ON posts \n                        FOR EACH ROW \n                        EXECUTE FUNCTION update_updated_at_column();\n                `);\n      } catch {\n        this.logger.log(\n          \"⚠️ Could not create update_posts_updated_at trigger (function might not exist)\",\n        );\n      }\n\n      this.logger.log(\"✅ Posts table ensured with correct schema\");\n    } catch (error) {\n      this.logger.error(\"❌ Failed to ensure posts table:\", error);\n      // Don't throw - allow code to continue, but log the error\n    }\n  }\n\n  /**\n   * Ensure likes and comments tables exist\n   */\n  private async ensureLikesCommentsTable() {\n    try {\n      this.logger.log(\"📝 Ensuring likes and comments tables exist...\");\n\n      // First, verify that posts table exists (required for foreign keys)\n      const postsTableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'posts' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (!postsTableCheck.rows[0]?.exists) {\n        this.logger.log(\n          \"⚠️  Posts table does not exist yet - skipping likes/comments table creation\",\n        );\n        return;\n      }\n\n      // Check if post_likes table exists and has correct structure\n      const likesTableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'post_likes' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (!likesTableCheck.rows[0]?.exists) {\n        this.logger.log(\"📝 Creating post_likes table...\");\n        await this.pool.query(`\n                    CREATE TABLE post_likes (\n                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                        post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,\n                        user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                        created_at TIMESTAMPTZ DEFAULT NOW(),\n                        UNIQUE(post_id, user_id)\n                    );\n                `);\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_likes_post_id ON post_likes(post_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_likes_user_id ON post_likes(user_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_likes_created_at ON post_likes(created_at DESC);`,\n        );\n        this.logger.log(\"✅ post_likes table created\");\n      } else {\n        // Check if id column exists\n        const idColumnCheck = await this.pool.query(`\n                    SELECT EXISTS (\n                        SELECT 1 FROM information_schema.columns \n                        WHERE table_name = 'post_likes' AND column_name = 'id' AND table_schema = 'public'\n                    ) AS exists;\n                `);\n        if (!idColumnCheck.rows[0]?.exists) {\n          this.logger.log(\n            \"⚠️ post_likes table exists but missing id column - recreating...\",\n          );\n          await this.pool.query(`DROP TABLE IF EXISTS post_likes CASCADE;`);\n          await this.pool.query(`\n                        CREATE TABLE post_likes (\n                            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                            post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,\n                            user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                            created_at TIMESTAMPTZ DEFAULT NOW(),\n                            UNIQUE(post_id, user_id)\n                        );\n                    `);\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_likes_post_id ON post_likes(post_id);`,\n          );\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_likes_user_id ON post_likes(user_id);`,\n          );\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_likes_created_at ON post_likes(created_at DESC);`,\n          );\n          this.logger.log(\"✅ post_likes table recreated\");\n        }\n      }\n\n      // Check if post_comments table exists and has correct structure\n      const commentsTableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'post_comments' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (!commentsTableCheck.rows[0]?.exists) {\n        this.logger.log(\"📝 Creating post_comments table...\");\n        await this.pool.query(`\n                    CREATE TABLE post_comments (\n                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                        post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,\n                        user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                        text TEXT NOT NULL CHECK (char_length(text) > 0 AND char_length(text) <= 2000),\n                        likes_count INTEGER DEFAULT 0,\n                        created_at TIMESTAMPTZ DEFAULT NOW(),\n                        updated_at TIMESTAMPTZ DEFAULT NOW()\n                    );\n                `);\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_comments_post_id ON post_comments(post_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_comments_user_id ON post_comments(user_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_post_comments_created_at ON post_comments(created_at DESC);`,\n        );\n        this.logger.log(\"✅ post_comments table created\");\n      } else {\n        // Check if id column exists\n        const idColumnCheck = await this.pool.query(`\n                    SELECT EXISTS (\n                        SELECT 1 FROM information_schema.columns \n                        WHERE table_name = 'post_comments' AND column_name = 'id' AND table_schema = 'public'\n                    ) AS exists;\n                `);\n        if (!idColumnCheck.rows[0]?.exists) {\n          this.logger.log(\n            \"⚠️ post_comments table exists but missing id column - recreating...\",\n          );\n          await this.pool.query(`DROP TABLE IF EXISTS comment_likes CASCADE;`);\n          await this.pool.query(`DROP TABLE IF EXISTS post_comments CASCADE;`);\n          await this.pool.query(`\n                        CREATE TABLE post_comments (\n                            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                            post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,\n                            user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                            text TEXT NOT NULL CHECK (char_length(text) > 0 AND char_length(text) <= 2000),\n                            likes_count INTEGER DEFAULT 0,\n                            created_at TIMESTAMPTZ DEFAULT NOW(),\n                            updated_at TIMESTAMPTZ DEFAULT NOW()\n                        );\n                    `);\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_comments_post_id ON post_comments(post_id);`,\n          );\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_comments_user_id ON post_comments(user_id);`,\n          );\n          await this.pool.query(\n            `CREATE INDEX IF NOT EXISTS idx_post_comments_created_at ON post_comments(created_at DESC);`,\n          );\n          this.logger.log(\"✅ post_comments table recreated\");\n        }\n      }\n\n      // Check if comment_likes table exists\n      const commentLikesTableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'comment_likes' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (!commentLikesTableCheck.rows[0]?.exists) {\n        this.logger.log(\"📝 Creating comment_likes table...\");\n        await this.pool.query(`\n                    CREATE TABLE comment_likes (\n                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                        comment_id UUID NOT NULL REFERENCES post_comments(id) ON DELETE CASCADE,\n                        user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n                        created_at TIMESTAMPTZ DEFAULT NOW(),\n                        UNIQUE(comment_id, user_id)\n                    );\n                `);\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_comment_likes_comment_id ON comment_likes(comment_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_comment_likes_user_id ON comment_likes(user_id);`,\n        );\n        this.logger.log(\"✅ comment_likes table created\");\n      }\n\n      // Check if user_notifications table exists (required for notifications)\n      const notificationsTableCheck = await this.pool.query(`\n                SELECT EXISTS (\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'user_notifications' AND table_schema = 'public'\n                ) AS exists;\n            `);\n\n      if (!notificationsTableCheck.rows[0]?.exists) {\n        this.logger.log(\"📝 Creating user_notifications table...\");\n        await this.pool.query(`\n                    CREATE TABLE user_notifications (\n                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n                        user_id UUID,\n                        title VARCHAR(255),\n                        content TEXT,\n                        notification_type VARCHAR(50),\n                        related_id UUID,\n                        is_read BOOLEAN DEFAULT false,\n                        read_at TIMESTAMPTZ,\n                        metadata JSONB,\n                        created_at TIMESTAMPTZ DEFAULT NOW()\n                    );\n                `);\n\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_user_notifications_user_id ON user_notifications(user_id);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_user_notifications_created_at ON user_notifications(created_at DESC);`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_user_notifications_is_read ON user_notifications(user_id, is_read) WHERE is_read = false;`,\n        );\n\n        this.logger.log(\"✅ user_notifications table created\");\n      }\n\n      // Create SQL functions for updating counts\n      this.logger.log(\"📝 Ensuring SQL functions exist...\");\n\n      // Function to update post likes count\n      await this.pool.query(`\n                CREATE OR REPLACE FUNCTION update_post_likes_count()\n                RETURNS TRIGGER AS $$\n                BEGIN\n                    IF TG_OP = 'INSERT' THEN\n                        UPDATE posts SET likes = likes + 1, updated_at = NOW() WHERE id = NEW.post_id;\n                        RETURN NEW;\n                    ELSIF TG_OP = 'DELETE' THEN\n                        UPDATE posts SET likes = GREATEST(0, likes - 1), updated_at = NOW() WHERE id = OLD.post_id;\n                        RETURN OLD;\n                    END IF;\n                    RETURN NULL;\n                END;\n                $$ LANGUAGE plpgsql;\n            `);\n\n      // Function to update post comments count\n      await this.pool.query(`\n                CREATE OR REPLACE FUNCTION update_post_comments_count()\n                RETURNS TRIGGER AS $$\n                BEGIN\n                    IF TG_OP = 'INSERT' THEN\n                        UPDATE posts SET comments = comments + 1, updated_at = NOW() WHERE id = NEW.post_id;\n                        RETURN NEW;\n                    ELSIF TG_OP = 'DELETE' THEN\n                        UPDATE posts SET comments = GREATEST(0, comments - 1), updated_at = NOW() WHERE id = OLD.post_id;\n                        RETURN OLD;\n                    END IF;\n                    RETURN NULL;\n                END;\n                $$ LANGUAGE plpgsql;\n            `);\n\n      // Function to update comment likes count\n      await this.pool.query(`\n                CREATE OR REPLACE FUNCTION update_comment_likes_count()\n                RETURNS TRIGGER AS $$\n                BEGIN\n                    IF TG_OP = 'INSERT' THEN\n                        UPDATE post_comments SET likes_count = likes_count + 1, updated_at = NOW() WHERE id = NEW.comment_id;\n                        RETURN NEW;\n                    ELSIF TG_OP = 'DELETE' THEN\n                        UPDATE post_comments SET likes_count = GREATEST(0, likes_count - 1), updated_at = NOW() WHERE id = OLD.comment_id;\n                        RETURN OLD;\n                    END IF;\n                    RETURN NULL;\n                END;\n                $$ LANGUAGE plpgsql;\n            `);\n\n      this.logger.log(\"✅ SQL functions ensured\");\n\n      // Create triggers\n      this.logger.log(\"📝 Ensuring triggers exist...\");\n\n      // Trigger for post_likes\n      await this.pool.query(`\n                DROP TRIGGER IF EXISTS trigger_update_post_likes_count ON post_likes;\n                CREATE TRIGGER trigger_update_post_likes_count\n                    AFTER INSERT OR DELETE ON post_likes\n                    FOR EACH ROW\n                    EXECUTE FUNCTION update_post_likes_count();\n            `);\n\n      // Trigger for post_comments\n      await this.pool.query(`\n                DROP TRIGGER IF EXISTS trigger_update_post_comments_count ON post_comments;\n                CREATE TRIGGER trigger_update_post_comments_count\n                    AFTER INSERT OR DELETE ON post_comments\n                    FOR EACH ROW\n                    EXECUTE FUNCTION update_post_comments_count();\n            `);\n\n      // Trigger for comment_likes\n      await this.pool.query(`\n                DROP TRIGGER IF EXISTS trigger_update_comment_likes_count ON comment_likes;\n                CREATE TRIGGER trigger_update_comment_likes_count\n                    AFTER INSERT OR DELETE ON comment_likes\n                    FOR EACH ROW\n                    EXECUTE FUNCTION update_comment_likes_count();\n            `);\n\n      // Trigger for post_comments updated_at\n      await this.pool\n        .query(\n          `\n                DROP TRIGGER IF EXISTS update_post_comments_updated_at ON post_comments;\n                CREATE TRIGGER update_post_comments_updated_at \n                    BEFORE UPDATE ON post_comments \n                    FOR EACH ROW \n                    EXECUTE FUNCTION update_updated_at_column();\n            `,\n        )\n        .catch(() => {\n          // Function might not exist, that's okay\n          this.logger.log(\n            \"⚠️ update_updated_at_column function not found, skipping trigger\",\n          );\n        });\n\n      this.logger.log(\"✅ Triggers ensured\");\n    } catch (error) {\n      this.logger.error(\"❌ Failed to ensure likes/comments tables:\", error);\n    }\n  }\n\n  // ============================================\n  // POSTS ENDPOINTS\n  // ============================================\n\n  @Get()\n  async getPosts(\n    @Query(\"limit\") limitArg: string,\n    @Query(\"offset\") offsetArg: string,\n    @Query(\"user_id\") userId?: string,\n    @Query(\"post_type\") postType?: string,\n    @Query(\"item_id\") itemId?: string,\n    @Query(\"ride_id\") rideId?: string,\n  ) {\n    try {\n      await this.ensurePostsTable();\n      await this.ensureLikesCommentsTable();\n\n      const limit = parseInt(limitArg) || 20;\n      const offset = parseInt(offsetArg) || 0;\n\n      // Build query with optional user_id for checking if user liked each post\n      // Use explicit column names to avoid conflicts in JOIN queries\n      let query = `\n                SELECT \n                    p.id,\n                    p.author_id,\n                    p.task_id,\n                    p.ride_id,\n                    p.item_id,\n                    p.title,\n                    p.description,\n                    p.images,\n                    p.likes,\n                    p.comments,\n                    p.post_type,\n                    p.metadata,\n                    p.created_at,\n                    p.updated_at,\n                    CASE \n                        WHEN u.id IS NOT NULL THEN json_build_object('id', u.id, 'name', COALESCE(u.name, 'ללא שם'), 'avatar_url', COALESCE(u.avatar_url, ''))\n                        ELSE json_build_object('id', p.author_id, 'name', 'משתמש לא נמצא', 'avatar_url', '')\n                    END as author,\n                    CASE WHEN t.id IS NOT NULL THEN json_build_object(\n                        'id', t.id, \n                        'title', t.title, \n                        'description', t.description,\n                        'status', t.status,\n                        'estimated_hours', t.estimated_hours,\n                        'due_date', t.due_date,\n                        'assignees', (\n                            SELECT json_agg(json_build_object(\n                                'id', u_assignee.id, \n                                'name', u_assignee.name, \n                                'avatar', u_assignee.avatar_url\n                            ))\n                            FROM user_profiles u_assignee\n                            WHERE u_assignee.id = ANY(t.assignees)\n                        )\n                    ) ELSE NULL END as task,\n                    CASE \n                        WHEN r.id IS NOT NULL THEN json_build_object(\n                            'id', r.id, \n                            'from_location', r.from_location,\n                            'to_location', r.to_location,\n                            'departure_time', r.departure_time,\n                            'available_seats', r.available_seats,\n                            'price_per_seat', r.price_per_seat,\n                            'status', r.status\n                        ) \n                        ELSE NULL \n                    END as ride_data,\n                    CASE \n                        WHEN i.id IS NOT NULL THEN json_build_object(\n                            'id', i.id,\n                            'title', i.title,\n                            'status', i.status\n                        )\n                        ELSE NULL\n                    END as item_data\n            `;\n\n      // Check if post_likes table exists before using it\n      let postLikesExists = false;\n      try {\n        const res = await this.pool.query(`\n                    SELECT EXISTS (\n                        SELECT 1 FROM information_schema.tables \n                        WHERE table_name = 'post_likes' AND table_schema = 'public'\n                    ) AS exists;\n                `);\n        postLikesExists = res.rows[0]?.exists;\n      } catch {\n        // Ignore\n      }\n\n      // Build WHERE conditions first to know param count\n      const whereConditions: string[] = [];\n      const params: any[] = [limit, offset];\n      let paramIndex = 3;\n\n      // Filter out hidden posts by default (unless viewing own profile)\n      whereConditions.push(`(p.status IS NULL OR p.status != 'hidden')`);\n\n      if (postType) {\n        whereConditions.push(`p.post_type = $${paramIndex}`);\n        params.push(postType);\n        paramIndex++;\n      }\n\n      if (itemId) {\n        whereConditions.push(`p.item_id = $${paramIndex}`);\n        params.push(itemId);\n        paramIndex++;\n      }\n\n      if (rideId) {\n        whereConditions.push(`p.ride_id = $${paramIndex}`);\n        params.push(rideId);\n        paramIndex++;\n      }\n\n      // Now we know the param index for userId\n      const userIdParamIndex = paramIndex;\n\n      if (userId && postLikesExists) {\n        query += `,\n                    EXISTS(SELECT 1 FROM post_likes pl WHERE pl.post_id = p.id AND pl.user_id = $${userIdParamIndex}) as is_liked\n                `;\n        params.push(userId);\n      } else {\n        query += `,\n                    false as is_liked\n                `;\n      }\n\n      query += `\n                FROM posts p\n                LEFT JOIN user_profiles u ON p.author_id = u.id\n                LEFT JOIN tasks t ON p.task_id = t.id\n                LEFT JOIN rides r ON p.ride_id = r.id\n                LEFT JOIN items i ON p.item_id = i.id\n            `;\n\n      if (whereConditions.length > 0) {\n        query += ` WHERE ${whereConditions.join(\" AND \")}`;\n      }\n\n      query += `\n                ORDER BY p.created_at DESC\n                LIMIT $1 OFFSET $2\n            `;\n\n      this.logger.log(\"📝 [getPosts] Executing query with params:\", {\n        limit,\n        offset,\n        userId,\n        hasUserId: !!userId,\n      });\n\n      try {\n        const { rows } = await this.pool.query(query, params);\n        this.logger.log(\n          `✅ [getPosts] Query returned ${rows.length} posts (limit: ${limit}, offset: ${offset})`,\n        );\n\n        // Count task-related posts in results\n        const taskPostsInResults = rows.filter(\n          (p) =>\n            p.post_type === \"task_assignment\" ||\n            p.post_type === \"task_completion\",\n        ).length;\n        this.logger.log(\n          `📊 Task-related posts in results: ${taskPostsInResults}/${rows.length}`,\n        );\n\n        if (rows.length > 0) {\n          // Show first few posts for debugging\n          const samplePosts = rows.slice(0, 3).map((p) => ({\n            id: p.id?.substring(0, 8),\n            title: p.title?.substring(0, 30),\n            post_type: p.post_type,\n            author_id: p.author_id?.substring(0, 8),\n            has_author: !!p.author,\n            author_id_in_author: p.author?.id?.substring(0, 8),\n          }));\n          this.logger.log(\"📋 Sample posts:\", samplePosts);\n        } else {\n          this.logger.warn(\"⚠️ getPosts returned 0 posts!\");\n        }\n\n        return { success: true, data: rows };\n      } catch (queryError) {\n        this.logger.error(`❌ [getPosts] Primary query failed:`, queryError);\n\n        // Fallback query if main query fails (e.g. issues with joins or columns)\n        // Try simplest possible query without joins first to diagnose\n        this.logger.log(\"⚠️ [getPosts] Attempting fallback query...\");\n\n        try {\n          const fallbackQuery = `\n                        SELECT \n                            id, author_id, title, description, images, likes, comments, created_at,\n                            post_type, metadata, ride_id, item_id\n                        FROM posts\n                        ORDER BY created_at DESC\n                        LIMIT $1 OFFSET $2\n                    `;\n          const fallbackParams = [limit, offset];\n          const fallbackRes = await this.pool.query(\n            fallbackQuery,\n            fallbackParams,\n          );\n\n          // Map fallback results to expected format\n          const mappedRows = fallbackRes.rows.map((row) => ({\n            ...row,\n            author: { id: row.author_id, name: \"משתמש\", avatar_url: \"\" },\n            task: null,\n            is_liked: false,\n            ride_data: null,\n            item_data: null,\n          }));\n\n          this.logger.log(\n            `✅[getPosts] Fallback query returned ${mappedRows.length} posts`,\n          );\n          return { success: true, data: mappedRows };\n        } catch {\n          this.logger.warn(\"⚠️ [getPosts] Fallback query also failed\");\n          throw queryError;\n        }\n      }\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      this.logger.error(\"Get posts error:\", errorMessage);\n      return {\n        success: false,\n        error: `Failed to get posts: ${errorMessage} `,\n      };\n    }\n  }\n\n  @Get(\"user/:userId\")\n  async getUserPosts(\n    @Param(\"userId\") userId: string,\n    @Query(\"limit\") limitArg: string,\n    @Query(\"viewer_id\") viewerId?: string,\n  ) {\n    try {\n      await this.ensurePostsTable();\n      await this.ensureLikesCommentsTable();\n\n      const limit = parseInt(limitArg) || 20;\n\n      // Use explicit column names to avoid conflicts in JOIN queries\n      let query = `\n                SELECT\n                p.id,\n                    p.author_id,\n                    p.task_id,\n                    p.ride_id,\n                    p.item_id,\n                    p.title,\n                    p.description,\n                    p.images,\n                    p.likes,\n                    p.comments,\n                    p.post_type,\n                    p.metadata,\n                    p.created_at,\n                    p.updated_at,\n                    CASE \n                        WHEN u.id IS NOT NULL THEN json_build_object('id', u.id, 'name', COALESCE(u.name, 'ללא שם'), 'avatar_url', COALESCE(u.avatar_url, ''))\n                        ELSE json_build_object('id', p.author_id, 'name', 'משתמש לא נמצא', 'avatar_url', '')\n                END as author,\n                    CASE WHEN t.id IS NOT NULL THEN json_build_object(\n                        'id', t.id, \n                        'title', t.title, \n                        'description', t.description,\n                        'status', t.status,\n                        'estimated_hours', t.estimated_hours,\n                        'due_date', t.due_date,\n                        'assignees', (\n                            SELECT json_agg(json_build_object(\n                                'id', u_assignee.id, \n                                'name', u_assignee.name, \n                                'avatar', u_assignee.avatar_url\n                            ))\n                            FROM user_profiles u_assignee\n                            WHERE u_assignee.id = ANY(t.assignees)\n                        )\n                    ) ELSE NULL END as task,\n                    CASE \n                        WHEN r.id IS NOT NULL THEN json_build_object(\n                            'id', r.id, \n                            'from_location', r.from_location,\n                            'to_location', r.to_location,\n                            'departure_time', r.departure_time,\n                            'available_seats', r.available_seats,\n                            'price_per_seat', r.price_per_seat,\n                            'status', r.status\n                        ) \n                        ELSE NULL \n                    END as ride_data,\n                    CASE \n                        WHEN i.id IS NOT NULL THEN json_build_object(\n                            'id', i.id,\n                            'title', i.title,\n                            'status', i.status\n                        )\n                        ELSE NULL\n                    END as item_data\n                `;\n\n      // Check if post_likes table exists before using it\n      const postLikesExists = await this.pool.query(`\n                SELECT EXISTS(\n                    SELECT 1 FROM information_schema.tables \n                    WHERE table_name = 'post_likes' AND table_schema = 'public'\n                ) AS exists;\n                `);\n\n      if (viewerId && postLikesExists.rows[0]?.exists) {\n        query += `,\n                    EXISTS(SELECT 1 FROM post_likes pl WHERE pl.post_id = p.id AND pl.user_id = $3) as is_liked\n                `;\n      } else {\n        query += `,\n                    false as is_liked\n                `;\n      }\n\n      query += `\n                FROM posts p\n                LEFT JOIN user_profiles u ON p.author_id = u.id\n                LEFT JOIN tasks t ON p.task_id = t.id\n                LEFT JOIN rides r ON p.ride_id = r.id\n                LEFT JOIN items i ON p.item_id = i.id\n                WHERE p.author_id = $1\n                ORDER BY p.created_at DESC\n                LIMIT $2\n            `;\n\n      const params = viewerId ? [userId, limit, viewerId] : [userId, limit];\n      const { rows } = await this.pool.query(query, params);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Get user posts error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        userId,\n        limit: limitArg,\n        viewerId,\n      });\n      return {\n        success: false,\n        error: `Failed to get user posts: ${errorMessage} `,\n      };\n    }\n  }\n\n  // ============================================\n  // LIKES ENDPOINTS\n  // ============================================\n\n  /**\n   * Toggle like on a post (like if not liked, unlike if already liked)\n   * POST /api/posts/:postId/like\n   */\n  @Post(\":postId/like\")\n  @UseGuards(JwtAuthGuard)\n  async toggleLike(@Param(\"postId\") postId: string, @Body() body: LikeBody) {\n    const client = await this.pool.connect();\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const { user_id } = body;\n      if (!user_id) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // Check if post exists\n      const postCheck = await client.query(\n        \"SELECT id, author_id, title, post_type FROM posts WHERE id = $1\",\n        [postId],\n      );\n      if (postCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Post not found\" };\n      }\n\n      // Check if user exists\n      const userCheck = await client.query(\n        \"SELECT id, name FROM user_profiles WHERE id = $1\",\n        [user_id],\n      );\n      if (userCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // Check if like already exists\n      const existingLike = await client.query(\n        \"SELECT id FROM post_likes WHERE post_id = $1 AND user_id = $2\",\n        [postId, user_id],\n      );\n\n      let isLiked: boolean;\n\n      if (existingLike.rows.length > 0) {\n        // Unlike - remove the like\n        await client.query(\n          \"DELETE FROM post_likes WHERE post_id = $1 AND user_id = $2\",\n          [postId, user_id],\n        );\n        isLiked = false;\n      } else {\n        // Like - add new like\n        await client.query(\n          \"INSERT INTO post_likes (post_id, user_id) VALUES ($1, $2)\",\n          [postId, user_id],\n        );\n        isLiked = true;\n\n        // Send notification to post author if it's not the same user\n        const post = postCheck.rows[0];\n        const user = userCheck.rows[0];\n\n        if (post.author_id !== user_id) {\n          const likerName = user.name || \"משתמש\";\n          const postType =\n            post.post_type === \"task_completion\" ? \"השלמת משימה\" : \"פוסט\";\n\n          await client.query(\n            `\n                        INSERT INTO user_notifications(user_id, title, content, notification_type, related_id, metadata)\n                VALUES($1, $2, $3, $4, $5, $6)\n                        ON CONFLICT DO NOTHING\n                    `,\n            [\n              post.author_id,\n              \"לייק חדש!\",\n              `${likerName} אהב / ה את ה${postType} שלך: \"${post.title}\"`,\n              \"like\",\n              postId,\n              { liker_id: user_id, post_id: postId },\n            ],\n          );\n        }\n      }\n\n      // Calculate likes count from post_likes table (more reliable than reading from posts.likes)\n      const countResult = await client.query(\n        \"SELECT COUNT(*)::int as count FROM post_likes WHERE post_id = $1\",\n        [postId],\n      );\n      const likesCount = countResult.rows[0]?.count || 0;\n\n      // Update posts.likes manually as fallback (in case trigger didn't fire)\n      await client.query(\n        \"UPDATE posts SET likes = $1, updated_at = NOW() WHERE id = $2\",\n        [likesCount, postId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear cache\n      await this.redisCache.delete(`post_likes_${postId} `);\n\n      return {\n        success: true,\n        data: {\n          post_id: postId,\n          is_liked: isLiked,\n          likes_count: likesCount,\n        },\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Toggle like error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        userId: body?.user_id,\n      });\n      return {\n        success: false,\n        error: `Failed to toggle like: ${errorMessage} `,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get users who liked a post\n   * GET /api/posts/:postId/likes\n   */\n  @Get(\":postId/likes\")\n  async getPostLikes(\n    @Param(\"postId\") postId: string,\n    @Query(\"limit\") limitArg: string,\n    @Query(\"offset\") offsetArg: string,\n  ) {\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const limit = parseInt(limitArg) || 50;\n      const offset = parseInt(offsetArg) || 0;\n\n      const { rows } = await this.pool.query(\n        `\n                SELECT\n                pl.id,\n                    pl.created_at,\n                    json_build_object(\n                        'id', u.id,\n                        'name', u.name,\n                        'avatar_url', u.avatar_url\n                    ) as user\n                FROM post_likes pl\n                JOIN user_profiles u ON pl.user_id = u.id\n                WHERE pl.post_id = $1\n                ORDER BY pl.created_at DESC\n                LIMIT $2 OFFSET $3\n            `,\n        [postId, limit, offset],\n      );\n\n      // Get total count\n      const countResult = await this.pool.query(\n        \"SELECT COUNT(*) as total FROM post_likes WHERE post_id = $1\",\n        [postId],\n      );\n\n      return {\n        success: true,\n        data: rows,\n        total: parseInt(countResult.rows[0]?.total || \"0\"),\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Get post likes error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        limit: limitArg,\n        offset: offsetArg,\n      });\n      return {\n        success: false,\n        error: `Failed to get likes: ${errorMessage} `,\n      };\n    }\n  }\n\n  /**\n   * Check if user liked a post\n   * GET /api/posts/:postId/likes/check/:userId\n   */\n  @Get(\":postId/likes/check/:userId\")\n  async checkUserLiked(\n    @Param(\"postId\") postId: string,\n    @Param(\"userId\") userId: string,\n  ) {\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const result = await this.pool.query(\n        \"SELECT EXISTS(SELECT 1 FROM post_likes WHERE post_id = $1 AND user_id = $2) as is_liked\",\n        [postId, userId],\n      );\n\n      return {\n        success: true,\n        data: {\n          post_id: postId,\n          user_id: userId,\n          is_liked: result.rows[0]?.is_liked || false,\n        },\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Check user liked error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        userId,\n      });\n      return {\n        success: false,\n        error: `Failed to check like status: ${errorMessage} `,\n      };\n    }\n  }\n\n  // ============================================\n  // COMMENTS ENDPOINTS\n  // ============================================\n\n  /**\n   * Add a comment to a post\n   * POST /api/posts/:postId/comments\n   */\n  @Post(\":postId/comments\")\n  @UseGuards(JwtAuthGuard)\n  async addComment(@Param(\"postId\") postId: string, @Body() body: CommentBody) {\n    const client = await this.pool.connect();\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const { user_id, text } = body;\n\n      if (!user_id) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      if (!text || text.trim().length === 0) {\n        return { success: false, error: \"Comment text is required\" };\n      }\n\n      if (text.length > 2000) {\n        return {\n          success: false,\n          error: \"Comment text is too long (max 2000 characters)\",\n        };\n      }\n\n      // Ensure schema is up to date (Just in case getPosts wasn't called yet or schema is stale)\n      await this.ensurePostsTable();\n\n      await client.query(\"BEGIN\");\n\n      this.logger.log(`[addComment] Checking existence of post ${postId}`);\n\n      // Check if post exists\n      const postCheck = await client.query(\n        \"SELECT id, author_id, title, post_type FROM posts WHERE id = $1\",\n        [postId],\n      );\n\n      this.logger.log(\n        `[addComment] Post check result: ${postCheck.rows.length} rows found`,\n      );\n\n      if (postCheck.rows.length === 0) {\n        // Debugging: Check if post exists with whitespace or case issues?\n        const debugCheck = await client.query(\"SELECT id FROM posts LIMIT 5\");\n        this.logger.log(\n          \"[addComment] Debug - First 5 posts in DB:\",\n          debugCheck.rows,\n        );\n\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Post not found\" };\n      }\n\n      // Check if user exists\n      const userCheck = await client.query(\n        \"SELECT id, name FROM user_profiles WHERE id = $1\",\n        [user_id],\n      );\n      if (userCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // Insert comment\n      const { rows } = await client.query(\n        `\n                INSERT INTO post_comments(post_id, user_id, text)\n                VALUES($1, $2, $3)\n                RETURNING id, post_id, user_id, text, likes_count, created_at, updated_at\n                    `,\n        [postId, user_id, text.trim()],\n      );\n\n      if (!rows || rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Failed to create comment\" };\n      }\n\n      const comment = rows[0];\n\n      // Get user info for the response\n      const userResult = await client.query(\n        `\n                SELECT id, name, avatar_url FROM user_profiles WHERE id = $1\n                    `,\n        [user_id],\n      );\n\n      // Calculate comments count from post_comments table (more reliable than reading from posts.comments)\n      const countResult = await client.query(\n        \"SELECT COUNT(*)::int as count FROM post_comments WHERE post_id = $1\",\n        [postId],\n      );\n      const commentsCount = countResult.rows[0]?.count || 0;\n\n      // Update posts.comments manually as fallback (in case trigger didn't fire)\n      await client.query(\n        \"UPDATE posts SET comments = $1, updated_at = NOW() WHERE id = $2\",\n        [commentsCount, postId],\n      );\n\n      // Send notification to post author if not same user\n      const post = postCheck.rows[0];\n      const user = userCheck.rows[0];\n\n      if (post.author_id !== user_id) {\n        const commenterName = user.name || \"משתמש\";\n        const postType =\n          post.post_type === \"task_completion\" ? \"השלמת משימה\" : \"פוסט\";\n\n        await client.query(\n          `\n                    INSERT INTO user_notifications(user_id, title, content, notification_type, related_id, metadata)\n                VALUES($1, $2, $3, $4, $5, $6)\n                `,\n          [\n            post.author_id,\n            \"תגובה חדשה!\",\n            `${commenterName} הגיב / ה על ה${postType} שלך: \"${text.substring(0, 30)}${text.length > 30 ? \"...\" : \"\"}\"`,\n            \"comment\",\n            postId,\n            { commenter_id: user_id, post_id: postId, comment_id: comment.id },\n          ],\n        );\n      }\n\n      await client.query(\"COMMIT\");\n\n      // Clear cache\n      await this.redisCache.delete(`post_comments_${postId} `);\n\n      return {\n        success: true,\n        data: {\n          ...comment,\n          user: userResult.rows[0] || null,\n          comments_count: commentsCount,\n        },\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Add comment error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        userId: body?.user_id,\n      });\n      return {\n        success: false,\n        error: `Failed to add comment: ${errorMessage} `,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get all comments for a post\n   * GET /api/posts/:postId/comments\n   */\n  @Get(\":postId/comments\")\n  async getPostComments(\n    @Param(\"postId\") postId: string,\n    @Query(\"limit\") limitArg: string,\n    @Query(\"offset\") offsetArg: string,\n    @Query(\"viewer_id\") viewerId?: string,\n  ) {\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const limit = parseInt(limitArg) || 50;\n      const offset = parseInt(offsetArg) || 0;\n\n      let query = `\n                SELECT\n                c.id,\n                    c.post_id,\n                    c.user_id,\n                    c.text,\n                    c.likes_count,\n                    c.created_at,\n                    c.updated_at,\n                    json_build_object(\n                        'id', u.id,\n                        'name', u.name,\n                        'avatar_url', u.avatar_url\n                    ) as user\n                `;\n\n      // Add is_liked if viewer_id is provided\n      if (viewerId) {\n        query += `,\n                    EXISTS(SELECT 1 FROM comment_likes cl WHERE cl.comment_id = c.id AND cl.user_id = $4) as is_liked\n                `;\n      } else {\n        query += `,\n                    false as is_liked\n                `;\n      }\n\n      query += `\n                FROM post_comments c\n                JOIN user_profiles u ON c.user_id = u.id\n                WHERE c.post_id = $1\n                ORDER BY c.created_at ASC\n                LIMIT $2 OFFSET $3\n            `;\n\n      const params = viewerId\n        ? [postId, limit, offset, viewerId]\n        : [postId, limit, offset];\n      const { rows } = await this.pool.query(query, params);\n\n      // Get total count\n      const countResult = await this.pool.query(\n        \"SELECT COUNT(*) as total FROM post_comments WHERE post_id = $1\",\n        [postId],\n      );\n\n      return {\n        success: true,\n        data: rows,\n        total: parseInt(countResult.rows[0]?.total || \"0\"),\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Get post comments error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        limit: limitArg,\n        offset: offsetArg,\n        viewerId,\n      });\n      return {\n        success: false,\n        error: `Failed to get comments: ${errorMessage} `,\n      };\n    }\n  }\n\n  /**\n   * Update a comment (only owner can update)\n   * PUT /api/posts/:postId/comments/:commentId\n   */\n  @Put(\":postId/comments/:commentId\")\n  @UseGuards(JwtAuthGuard)\n  async updateComment(\n    @Param(\"postId\") postId: string,\n    @Param(\"commentId\") commentId: string,\n    @Body() body: UpdateCommentBody,\n  ) {\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const { user_id, text } = body;\n\n      if (!user_id) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      if (!text || text.trim().length === 0) {\n        return { success: false, error: \"Comment text is required\" };\n      }\n\n      if (text.length > 2000) {\n        return {\n          success: false,\n          error: \"Comment text is too long (max 2000 characters)\",\n        };\n      }\n\n      // Check if comment exists and belongs to user\n      const existingComment = await this.pool.query(\n        \"SELECT id, user_id FROM post_comments WHERE id = $1 AND post_id = $2\",\n        [commentId, postId],\n      );\n\n      if (existingComment.rows.length === 0) {\n        return { success: false, error: \"Comment not found\" };\n      }\n\n      if (existingComment.rows[0].user_id !== user_id) {\n        return { success: false, error: \"You can only edit your own comments\" };\n      }\n\n      // Update comment\n      const { rows } = await this.pool.query(\n        `\n                UPDATE post_comments \n                SET text = $1, updated_at = NOW()\n                WHERE id = $2\n                RETURNING *\n                    `,\n        [text.trim(), commentId],\n      );\n\n      // Clear cache\n      await this.redisCache.delete(`post_comments_${postId} `);\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Update comment error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        commentId,\n        userId: body?.user_id,\n      });\n      return {\n        success: false,\n        error: `Failed to update comment: ${errorMessage} `,\n      };\n    }\n  }\n\n  /**\n   * Delete a comment (only owner can delete)\n   * DELETE /api/posts/:postId/comments/:commentId\n   */\n  @Delete(\":postId/comments/:commentId\")\n  @UseGuards(JwtAuthGuard)\n  async deleteComment(\n    @Param(\"postId\") postId: string,\n    @Param(\"commentId\") commentId: string,\n    @Query(\"user_id\") userId: string,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      await this.ensureLikesCommentsTable();\n\n      if (!userId) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // Check if comment exists and belongs to user\n      const existingComment = await client.query(\n        \"SELECT id, user_id FROM post_comments WHERE id = $1 AND post_id = $2\",\n        [commentId, postId],\n      );\n\n      if (existingComment.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Comment not found\" };\n      }\n\n      if (existingComment.rows[0].user_id !== userId) {\n        await client.query(\"ROLLBACK\");\n        return {\n          success: false,\n          error: \"You can only delete your own comments\",\n        };\n      }\n\n      // Delete comment (trigger will update count)\n      await client.query(\"DELETE FROM post_comments WHERE id = $1\", [\n        commentId,\n      ]);\n\n      // Calculate comments count from post_comments table (more reliable than reading from posts.comments)\n      const countResult = await client.query(\n        \"SELECT COUNT(*)::int as count FROM post_comments WHERE post_id = $1\",\n        [postId],\n      );\n      const commentsCount = countResult.rows[0]?.count || 0;\n\n      // Update posts.comments manually as fallback (in case trigger didn't fire)\n      await client.query(\n        \"UPDATE posts SET comments = $1, updated_at = NOW() WHERE id = $2\",\n        [commentsCount, postId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear cache\n      await this.redisCache.delete(`post_comments_${postId} `);\n\n      return {\n        success: true,\n        data: {\n          deleted_comment_id: commentId,\n          comments_count: commentsCount,\n        },\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Delete comment error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        commentId,\n        userId,\n      });\n      return {\n        success: false,\n        error: `Failed to delete comment: ${errorMessage} `,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ============================================\n  // COMMENT LIKES ENDPOINTS\n  // ============================================\n\n  /**\n   * Toggle like on a comment\n   * POST /api/posts/:postId/comments/:commentId/like\n   */\n  @Post(\":postId/comments/:commentId/like\")\n  @UseGuards(JwtAuthGuard)\n  async toggleCommentLike(\n    @Param(\"postId\") postId: string,\n    @Param(\"commentId\") commentId: string,\n    @Body() body: LikeBody,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      await this.ensureLikesCommentsTable();\n\n      const { user_id } = body;\n      if (!user_id) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // Check if comment exists\n      const commentCheck = await client.query(\n        \"SELECT id, user_id, text FROM post_comments WHERE id = $1 AND post_id = $2\",\n        [commentId, postId],\n      );\n      if (commentCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Comment not found\" };\n      }\n\n      // Check if user exists\n      const userCheck = await client.query(\n        \"SELECT id, name FROM user_profiles WHERE id = $1\",\n        [user_id],\n      );\n      if (userCheck.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // Check if like already exists\n      const existingLike = await client.query(\n        \"SELECT id FROM comment_likes WHERE comment_id = $1 AND user_id = $2\",\n        [commentId, user_id],\n      );\n\n      let isLiked: boolean;\n\n      if (existingLike.rows.length > 0) {\n        // Unlike - remove the like\n        await client.query(\n          \"DELETE FROM comment_likes WHERE comment_id = $1 AND user_id = $2\",\n          [commentId, user_id],\n        );\n        isLiked = false;\n      } else {\n        // Like - add new like\n        await client.query(\n          \"INSERT INTO comment_likes (comment_id, user_id) VALUES ($1, $2)\",\n          [commentId, user_id],\n        );\n        isLiked = true;\n\n        // Send notification to comment author if not same user\n        const comment = commentCheck.rows[0];\n        const user = userCheck.rows[0];\n\n        if (comment.user_id !== user_id) {\n          const likerName = user.name || \"משתמש\";\n\n          await client.query(\n            `\n                        INSERT INTO user_notifications(user_id, title, content, notification_type, related_id, metadata)\n                VALUES($1, $2, $3, $4, $5, $6)\n                        ON CONFLICT DO NOTHING\n                    `,\n            [\n              comment.user_id,\n              \"לייק לתגובה!\",\n              `${likerName} אהב / ה את התגובה שלך: \"${comment.text.substring(0, 30)}${comment.text.length > 30 ? \"...\" : \"\"}\"`,\n              \"like\",\n              postId,\n              { liker_id: user_id, post_id: postId, comment_id: commentId },\n            ],\n          );\n        }\n      }\n\n      // Calculate likes count from comment_likes table (more reliable than reading from post_comments.likes_count)\n      const countResult = await client.query(\n        \"SELECT COUNT(*)::int as count FROM comment_likes WHERE comment_id = $1\",\n        [commentId],\n      );\n      const likesCount = countResult.rows[0]?.count || 0;\n\n      // Update post_comments.likes_count manually as fallback (in case trigger didn't fire)\n      await client.query(\n        \"UPDATE post_comments SET likes_count = $1, updated_at = NOW() WHERE id = $2\",\n        [likesCount, commentId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      return {\n        success: true,\n        data: {\n          comment_id: commentId,\n          is_liked: isLiked,\n          likes_count: likesCount,\n        },\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Toggle comment like error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        commentId,\n        userId: body?.user_id,\n      });\n      return {\n        success: false,\n        error: `Failed to toggle comment like: ${errorMessage} `,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ============================================\n  // POST UPDATE ENDPOINT\n  // ============================================\n\n  /**\n   * Update a post (title, description, image)\n   * PUT /api/posts/:postId\n   *\n   * Rules:\n   * 1. Only post owner can update\n   * 2. Can update: title, description, image_url\n   */\n  @Put(\":postId\")\n  @UseGuards(JwtAuthGuard)\n  async updatePost(\n    @Param(\"postId\") postId: string,\n    @Body()\n    body: {\n      user_id?: string;\n      title?: string;\n      description?: string;\n      image?: string;\n    },\n    @Req() req: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get user_id from authenticated request\n      const user_id =\n        req.user?.userId || req.user?.id || req.user?.sub || body.user_id;\n\n      if (!user_id) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not authenticated\" };\n      }\n\n      // Get post details\n      const postResult = await client.query(\n        \"SELECT * FROM posts WHERE id = $1\",\n        [postId],\n      );\n\n      if (postResult.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Post not found\" };\n      }\n\n      const post = postResult.rows[0];\n\n      // Check if user is the owner\n      if (post.author_id !== user_id) {\n        await client.query(\"ROLLBACK\");\n        return {\n          success: false,\n          error: \"Permission denied. You can only update your own posts.\",\n        };\n      }\n\n      // Build update query dynamically\n      const updates: string[] = [];\n      const values: any[] = [];\n      let paramIndex = 1;\n\n      if (body.title !== undefined) {\n        updates.push(`title = $${paramIndex++}`);\n        values.push(body.title);\n      }\n\n      if (body.description !== undefined) {\n        updates.push(`description = $${paramIndex++}`);\n        values.push(body.description);\n      }\n\n      if (body.image !== undefined) {\n        updates.push(`image_url = $${paramIndex++}`);\n        values.push(body.image);\n      }\n\n      if (updates.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"No fields to update\" };\n      }\n\n      // Add updated_at\n      updates.push(`updated_at = NOW()`);\n      values.push(postId);\n\n      // Execute update\n      const updateQuery = `\n                UPDATE posts \n                SET ${updates.join(\", \")}\n                WHERE id = $${paramIndex}\n                RETURNING *\n            `;\n\n      const result = await client.query(updateQuery, values);\n\n      // Track update activity\n      await client.query(\n        `\n                INSERT INTO user_activities (user_id, activity_type, activity_data)\n                VALUES ($1, $2, $3)\n            `,\n        [\n          user_id,\n          \"post_updated\",\n          JSON.stringify({\n            post_id: postId,\n            updated_fields: Object.keys(body).filter((k) => k !== \"user_id\"),\n          }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear relevant caches\n      await this.redisCache.delete(`post_${postId}`);\n      await this.redisCache.invalidatePattern(\"posts_*\");\n      await this.redisCache.invalidatePattern(\"user_posts_*\");\n\n      return {\n        success: true,\n        data: result.rows[0],\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      this.logger.error(\"Update post error:\", errorMessage);\n      return {\n        success: false,\n        error: `Failed to update post: ${errorMessage}`,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ============================================\n  // POST HIDE/UNHIDE ENDPOINTS\n  // ============================================\n\n  /**\n   * Hide a post (soft delete - sets status to 'hidden')\n   * POST /api/posts/:postId/hide\n   *\n   * Rules:\n   * 1. Only post owner can hide their posts\n   */\n  @Post(\":postId/hide\")\n  @UseGuards(JwtAuthGuard)\n  async hidePost(\n    @Param(\"postId\") postId: string,\n    @Body() body: { user_id?: string },\n    @Req() req: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      // Get user_id from authenticated request\n      const user_id =\n        req.user?.userId || req.user?.id || req.user?.sub || body.user_id;\n\n      if (!user_id) {\n        return { success: false, error: \"User not authenticated\" };\n      }\n\n      // Get post details\n      const postResult = await client.query(\n        \"SELECT * FROM posts WHERE id = $1\",\n        [postId],\n      );\n\n      if (postResult.rows.length === 0) {\n        return { success: false, error: \"Post not found\" };\n      }\n\n      const post = postResult.rows[0];\n\n      // Check if user is the owner\n      if (post.author_id !== user_id) {\n        return {\n          success: false,\n          error: \"Permission denied. You can only hide your own posts.\",\n        };\n      }\n\n      // Update post status to 'hidden'\n      await client.query(\n        `UPDATE posts \n                 SET status = 'hidden', updated_at = NOW()\n                 WHERE id = $1`,\n        [postId],\n      );\n\n      // Track hide activity\n      await client.query(\n        `\n                INSERT INTO user_activities (user_id, activity_type, activity_data)\n                VALUES ($1, $2, $3)\n            `,\n        [user_id, \"post_hidden\", JSON.stringify({ post_id: postId })],\n      );\n\n      // Clear relevant caches\n      await this.redisCache.delete(`post_${postId}`);\n      await this.redisCache.invalidatePattern(\"posts_*\");\n      await this.redisCache.invalidatePattern(\"user_posts_*\");\n\n      return {\n        success: true,\n        data: { status: \"hidden\", post_id: postId },\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      this.logger.error(\"Hide post error:\", errorMessage);\n      return {\n        success: false,\n        error: `Failed to hide post: ${errorMessage}`,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Unhide a post (restore from hidden status)\n   * POST /api/posts/:postId/unhide\n   *\n   * Rules:\n   * 1. Only post owner can unhide their posts\n   */\n  @Post(\":postId/unhide\")\n  @UseGuards(JwtAuthGuard)\n  async unhidePost(\n    @Param(\"postId\") postId: string,\n    @Body() body: { user_id?: string },\n    @Req() req: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      // Get user_id from authenticated request\n      const user_id =\n        req.user?.userId || req.user?.id || req.user?.sub || body.user_id;\n\n      if (!user_id) {\n        return { success: false, error: \"User not authenticated\" };\n      }\n\n      // Get post details\n      const postResult = await client.query(\n        \"SELECT * FROM posts WHERE id = $1\",\n        [postId],\n      );\n\n      if (postResult.rows.length === 0) {\n        return { success: false, error: \"Post not found\" };\n      }\n\n      const post = postResult.rows[0];\n\n      // Check if user is the owner\n      if (post.author_id !== user_id) {\n        return {\n          success: false,\n          error: \"Permission denied. You can only unhide your own posts.\",\n        };\n      }\n\n      // Update post status back to 'active' or original status\n      await client.query(\n        `UPDATE posts \n                 SET status = 'active', updated_at = NOW()\n                 WHERE id = $1`,\n        [postId],\n      );\n\n      // Track unhide activity\n      await client.query(\n        `\n                INSERT INTO user_activities (user_id, activity_type, activity_data)\n                VALUES ($1, $2, $3)\n            `,\n        [user_id, \"post_unhidden\", JSON.stringify({ post_id: postId })],\n      );\n\n      // Clear relevant caches\n      await this.redisCache.delete(`post_${postId}`);\n      await this.redisCache.invalidatePattern(\"posts_*\");\n      await this.redisCache.invalidatePattern(\"user_posts_*\");\n\n      return {\n        success: true,\n        data: { status: \"active\", post_id: postId },\n      };\n    } catch (error) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      this.logger.error(\"Unhide post error:\", errorMessage);\n      return {\n        success: false,\n        error: `Failed to unhide post: ${errorMessage}`,\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  // ============================================\n  // POST DELETION ENDPOINT\n  // ============================================\n\n  /**\n   * Delete a post and its related entity (ride/item/task)\n   * DELETE /api/posts/:postId\n   *\n   * Rules:\n   * 1. User can delete their own posts\n   * 2. Super admin can delete any post\n   * 3. Deleting a post cascades based on post_type:\n   *    - ride: Deletes the ride (post auto-deleted via CASCADE)\n   *    - item/donation: Deletes the item (post auto-deleted via CASCADE)\n   *    - task: Only deletes the post, not the task\n   *    - general: Only deletes the post\n   */\n  @Delete(\":postId\")\n  @UseGuards(JwtAuthGuard)\n  async deletePost(@Param(\"postId\") postId: string, @Req() req: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get user_id from authenticated request (more secure/reliable than body)\n      // JwtAuthGuard populates req.user with SessionTokenPayload which uses 'userId'\n      const user_id = req.user?.userId || req.user?.id || req.user?.sub;\n\n      if (!user_id) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not authenticated\" };\n      }\n\n      // Get post details\n      const postResult = await client.query(\n        `SELECT p.*, u.roles \n                 FROM posts p\n                 LEFT JOIN user_profiles u ON p.author_id = u.id\n                 WHERE p.id = $1`,\n        [postId],\n      );\n\n      if (postResult.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Post not found\" };\n      }\n\n      const post = postResult.rows[0];\n\n      // Check permissions\n      const userResult = await client.query(\n        \"SELECT roles FROM user_profiles WHERE id = $1\",\n        [user_id],\n      );\n\n      if (userResult.rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      const userRoles = userResult.rows[0].roles || [];\n      const isSuperAdmin = userRoles.includes(\"super_admin\");\n      const isOwner = post.author_id === user_id;\n\n      if (!isOwner && !isSuperAdmin) {\n        await client.query(\"ROLLBACK\");\n        return {\n          success: false,\n          error:\n            \"Permission denied. You can only delete your own posts or be a super admin.\",\n        };\n      }\n\n      this.logger.log(\n        `🗑️ Deleting post ${postId} (type: ${post.post_type}) by user ${user_id} (owner: ${isOwner}, admin: ${isSuperAdmin})`,\n      );\n\n      // Handle deletion based on post type\n      let deletionStrategy = \"post_only\";\n      let relatedEntityDeleted = false;\n\n      switch (post.post_type) {\n        case \"ride\":\n          if (post.ride_id) {\n            // Delete the ride - post will be auto-deleted via CASCADE\n            await client.query(\"DELETE FROM rides WHERE id = $1\", [\n              post.ride_id,\n            ]);\n            deletionStrategy = \"ride_cascade\";\n            relatedEntityDeleted = true;\n            this.logger.log(\n              `✅ Deleted ride ${post.ride_id} (post auto-deleted via CASCADE)`,\n            );\n          } else {\n            // Orphaned ride post - delete post only\n            await client.query(\"DELETE FROM posts WHERE id = $1\", [postId]);\n            deletionStrategy = \"post_only\";\n          }\n          break;\n\n        case \"item\":\n        case \"donation\":\n          if (post.item_id) {\n            // Delete the item - post will be auto-deleted via CASCADE\n            await client.query(\"DELETE FROM items WHERE id = $1\", [\n              post.item_id,\n            ]);\n            deletionStrategy = \"item_cascade\";\n            relatedEntityDeleted = true;\n            this.logger.log(\n              `✅ Deleted item ${post.item_id} (post auto-deleted via CASCADE)`,\n            );\n          } else {\n            // Orphaned item post - delete post only\n            await client.query(\"DELETE FROM posts WHERE id = $1\", [postId]);\n            deletionStrategy = \"post_only\";\n          }\n          break;\n\n        case \"task_completion\":\n        case \"task_assignment\":\n          // For tasks, only delete the post, not the task itself\n          // Tasks can have multiple posts and should be managed separately\n          await client.query(\"DELETE FROM posts WHERE id = $1\", [postId]);\n          deletionStrategy = \"post_only\";\n          this.logger.log(\n            `✅ Deleted task post ${postId} (task ${post.task_id} preserved)`,\n          );\n          break;\n\n        default:\n          // General posts or unknown types - delete post only\n          await client.query(\"DELETE FROM posts WHERE id = $1\", [postId]);\n          deletionStrategy = \"post_only\";\n          this.logger.log(`✅ Deleted general post ${postId}`);\n      }\n\n      // Track deletion activity\n      await client.query(\n        `\n                INSERT INTO user_activities (user_id, activity_type, activity_data)\n                VALUES ($1, $2, $3)\n            `,\n        [\n          user_id,\n          \"post_deleted\",\n          JSON.stringify({\n            post_id: postId,\n            post_type: post.post_type,\n            deletion_strategy: deletionStrategy,\n            related_entity_deleted: relatedEntityDeleted,\n            is_admin_action: isSuperAdmin && !isOwner,\n          }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear relevant caches\n      await this.redisCache.delete(`post_${postId}`);\n      await this.redisCache.invalidatePattern(\"posts_*\");\n      await this.redisCache.invalidatePattern(\"user_posts_*\");\n\n      return {\n        success: true,\n        data: {\n          post_id: postId,\n          post_type: post.post_type,\n          deletion_strategy: deletionStrategy,\n          message: relatedEntityDeleted\n            ? `Post and related ${post.post_type} deleted successfully`\n            : \"Post deleted successfully\",\n        },\n      };\n    } catch (error) {\n      try {\n        await client.query(\"ROLLBACK\");\n      } catch (rollbackError) {\n        this.logger.error(\"Rollback error:\", rollbackError);\n      }\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      const errorStack = error instanceof Error ? error.stack : undefined;\n      this.logger.error(\"Delete post error:\", {\n        message: errorMessage,\n        stack: errorStack,\n        postId,\n        userId: req?.user?.id,\n      });\n      return {\n        success: false,\n        error: `Failed to delete post: ${errorMessage}`,\n      };\n    } finally {\n      client.release();\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/rate-limit.controller.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/redis-test.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":45,"column":54,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":45,"endColumn":57,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1071,1074],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1071,1074],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Utility endpoints to verify Redis connectivity and operations.\n// - Reached from: Routes under '/redis-test'.\n// - Provides: info, set/get/delete, keys, increment, and a comprehensive test suite.\nimport {\n  Controller,\n  Get,\n  Post,\n  Delete,\n  Body,\n  Param,\n  Query,\n} from \"@nestjs/common\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n@Controller(\"redis-test\")\nexport class RedisTestController {\n  constructor(private readonly redisCache: RedisCacheService) {}\n\n  /**\n   * Get Redis info and stats\n   */\n  @Get(\"info\")\n  async getRedisInfo() {\n    try {\n      const info = await this.redisCache.getInfo();\n      return {\n        success: true,\n        ...info,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Set a test value in Redis\n   * POST /redis-test/set\n   * Body: { key: string, value: any, ttl?: number }\n   */\n  @Post(\"set\")\n  async setValue(@Body() body: { key: string; value: any; ttl?: number }) {\n    try {\n      const { key, value, ttl } = body;\n\n      if (!key) {\n        return { success: false, error: \"Key is required\" };\n      }\n\n      await this.redisCache.set(key, value, ttl);\n\n      return {\n        success: true,\n        message: `Value set for key: ${key}`,\n        key,\n        value,\n        ...(ttl && { ttl }),\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Get a value from Redis\n   * GET /redis-test/get/:key\n   */\n  @Get(\"get/:key\")\n  async getValue(@Param(\"key\") key: string) {\n    try {\n      const value = await this.redisCache.get(key);\n      const exists = await this.redisCache.exists(key);\n\n      return {\n        success: true,\n        key,\n        value,\n        exists,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Delete a key from Redis\n   * DELETE /redis-test/delete/:key\n   */\n  @Delete(\"delete/:key\")\n  async deleteValue(@Param(\"key\") key: string) {\n    try {\n      const deleted = await this.redisCache.delete(key);\n\n      return {\n        success: true,\n        key,\n        deleted,\n        message: deleted ? \"Key deleted\" : \"Key not found\",\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Get all keys (with optional pattern)\n   * GET /redis-test/keys?pattern=*\n   */\n  @Get(\"keys\")\n  async getKeys(@Query(\"pattern\") pattern: string = \"*\") {\n    try {\n      const keys = await this.redisCache.getKeys(pattern);\n\n      return {\n        success: true,\n        pattern,\n        keys,\n        count: keys.length,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Increment a counter\n   * POST /redis-test/increment/:key\n   * Body: { amount?: number }\n   */\n  @Post(\"increment/:key\")\n  async incrementValue(\n    @Param(\"key\") key: string,\n    @Body() body: { amount?: number },\n  ) {\n    try {\n      const amount = body.amount || 1;\n      const newValue = await this.redisCache.increment(key, amount);\n\n      return {\n        success: true,\n        key,\n        amount,\n        newValue,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n      };\n    }\n  }\n\n  /**\n   * Test Redis operations (comprehensive test)\n   * POST /redis-test/comprehensive\n   */\n  @Post(\"comprehensive\")\n  async comprehensiveTest() {\n    const testKey = `test_${Date.now()}`;\n    const testValue = {\n      message: \"Hello Redis!\",\n      timestamp: new Date().toISOString(),\n    };\n\n    try {\n      const results = [];\n\n      // Test 1: Set value\n      await this.redisCache.set(testKey, testValue, 60); // 60 seconds TTL\n      results.push({ test: \"SET\", status: \"PASS\", key: testKey });\n\n      // Test 2: Get value\n      const retrieved = await this.redisCache.get(testKey);\n      const isEqual = JSON.stringify(retrieved) === JSON.stringify(testValue);\n      results.push({\n        test: \"GET\",\n        status: isEqual ? \"PASS\" : \"FAIL\",\n        retrieved,\n        expected: testValue,\n      });\n\n      // Test 3: Check exists\n      const exists = await this.redisCache.exists(testKey);\n      results.push({\n        test: \"EXISTS\",\n        status: exists ? \"PASS\" : \"FAIL\",\n        exists,\n      });\n\n      // Test 4: Increment counter\n      const counterKey = `counter_${Date.now()}`;\n      const count1 = await this.redisCache.increment(counterKey);\n      const count2 = await this.redisCache.increment(counterKey, 5);\n      results.push({\n        test: \"INCREMENT\",\n        status: count1 === 1 && count2 === 6 ? \"PASS\" : \"FAIL\",\n        count1,\n        count2,\n      });\n\n      // Test 5: Delete\n      const deleted = await this.redisCache.delete(testKey);\n      const stillExists = await this.redisCache.exists(testKey);\n      results.push({\n        test: \"DELETE\",\n        status: deleted && !stillExists ? \"PASS\" : \"FAIL\",\n        deleted,\n        stillExists,\n      });\n\n      // Cleanup counter\n      await this.redisCache.delete(counterKey);\n\n      const passedTests = results.filter((r) => r.status === \"PASS\").length;\n      const totalTests = results.length;\n\n      return {\n        success: true,\n        summary: `${passedTests}/${totalTests} tests passed`,\n        allTestsPassed: passedTests === totalTests,\n        results,\n      };\n    } catch (error) {\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : String(error),\n        testKey,\n      };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/rides.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":33,"column":38,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":33,"endColumn":41,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1094,1097],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1094,1097],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":242,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":242,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8093,8096],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8093,8096],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":355,"column":68,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":355,"endColumn":71,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11268,11271],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11268,11271],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":485,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":485,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[15438,15441],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[15438,15441],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":673,"column":65,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":673,"endColumn":68,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[21392,21395],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[21392,21395],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Rides API for creating, listing, booking, updating, and stats; integrates with community/user activity.\n// - Reached from: Routes under '/api/rides'.\n// - Provides: Create ride, list with filters, get by id, book ride, update booking status, per-user rides, summary stats; clears caches accordingly.\n// - Storage: `rides`, `ride_bookings`, `user_profiles`, `community_stats`; Redis caches with TTL.\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Put,\n  Query,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n@Controller(\"api/rides\")\nexport class RidesController {\n  private readonly logger = new Logger(RidesController.name);\n  private readonly CACHE_TTL = 5 * 60; // 5 minutes for ride data\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  @Post()\n  async createRide(@Body() rideData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      this.logger.log(\n        \"🚗 Server - Creating ride with data:\",\n        JSON.stringify(rideData, null, 2),\n      );\n\n      // Validate required fields\n      if (!rideData.driver_id) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Driver ID is required\" };\n      }\n\n      if (!rideData.from_location || !rideData.to_location) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"From and to locations are required\" };\n      }\n\n      if (!rideData.departure_time) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Departure time is required\" };\n      }\n\n      // Check or create user profile for driver_id\n      let driverUuid = rideData.driver_id;\n\n      // If driver_id is not a valid UUID, try to find or create user profile\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(rideData.driver_id)) {\n        // Try to find existing user profile by legacy ID or email\n        const { rows: existingUsers } = await client.query(\n          `\n          SELECT id FROM user_profiles \n          WHERE settings->>'legacy_id' = $1 OR email = $2 \n          LIMIT 1\n        `,\n          [rideData.driver_id, `${rideData.driver_id}@legacy.com`],\n        );\n\n        if (existingUsers.length > 0) {\n          driverUuid = existingUsers[0].id;\n          this.logger.log(\n            `🔄 Found existing user profile for ${rideData.driver_id}: ${driverUuid}`,\n          );\n        } else {\n          // Create new user profile for legacy user\n          const { rows: newUsers } = await client.query(\n            `\n            INSERT INTO user_profiles (email, name, settings)\n            VALUES ($1, $2, $3)\n            RETURNING id\n          `,\n            [\n              `${rideData.driver_id}@legacy.com`,\n              `User ${rideData.driver_id}`,\n              JSON.stringify({\n                legacy_id: rideData.driver_id,\n                source: \"legacy-app\",\n              }),\n            ],\n          );\n\n          driverUuid = newUsers[0].id;\n          this.logger.log(\n            `✨ Created new user profile for ${rideData.driver_id}: ${driverUuid}`,\n          );\n        }\n      }\n\n      // Insert ride\n      const { rows } = await client.query(\n        `\n        INSERT INTO rides (\n          driver_id, title, from_location, to_location, departure_time,\n          arrival_time, available_seats, price_per_seat, description, requirements, metadata\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)\n        RETURNING *\n      `,\n        [\n          driverUuid,\n          rideData.title ||\n            `נסיעה מ${rideData.from_location?.name || \"כאן\"} ל${rideData.to_location?.name || \"שם\"}`,\n          JSON.stringify(rideData.from_location),\n          JSON.stringify(rideData.to_location),\n          rideData.departure_time,\n          rideData.arrival_time || null,\n          rideData.available_seats || 1,\n          rideData.price_per_seat || 0,\n          rideData.description,\n          rideData.requirements,\n          rideData.metadata ? JSON.stringify(rideData.metadata) : null,\n        ],\n      );\n\n      const ride = rows[0];\n\n      // Create a corresponding post for the ride (enables likes/comments)\n      await client.query(\n        `\n        INSERT INTO posts (author_id, ride_id, title, description, post_type, metadata, images)\n        VALUES ($1, $2, $3, $4, $5, $6, $7)\n      `,\n        [\n          driverUuid,\n          ride.id,\n          ride.title,\n          ride.description ||\n            `נסיעה מ${rideData.from_location?.name || \"כאן\"} ל${rideData.to_location?.name || \"שם\"}`,\n          \"ride\",\n          JSON.stringify({\n            from_location: rideData.from_location,\n            to_location: rideData.to_location,\n            departure_time: rideData.departure_time,\n            available_seats: rideData.available_seats,\n            price_per_seat: rideData.price_per_seat,\n          }),\n          rideData.images || [],\n        ],\n      );\n\n      // Track user activity\n      await client.query(\n        `\n        INSERT INTO user_activities (user_id, activity_type, activity_data)\n        VALUES ($1, $2, $3)\n      `,\n        [\n          driverUuid,\n          \"ride_created\",\n          JSON.stringify({\n            ride_id: ride.id,\n            from: rideData.from_location?.name,\n            to: rideData.to_location?.name,\n            seats: rideData.available_seats,\n          }),\n        ],\n      );\n\n      // Update community stats\n      await client.query(`\n        INSERT INTO community_stats (stat_type, stat_value, date_period)\n        VALUES ('rides_created', 1, CURRENT_DATE)\n        ON CONFLICT (stat_type, city, date_period) \n        DO UPDATE SET stat_value = community_stats.stat_value + 1, updated_at = NOW()\n      `);\n\n      await client.query(\"COMMIT\");\n\n      // Best-effort cache clearing (do not fail the request if Redis is down)\n      try {\n        await this.clearRideCaches();\n        await this.clearCommunityStatsCaches();\n      } catch (cacheError) {\n        // eslint-disable-next-line no-console\n        this.logger.error(\n          \"⚠️ Cache clear failed after ride creation:\",\n          cacheError,\n        );\n      }\n\n      return { success: true, data: ride };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Create ride error:\", error);\n      return { success: false, error: \"Failed to create ride\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get()\n  async getRides(\n    @Query(\"from_city\") fromCity?: string,\n    @Query(\"to_city\") toCity?: string,\n    @Query(\"date\") date?: string,\n    @Query(\"status\") status?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n    @Query(\"include_past\") include_past?: string,\n    @Query(\"sort_by\") sort_by?: string,\n    @Query(\"sort_order\") sort_order?: string,\n  ) {\n    // Cache key includes include_past and sort params\n    const cacheKey = `rides_${fromCity || \"all\"}_${toCity || \"all\"}_${date || \"all\"}_${status || \"active\"}_${limit || \"50\"}_${offset || \"0\"}_${include_past || \"false\"}_${sort_by || \"dep\"}_${sort_order || \"asc\"}`;\n\n    const cached = await this.redisCache.get(cacheKey);\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    let query = `\n      SELECT r.*, up.name as driver_name, up.avatar_url as driver_avatar,\n             up.phone as driver_phone, \n             (r.available_seats - COALESCE(bookings.booked_seats, 0)) as remaining_seats\n      FROM rides r\n      LEFT JOIN user_profiles up ON r.driver_id = up.id\n      LEFT JOIN (\n        SELECT ride_id, SUM(seats_requested) as booked_seats\n        FROM ride_bookings \n        WHERE status = 'approved'\n        GROUP BY ride_id\n      ) bookings ON r.id = bookings.ride_id\n      WHERE 1=1\n    `;\n\n    const params: any[] = [];\n    let paramCount = 0;\n\n    if (fromCity) {\n      paramCount++;\n      query += ` AND r.from_location->>'city' ILIKE $${paramCount}`;\n      params.push(`%${fromCity}%`);\n    }\n\n    if (toCity) {\n      paramCount++;\n      query += ` AND r.to_location->>'city' ILIKE $${paramCount}`;\n      params.push(`%${toCity}%`);\n    }\n\n    if (date) {\n      paramCount++;\n      query += ` AND DATE(r.departure_time) = $${paramCount}`;\n      params.push(date);\n    } else {\n      // Only show future rides by default unless include_past is true, AND we are not sorting by created_at (feed mode)\n      // If sorting by created_at, we typically want history too, but let's stick to explicit include_past for safety\n      if (include_past !== \"true\") {\n        query += ` AND r.departure_time > NOW()`;\n      }\n    }\n\n    if (status) {\n      paramCount++;\n      query += ` AND r.status = $${paramCount}`;\n      params.push(status);\n    } else {\n      query += ` AND r.status = 'active'`;\n    }\n\n    // Sorting logic\n    const allowedSortColumns = [\n      \"departure_time\",\n      \"created_at\",\n      \"price_per_seat\",\n    ];\n    const sortCol =\n      sort_by && allowedSortColumns.includes(sort_by)\n        ? sort_by\n        : \"departure_time\";\n    const sortDir =\n      sort_order && [\"asc\", \"desc\"].includes(sort_order.toLowerCase())\n        ? sort_order.toUpperCase()\n        : \"ASC\";\n\n    query += ` ORDER BY r.${sortCol} ${sortDir}`;\n\n    if (limit) {\n      paramCount++;\n      query += ` LIMIT $${paramCount}`;\n      params.push(parseInt(limit));\n    } else {\n      query += ` LIMIT 50`;\n    }\n\n    if (offset) {\n      paramCount++;\n      query += ` OFFSET $${paramCount}`;\n      params.push(parseInt(offset));\n    }\n\n    const { rows } = await this.pool.query(query, params);\n\n    await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n    return { success: true, data: rows };\n  }\n\n  /**\n   * Get a single ride by ID with caching\n   * Cache TTL: 10 minutes (rides can change with bookings, so moderate TTL)\n   */\n  @Get(\":id\")\n  async getRideById(@Param(\"id\") id: string) {\n    const cacheKey = `ride_${id}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT r.*, up.name as driver_name, up.avatar_url as driver_avatar,\n             up.phone as driver_phone, up.email as driver_email,\n             (r.available_seats - COALESCE(bookings.booked_seats, 0)) as remaining_seats\n      FROM rides r\n      LEFT JOIN user_profiles up ON r.driver_id = up.id\n      LEFT JOIN (\n        SELECT ride_id, SUM(seats_requested) as booked_seats\n        FROM ride_bookings \n        WHERE status = 'approved'\n        GROUP BY ride_id\n      ) bookings ON r.id = bookings.ride_id\n      WHERE r.id = $1\n    `,\n      [id],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Ride not found\" };\n    }\n\n    // Cache for 10 minutes\n    await this.redisCache.set(cacheKey, rows[0], 10 * 60);\n    return { success: true, data: rows[0] };\n  }\n\n  @Post(\":id/book\")\n  async bookRide(@Param(\"id\") rideId: string, @Body() bookingData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Check if ride exists and has available seats\n      const { rows: rideRows } = await client.query(\n        `\n        SELECT r.*, (r.available_seats - COALESCE(bookings.booked_seats, 0)) as remaining_seats\n        FROM rides r\n        LEFT JOIN (\n          SELECT ride_id, SUM(seats_requested) as booked_seats\n          FROM ride_bookings \n          WHERE status = 'approved'\n          GROUP BY ride_id\n        ) bookings ON r.id = bookings.ride_id\n        WHERE r.id = $1 AND r.status = 'active'\n      `,\n        [rideId],\n      );\n\n      if (rideRows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Ride not found or not available\" };\n      }\n\n      const ride = rideRows[0];\n      const requestedSeats = bookingData.seats_requested || 1;\n\n      if (ride.remaining_seats < requestedSeats) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Not enough available seats\" };\n      }\n\n      // Resolve passenger ID to UUID (supports email, firebase_uid, or UUID)\n      // NOTE: We only use our own UUID (user_profiles.id) for user identification\n      let passengerUuid = bookingData.passenger_id;\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(passengerUuid)) {\n        // Try to find user by email or firebase_uid ONLY\n        const { rows: existingUsers } = await client.query(\n          `\n          SELECT id FROM user_profiles \n          WHERE LOWER(email) = LOWER($1) \n             OR firebase_uid = $1 \n             OR id::text = $1\n          LIMIT 1\n        `,\n          [passengerUuid],\n        );\n\n        if (existingUsers.length > 0) {\n          passengerUuid = existingUsers[0].id;\n          this.logger.log(\n            `🔄 Found existing user profile for ${bookingData.passenger_id}: ${passengerUuid}`,\n          );\n        } else {\n          // User not found - this is an error, passenger must exist\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: `User not found: ${bookingData.passenger_id}. User must be registered before booking a ride.`,\n          };\n        }\n      } else {\n        // Verify UUID exists\n        const { rows: verifyUsers } = await client.query(\n          `\n          SELECT id FROM user_profiles WHERE id = $1::uuid LIMIT 1\n        `,\n          [passengerUuid],\n        );\n\n        if (verifyUsers.length === 0) {\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: `User not found: ${passengerUuid}. User must be registered before booking a ride.`,\n          };\n        }\n      }\n\n      // Create booking\n      const { rows: bookingRows } = await client.query(\n        `\n        INSERT INTO ride_bookings (ride_id, passenger_id, seats_requested, message)\n        VALUES ($1, $2, $3, $4)\n        RETURNING *\n      `,\n        [rideId, passengerUuid, requestedSeats, bookingData.message || \"\"],\n      );\n\n      const booking = bookingRows[0];\n\n      // Track user activity\n      await client.query(\n        `\n        INSERT INTO user_activities (user_id, activity_type, activity_data)\n        VALUES ($1, $2, $3)\n      `,\n        [\n          passengerUuid,\n          \"ride_booking_created\",\n          JSON.stringify({\n            ride_id: rideId,\n            booking_id: booking.id,\n            seats: requestedSeats,\n          }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n      await this.clearRideCaches();\n      // Clear community stats caches to reflect booking impact\n      await this.clearCommunityStatsCaches();\n\n      return { success: true, data: booking };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Book ride error:\", error);\n      return { success: false, error: \"Failed to book ride\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Put(\"bookings/:bookingId/status\")\n  async updateBookingStatus(\n    @Param(\"bookingId\") bookingId: string,\n    @Body() statusData: any,\n  ) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      const { rows } = await client.query(\n        `\n        UPDATE ride_bookings \n        SET status = $1, updated_at = NOW()\n        WHERE id = $2\n        RETURNING *\n      `,\n        [statusData.status, bookingId],\n      );\n\n      if (rows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Booking not found\" };\n      }\n\n      const booking = rows[0];\n\n      // If approved, check if ride is now full\n      if (statusData.status === \"approved\") {\n        const { rows: rideRows } = await client.query(\n          `\n          SELECT r.*, (r.available_seats - COALESCE(bookings.booked_seats, 0)) as remaining_seats\n          FROM rides r\n          LEFT JOIN (\n            SELECT ride_id, SUM(seats_requested) as booked_seats\n            FROM ride_bookings \n            WHERE status = 'approved'\n            GROUP BY ride_id\n          ) bookings ON r.id = bookings.ride_id\n          WHERE r.id = $1\n        `,\n          [booking.ride_id],\n        );\n\n        if (rideRows.length > 0 && rideRows[0].remaining_seats <= 0) {\n          await client.query(\n            `\n            UPDATE rides SET status = 'full', updated_at = NOW() WHERE id = $1\n          `,\n            [booking.ride_id],\n          );\n        }\n\n        // Update community stats for completed rides\n        await client.query(`\n          INSERT INTO community_stats (stat_type, stat_value, date_period)\n          VALUES ('rides_booked', 1, CURRENT_DATE)\n          ON CONFLICT (stat_type, city, date_period) \n          DO UPDATE SET stat_value = community_stats.stat_value + 1, updated_at = NOW()\n        `);\n      }\n\n      await client.query(\"COMMIT\");\n      await this.clearRideCaches();\n\n      return { success: true, data: booking };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Update booking status error:\", error);\n      return { success: false, error: \"Failed to update booking status\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"user/:userId\")\n  async getUserRides(\n    @Param(\"userId\") userId: string,\n    @Query(\"type\") type?: string,\n  ) {\n    // Resolve potential legacy ID\n    let resolvedUserId = userId;\n    const uuidRegex =\n      /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n\n    if (!uuidRegex.test(userId)) {\n      const { rows: existingUsers } = await this.pool.query(\n        `\n        SELECT id FROM user_profiles \n        WHERE settings->>'legacy_id' = $1 OR id::text = $1\n        LIMIT 1\n      `,\n        [userId],\n      ); // Try match against legacy_id\n\n      if (existingUsers.length > 0) {\n        resolvedUserId = existingUsers[0].id;\n      } else {\n        // If not found, and it's not a UUID, we can't query the UUID column.\n        // Return empty or throw 404. Returning empty is safer for lists.\n        return { success: true, data: [] };\n      }\n    }\n\n    const cacheKey = `user_rides_${resolvedUserId}_${type || \"all\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    let query;\n    let params;\n\n    if (type === \"driver\" || !type) {\n      // Rides where user is the driver\n      query = `\n        SELECT r.*, \n               (r.available_seats - COALESCE(bookings.booked_seats, 0)) as remaining_seats,\n               COALESCE(bookings.booking_count, 0) as total_bookings\n        FROM rides r\n        LEFT JOIN (\n          SELECT ride_id, \n                 SUM(CASE WHEN status = 'approved' THEN seats_requested ELSE 0 END) as booked_seats,\n                 COUNT(*) as booking_count\n          FROM ride_bookings \n          GROUP BY ride_id\n        ) bookings ON r.id = bookings.ride_id\n        WHERE r.driver_id = $1\n        ORDER BY r.departure_time DESC\n      `;\n      params = [resolvedUserId];\n    } else {\n      // Rides where user is a passenger\n      query = `\n        SELECT r.*, rb.status as booking_status, rb.seats_requested, rb.created_at as booking_date,\n               up.name as driver_name, up.phone as driver_phone\n        FROM ride_bookings rb\n        JOIN rides r ON rb.ride_id = r.id\n        LEFT JOIN user_profiles up ON r.driver_id = up.id\n        WHERE rb.passenger_id = $1\n        ORDER BY r.departure_time DESC\n      `;\n      params = [resolvedUserId];\n    }\n\n    const { rows } = await this.pool.query(query, params);\n\n    await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n    return { success: true, data: rows };\n  }\n\n  @Get(\"stats/summary\")\n  async getRideStats() {\n    const cacheKey = \"ride_stats_summary\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(`\n      SELECT \n        COUNT(*) as total_rides,\n        COUNT(DISTINCT driver_id) as unique_drivers,\n        COUNT(CASE WHEN status = 'active' THEN 1 END) as active_rides,\n        COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_rides,\n        SUM(available_seats) as total_seats_offered,\n        AVG(CASE WHEN price_per_seat > 0 THEN price_per_seat END) as avg_price\n      FROM rides\n      WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'\n    `);\n\n    const bookingStats = await this.pool.query(`\n      SELECT \n        COUNT(*) as total_bookings,\n        COUNT(CASE WHEN status = 'approved' THEN 1 END) as approved_bookings,\n        SUM(CASE WHEN status = 'approved' THEN seats_requested ELSE 0 END) as total_seats_booked\n      FROM ride_bookings\n      WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'\n    `);\n\n    const stats = {\n      ...rows[0],\n      ...bookingStats.rows[0],\n    };\n\n    await this.redisCache.set(cacheKey, stats, this.CACHE_TTL);\n    return { success: true, data: stats };\n  }\n\n  @Put(\":id\")\n  async updateRide(@Param(\"id\") id: string, @Body() updateData: any) {\n    const { rows } = await this.pool.query(\n      `\n      UPDATE rides \n      SET title = COALESCE($1, title),\n          description = COALESCE($2, description),\n          departure_time = COALESCE($3, departure_time),\n          arrival_time = COALESCE($4, arrival_time),\n          available_seats = COALESCE($5, available_seats),\n          price_per_seat = COALESCE($6, price_per_seat),\n          requirements = COALESCE($7, requirements),\n          status = COALESCE($8, status),\n          updated_at = NOW()\n      WHERE id = $9\n      RETURNING *\n    `,\n      [\n        updateData.title,\n        updateData.description,\n        updateData.departure_time,\n        updateData.arrival_time,\n        updateData.available_seats,\n        updateData.price_per_seat,\n        updateData.requirements,\n        updateData.status,\n        id,\n      ],\n    );\n\n    if (rows.length === 0) {\n      return { success: false, error: \"Ride not found\" };\n    }\n\n    // Clear specific ride cache\n    await this.redisCache.delete(`ride_${id}`);\n    await this.clearRideCaches();\n    return { success: true, data: rows[0] };\n  }\n\n  @Delete(\":id\")\n  async deleteRide(@Param(\"id\") id: string) {\n    const { rowCount } = await this.pool.query(\n      `\n      UPDATE rides SET status = 'cancelled', updated_at = NOW() WHERE id = $1\n    `,\n      [id],\n    );\n\n    if (rowCount === 0) {\n      return { success: false, error: \"Ride not found\" };\n    }\n\n    // Clear specific ride cache\n    await this.redisCache.delete(`ride_${id}`);\n    await this.clearRideCaches();\n    return { success: true, message: \"Ride cancelled successfully\" };\n  }\n\n  private async clearRideCaches() {\n    const patterns = [\"rides_*\", \"user_rides_*\", \"ride_stats_*\", \"ride_*\"];\n\n    for (const pattern of patterns) {\n      await this.redisCache.invalidatePattern(pattern);\n    }\n  }\n\n  private async clearCommunityStatsCaches() {\n    const patterns = [\n      \"community_stats_*\",\n      \"community_trends_*\",\n      \"dashboard_stats\",\n      \"real_time_stats\",\n    ];\n    for (const pattern of patterns) {\n      const keys = await this.redisCache.getKeys(pattern);\n      for (const key of keys) {\n        await this.redisCache.delete(key);\n      }\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/session.controller.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/stats.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":108,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":108,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4233,4236],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4233,4236],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":127,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":127,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4943,4946],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4943,4946],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":264,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":264,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9271,9274],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9271,9274],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":275,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":275,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9549,9552],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9549,9552],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":319,"column":41,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":319,"endColumn":44,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10930,10933],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10930,10933],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":388,"column":22,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":388,"endColumn":25,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13228,13231],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13228,13231],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":508,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":508,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16894,16897],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16894,16897],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":665,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":665,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[21817,21820],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[21817,21820],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":815,"column":41,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":815,"endColumn":44,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[26438,26441],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[26438,26441],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":861,"column":32,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":861,"endColumn":35,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[28216,28219],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[28216,28219],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Stats/analytics endpoints for community, trends, city-level, category/user analytics, dashboard, and real-time metrics.\n// - Reached from: Routes under '/api/stats'.\n// - Provides: Aggregations over `community_stats`, donations/rides/users; caches responses with TTL; cache invalidation helpers.\n\n// TODO: CRITICAL - This file is extremely long (529+ lines). Split into specialized services:\n//   - CommunityStatsService for community-wide analytics\n//   - TrendsAnalyticsService for trend analysis\n//   - UserStatsService for user-specific analytics\n//   - DashboardStatsService for dashboard data\n//   - StatsCache service for cache management\n// TODO: Add comprehensive DTO validation for all query parameters\n// TODO: Implement proper pagination for large datasets\n// TODO: Add comprehensive error handling and validation\n// TODO: Replace hardcoded SQL queries with proper query builder\n// TODO: Add comprehensive caching strategies with proper invalidation\n// TODO: Implement proper authorization for sensitive stats\n// TODO: Add comprehensive logging and monitoring for analytics queries\n// TODO: Add comprehensive unit tests for all statistical calculations\n// TODO: Implement proper data privacy and anonymization\nimport {\n  Controller,\n  Get,\n  Post,\n  Body,\n  Query,\n  Param,\n  UseGuards,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { JwtAuthGuard, AdminAuthGuard } from \"../auth/jwt-auth.guard\";\n\n@Controller(\"api/stats\")\nexport class StatsController {\n  private readonly logger = new Logger(StatsController.name);\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes for stats\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  @Get(\"community\")\n  // שינוי: הוספת תמיכה ב-forceRefresh parameter לטעינה מחדש של נתונים\n  // Change: Added support for forceRefresh parameter to reload data\n  async getCommunityStats(\n    @Query(\"city\") city?: string,\n    @Query(\"period\") period?: string,\n    @Query(\"forceRefresh\") forceRefresh?: string,\n  ) {\n    try {\n      // TODO: Add comprehensive input validation for city and period parameters\n      // TODO: Implement proper DTO for query parameters with validation\n      // TODO: Add proper cache key generation utility to prevent key collisions\n      // TODO: Add comprehensive error handling for cache operations\n      const cacheKey = `community_stats_${city || \"global\"}_${period || \"current\"}`;\n\n      // Only use cache if forceRefresh is not true\n      // שינוי: תמיכה ב-forceRefresh לדילוג על cache וטעינה מחדש מהמסד נתונים\n      // Change: Support for forceRefresh to skip cache and reload from database\n      if (forceRefresh !== \"true\") {\n        try {\n          const cached = await this.redisCache.get(cacheKey);\n\n          if (cached) {\n            return { success: true, data: cached };\n          }\n        } catch (cacheError) {\n          // Log cache error but continue to fetch from database\n          this.logger.warn(\n            \"Cache get error, continuing to database:\",\n            cacheError,\n          );\n        }\n      } else {\n        // Clear cache when force refresh is requested\n        // ניקוי cache כאשר מתבקש force refresh\n        try {\n          await this.redisCache.delete(cacheKey);\n        } catch (cacheError) {\n          // Log cache error but continue\n          this.logger.warn(\"Cache delete error:\", cacheError);\n        }\n      }\n\n      let dateFilter = \"\";\n      if (period === \"week\") {\n        dateFilter = \"AND date_period >= CURRENT_DATE - INTERVAL '7 days'\";\n      } else if (period === \"month\") {\n        dateFilter = \"AND date_period >= CURRENT_DATE - INTERVAL '30 days'\";\n      } else if (period === \"year\") {\n        dateFilter = \"AND date_period >= CURRENT_DATE - INTERVAL '365 days'\";\n      }\n\n      let query = `\n        SELECT \n          stat_type,\n          SUM(stat_value) as total_value,\n          COUNT(DISTINCT date_period) as days_tracked\n        FROM community_stats \n        WHERE 1=1\n      `;\n\n      const params: any[] = [];\n      if (city) {\n        query += ` AND city = $1`;\n        params.push(city);\n      } else {\n        query += ` AND city IS NULL`;\n      }\n\n      query += dateFilter;\n      query += ` GROUP BY stat_type ORDER BY stat_type`;\n\n      const { rows } = await this.pool.query(query, params);\n\n      // Format response\n      // שינוי: פורמט תגובה עם מבנה value object לתמיכה במיפוי בצד הלקוח\n      // Change: Response format with value object structure for client-side mapping support\n      // TODO: Replace 'any' type with proper statistics response interface\n      // TODO: Add proper data validation and error handling\n      // TODO: Implement proper data transformation utilities\n      const stats: any = {};\n      rows.forEach((row) => {\n        stats[row.stat_type] = {\n          value: parseInt(row.total_value) || 0, // TODO: Add proper number parsing with validation\n          days_tracked: parseInt(row.days_tracked) || 0, // TODO: Add proper number parsing with validation\n        };\n      });\n\n      // Add computed stats\n      // הוספת סטטיסטיקות מחושבות (unique_donors, total_money_donated, וכו')\n      // Adding computed stats (unique_donors, total_money_donated, etc.)\n      await this.addComputedStats(stats, city);\n\n      try {\n        await this.redisCache.set(cacheKey, stats, this.CACHE_TTL);\n      } catch (cacheError) {\n        // Log cache error but still return the stats\n        this.logger.warn(\"Cache set error:\", cacheError);\n      }\n\n      return { success: true, data: stats };\n    } catch (error) {\n      this.logger.error(\"Error in getCommunityStats:\", error);\n      // Return a meaningful error response\n      return {\n        success: false,\n        error: \"Failed to fetch community stats\",\n        message: error instanceof Error ? error.message : \"Unknown error\",\n        data: {}, // Return empty stats to prevent client-side crashes\n      };\n    }\n  }\n\n  @Get(\"community/version\")\n  // Lightweight endpoint to check if stats have changed\n  // נקודת קצה קלת משקל לבדיקה אם הסטטיסטיקות השתנו\n  async getCommunityStatsVersion(@Query(\"city\") city?: string) {\n    try {\n      const cacheKey = `community_stats_version_${city || \"global\"}`;\n\n      // Check cache first (1 minute TTL for version check)\n      try {\n        const cached = await this.redisCache.get(cacheKey);\n        if (cached) {\n          return { success: true, version: cached };\n        }\n      } catch (cacheError) {\n        this.logger.warn(\"Cache get error in version check:\", cacheError);\n      }\n\n      // Get the latest update timestamp from community_stats\n      const query = `\n        SELECT MAX(updated_at) as last_update\n        FROM community_stats\n        ${city ? \"WHERE city = $1\" : \"WHERE city IS NULL\"}\n      `;\n\n      const params = city ? [city] : [];\n      const { rows } = await this.pool.query(query, params);\n\n      // Create version hash from timestamp\n      const lastUpdate = rows[0]?.last_update || new Date();\n      const version = new Date(lastUpdate).getTime().toString();\n\n      // Cache for 1 minute\n      try {\n        await this.redisCache.set(cacheKey, version, 60);\n      } catch (cacheError) {\n        this.logger.warn(\"Cache set error in version check:\", cacheError);\n      }\n\n      return { success: true, version };\n    } catch (error) {\n      this.logger.error(\"Error in getCommunityStatsVersion:\", error);\n      return {\n        success: false,\n        error: \"Failed to fetch stats version\",\n        version: Date.now().toString(), // Return current timestamp as fallback\n      };\n    }\n  }\n\n  @Get(\"community/trends\")\n  async getCommunityTrends(\n    @Query(\"stat_type\") statType: string,\n    @Query(\"city\") city?: string,\n    @Query(\"days\") days?: string,\n  ) {\n    const cacheKey = `community_trends_${statType}_${city || \"global\"}_${days || \"30\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const daysBack = parseInt(days || \"30\");\n    let query = `\n      SELECT date_period, SUM(stat_value) as value\n      FROM community_stats \n      WHERE stat_type = $1\n        AND date_period >= CURRENT_DATE - INTERVAL '${daysBack} days'\n    `;\n\n    const params = [statType];\n    if (city) {\n      query += ` AND city = $2`;\n      params.push(city);\n    } else {\n      query += ` AND city IS NULL`;\n    }\n\n    query += ` GROUP BY date_period ORDER BY date_period ASC`;\n\n    const { rows } = await this.pool.query(query, params);\n\n    await this.redisCache.set(cacheKey, rows, this.CACHE_TTL);\n    return { success: true, data: rows };\n  }\n\n  @Get(\"community/cities\")\n  async getStatsByCity(@Query(\"stat_type\") statType?: string) {\n    const cacheKey = `city_stats_${statType || \"all\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    let query = `\n      SELECT \n        city,\n        stat_type,\n        SUM(stat_value) as total_value\n      FROM community_stats \n      WHERE city IS NOT NULL\n    `;\n\n    const params: any[] = [];\n    if (statType) {\n      query += ` AND stat_type = $1`;\n      params.push(statType);\n    }\n\n    query += ` GROUP BY city, stat_type ORDER BY total_value DESC`;\n\n    const { rows } = await this.pool.query(query, params);\n\n    // Group by city\n    const citiesData: any = {};\n    rows.forEach((row) => {\n      if (!citiesData[row.city]) {\n        citiesData[row.city] = {};\n      }\n      citiesData[row.city][row.stat_type] = parseInt(row.total_value);\n    });\n\n    await this.redisCache.set(cacheKey, citiesData, this.CACHE_TTL);\n    return { success: true, data: citiesData };\n  }\n\n  @Post(\"track-visit\")\n  async trackSiteVisit() {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Track site visit - global stat, no city filter\n      await client.query(`\n        INSERT INTO community_stats (stat_type, stat_value, city, date_period)\n        VALUES ('site_visits', 1, NULL, CURRENT_DATE)\n        ON CONFLICT (stat_type, city, date_period) \n        DO UPDATE SET \n          stat_value = community_stats.stat_value + 1,\n          updated_at = NOW()\n      `);\n\n      // Clear relevant caches\n      await this.clearStatsCaches(\"site_visits\", undefined);\n\n      await client.query(\"COMMIT\");\n      return { success: true, message: \"Site visit tracked successfully\" };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Track site visit error:\", error);\n      return { success: false, error: \"Failed to track site visit\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Post(\"increment\")\n  @UseGuards(AdminAuthGuard)\n  async incrementStat(@Body() statData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Update community stats\n      await client.query(\n        `\n        INSERT INTO community_stats (stat_type, stat_value, city, date_period)\n        VALUES ($1, $2, $3, CURRENT_DATE)\n        ON CONFLICT (stat_type, city, date_period) \n        DO UPDATE SET \n          stat_value = community_stats.stat_value + $2,\n          updated_at = NOW()\n      `,\n        [statData.stat_type, statData.value || 1, statData.city || null],\n      );\n\n      // Clear relevant caches\n      await this.clearStatsCaches(statData.stat_type, statData.city);\n\n      await client.query(\"COMMIT\");\n      return { success: true, message: \"Stat incremented successfully\" };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Increment stat error:\", error);\n      return { success: false, error: \"Failed to increment stat\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get(\"analytics/categories\")\n  async getCategoryAnalytics() {\n    const cacheKey = \"category_analytics\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // Get category usage from donations\n    const donationsByCategory = await this.pool.query(`\n      SELECT \n        dc.slug,\n        dc.name_he,\n        dc.icon,\n        COUNT(d.id) as donation_count,\n        SUM(CASE WHEN d.type = 'money' THEN d.amount ELSE 0 END) as total_money,\n        COUNT(CASE WHEN d.created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as weekly_count,\n        COUNT(CASE WHEN d.created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as monthly_count\n      FROM donation_categories dc\n      LEFT JOIN donations d ON dc.id = d.category_id\n      WHERE dc.is_active = true\n      GROUP BY dc.id, dc.slug, dc.name_he, dc.icon\n      ORDER BY donation_count DESC\n    `);\n\n    // Get category clicks from analytics table (legacy)\n    const analyticsData = await this.pool.query(`\n      SELECT \n        data->>'categoryId' as category_slug,\n        SUM((data->>'count')::integer) as click_count\n      FROM analytics \n      WHERE data->>'categoryId' IS NOT NULL\n      GROUP BY data->>'categoryId'\n    `);\n\n    // Merge data\n    const analytics: any = {};\n    analyticsData.rows.forEach((row) => {\n      analytics[row.category_slug] = {\n        clicks: parseInt(row.click_count) || 0,\n      };\n    });\n\n    const categoryStats = donationsByCategory.rows.map((category) => ({\n      ...category,\n      clicks: analytics[category.slug]?.clicks || 0,\n      engagement_score:\n        category.donation_count * 10 + (analytics[category.slug]?.clicks || 0),\n    }));\n\n    // Cache for 20 minutes - analytics are relatively static\n    await this.redisCache.set(cacheKey, categoryStats, 20 * 60);\n    return { success: true, data: categoryStats };\n  }\n\n  @Get(\"analytics/users\")\n  @UseGuards(AdminAuthGuard)\n  async getUserAnalytics() {\n    const cacheKey = \"user_analytics\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // User growth - from user_profiles only (legacy users table no longer used)\n    const userGrowth = await this.pool.query(`\n      SELECT \n        DATE(join_date) as date,\n        COUNT(*) as new_users\n      FROM user_profiles\n      WHERE email IS NOT NULL AND email <> ''\n        AND join_date >= CURRENT_DATE - INTERVAL '30 days'\n      GROUP BY DATE(join_date)\n      ORDER BY date ASC\n    `);\n\n    // User activity\n    const userActivity = await this.pool.query(`\n      SELECT \n        activity_type,\n        COUNT(*) as count,\n        COUNT(DISTINCT user_id) as unique_users\n      FROM user_activities \n      WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'\n      GROUP BY activity_type\n      ORDER BY count DESC\n    `);\n\n    // User distribution by city - from user_profiles only\n    const usersByCity = await this.pool.query(`\n      SELECT \n        city,\n        COUNT(*) as user_count\n      FROM user_profiles\n      WHERE email IS NOT NULL AND email <> ''\n        AND city IS NOT NULL \n        AND is_active = true\n      GROUP BY city\n      ORDER BY user_count DESC\n      LIMIT 10\n    `);\n\n    const analytics = {\n      user_growth: userGrowth.rows,\n      user_activity: userActivity.rows,\n      users_by_city: usersByCity.rows,\n    };\n\n    // Cache for 20 minutes - analytics are relatively static\n    await this.redisCache.set(cacheKey, analytics, 20 * 60);\n    return { success: true, data: analytics };\n  }\n\n  @Get(\"dashboard\")\n  @UseGuards(JwtAuthGuard)\n  async getDashboardStats() {\n    const cacheKey = \"dashboard_stats\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // Tasks statistics - count by status\n    const tasksStats = await this.pool.query(`\n      SELECT \n        COUNT(CASE WHEN status = 'open' THEN 1 END) as tasks_open,\n        COUNT(CASE WHEN status = 'in_progress' THEN 1 END) as tasks_in_progress,\n        COUNT(CASE WHEN status = 'done' THEN 1 END) as tasks_done,\n        COUNT(*) as tasks_total\n      FROM tasks\n    `);\n\n    // Users and admins statistics\n    const usersStats = await this.pool.query(`\n      SELECT \n        COUNT(*) as total_users,\n        COUNT(CASE \n          WHEN 'admin' = ANY(roles) OR 'super_admin' = ANY(roles) \n          THEN 1 \n        END) as admins_count,\n        COUNT(CASE \n          WHEN NOT ('admin' = ANY(roles) OR 'super_admin' = ANY(roles))\n          THEN 1 \n        END) as regular_users_count,\n        COUNT(CASE \n          WHEN ('admin' = ANY(roles) OR 'super_admin' = ANY(roles)) \n            AND parent_manager_id IS NOT NULL\n          THEN 1 \n        END) as managers_with_subordinates\n      FROM user_profiles\n      WHERE email IS NOT NULL AND email <> ''\n    `);\n\n    // Volunteer hours statistics - check if table exists first\n    let hoursStats: any;\n    try {\n      const tableExists = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'task_time_logs'\n        )\n      `);\n\n      if (tableExists.rows[0].exists) {\n        hoursStats = await this.pool.query(`\n          SELECT \n            COALESCE(SUM(actual_hours), 0)::NUMERIC as total_volunteer_hours,\n            COUNT(DISTINCT user_id) as users_with_hours,\n            COALESCE(\n              SUM(CASE \n                WHEN logged_at >= DATE_TRUNC('month', NOW()) \n                THEN actual_hours ELSE 0 \n              END), 0\n            )::NUMERIC as current_month_hours\n          FROM task_time_logs\n        `);\n      } else {\n        // Table doesn't exist - return zero values\n        hoursStats = {\n          rows: [\n            {\n              total_volunteer_hours: \"0\",\n              users_with_hours: 0,\n              current_month_hours: \"0\",\n            },\n          ],\n        };\n      }\n    } catch (error) {\n      this.logger.warn(\n        \"Task time logs table check failed, using zero values:\",\n        error,\n      );\n      hoursStats = {\n        rows: [\n          {\n            total_volunteer_hours: \"0\",\n            users_with_hours: 0,\n            current_month_hours: \"0\",\n          },\n        ],\n      };\n    }\n\n    const totalHours = parseFloat(\n      hoursStats.rows[0]?.total_volunteer_hours || \"0\",\n    );\n    const usersWithHours = Number(hoursStats.rows[0]?.users_with_hours || 0);\n    const totalUsers = Number(usersStats.rows[0].total_users || 0);\n    const avgHoursPerUser = totalUsers > 0 ? totalHours / totalUsers : 0;\n    const currentMonthHours = parseFloat(\n      hoursStats.rows[0]?.current_month_hours || \"0\",\n    );\n\n    // Merge all metrics and convert to numbers\n    const metrics = {\n      // Tasks stats\n      tasks_open: Number(tasksStats.rows[0].tasks_open || 0),\n      tasks_in_progress: Number(tasksStats.rows[0].tasks_in_progress || 0),\n      tasks_done: Number(tasksStats.rows[0].tasks_done || 0),\n      tasks_total: Number(tasksStats.rows[0].tasks_total || 0),\n\n      // Users stats\n      total_users: totalUsers,\n      admins_count: Number(usersStats.rows[0].admins_count || 0),\n      regular_users_count: Number(usersStats.rows[0].regular_users_count || 0),\n      managers_with_subordinates: Number(\n        usersStats.rows[0].managers_with_subordinates || 0,\n      ),\n\n      // Volunteer hours stats\n      total_volunteer_hours: totalHours,\n      users_with_hours: usersWithHours,\n      avg_hours_per_user: Math.round(avgHoursPerUser * 100) / 100, // Round to 2 decimal places\n      current_month_hours: currentMonthHours,\n    };\n\n    const dashboard = {\n      metrics: metrics,\n    };\n\n    await this.redisCache.set(cacheKey, dashboard, 5 * 60); // 5 minutes cache\n    return { success: true, data: dashboard };\n  }\n\n  @Get(\"real-time\")\n  async getRealTimeStats() {\n    // This endpoint provides frequently updated stats with short cache\n    const cacheKey = \"real_time_stats\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // Last hour's activity\n    const recentActivity = await this.pool.query(`\n      SELECT \n        activity_type,\n        COUNT(*) as count\n      FROM user_activities \n      WHERE created_at >= NOW() - INTERVAL '1 hour'\n      GROUP BY activity_type\n    `);\n\n    // Current active donations and rides\n    const donationsRides = await this.pool.query(`\n      SELECT \n        COUNT(CASE WHEN d.status = 'active' THEN 1 END) as active_donations,\n        COUNT(CASE WHEN r.status = 'active' THEN 1 END) as active_rides\n      FROM donations d\n      FULL OUTER JOIN rides r ON 1=1\n    `);\n\n    // Users online - from user_profiles only\n    const usersOnline = await this.pool.query(`\n      SELECT \n        COUNT(CASE WHEN last_active >= NOW() - INTERVAL '5 minutes' THEN 1 END) as users_online\n      FROM user_profiles\n      WHERE email IS NOT NULL AND email <> ''\n    `);\n\n    const currentActive = {\n      ...donationsRides.rows[0],\n      users_online: usersOnline.rows[0].users_online,\n    };\n\n    const realTimeData = {\n      recent_activity: recentActivity.rows,\n      current_active: currentActive,\n      last_updated: new Date().toISOString(),\n    };\n\n    await this.redisCache.set(cacheKey, realTimeData, 60); // 1 minute cache\n    return { success: true, data: realTimeData };\n  }\n\n  @Get(\"details/:statType\")\n  @UseGuards(JwtAuthGuard)\n  async getStatDetails(@Param(\"statType\") statType: string) {\n    // TODO: Add proper pagination for large datasets\n    // TODO: Add proper data anonymization for sensitive data\n    const cacheKey = `stat_details_${statType}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    let query = \"\";\n    const params: any[] = [];\n\n    try {\n      switch (statType) {\n        case \"siteVisits\":\n          // Get recent site visits with timestamps\n          query = `\n            SELECT \n              created_at as timestamp,\n              NULL as user_agent\n            FROM community_stats \n            WHERE stat_type = 'site_visits'\n            ORDER BY created_at DESC\n            LIMIT 100\n          `;\n          break;\n\n        case \"totalUsers\":\n          // Get all registered users from both user_profiles and users (legacy) tables\n          query = `\n            SELECT \n              name,\n              email,\n              city,\n              join_date,\n              created_at\n            FROM user_profiles \n            WHERE email IS NOT NULL AND email <> ''\n            ORDER BY created_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        case \"totalMoneyDonated\":\n          // Get all money donations with donor info\n          query = `\n            SELECT \n              d.amount,\n              d.created_at,\n              d.created_at as donation_date,\n              up.name as donor_name,\n              dc.name_he as category_name\n            FROM donations d\n            LEFT JOIN user_profiles up ON up.id = d.donor_id\n            LEFT JOIN donation_categories dc ON dc.id = d.category_id\n            WHERE d.type = 'money' AND d.amount > 0\n            ORDER BY d.created_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        case \"itemDonations\":\n          // Get all item donations\n          query = `\n            SELECT \n              d.title,\n              d.title as item_name,\n              d.created_at,\n              up.name as donor_name\n            FROM donations d\n            LEFT JOIN user_profiles up ON up.id = d.donor_id\n            WHERE d.type = 'item' AND d.status = 'active'\n            ORDER BY d.created_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        case \"completedRides\":\n          // Get all completed rides\n          query = `\n            SELECT \n              r.from_location->>'city' as from_city,\n              r.to_location->>'city' as to_city,\n              r.departure_time as ride_date,\n              r.created_at,\n              up.name as driver_name\n            FROM rides r\n            LEFT JOIN user_profiles up ON up.id = r.driver_id\n            WHERE r.status = 'completed'\n            ORDER BY r.created_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        case \"uniqueDonors\":\n        case \"recurringDonationsAmount\":\n          // Get recurring donors\n          query = `\n            SELECT \n              up.name as donor_name,\n              d.amount,\n              d.created_at as start_date,\n              'חודשי' as frequency\n            FROM donations d\n            INNER JOIN user_profiles up ON up.id = d.donor_id\n            WHERE d.is_recurring = true \n              AND d.type = 'money' \n              AND d.status = 'active'\n              AND up.is_active = true\n            ORDER BY d.amount DESC, d.created_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        case \"completedTasks\":\n          // Get completed community tasks\n          // משימות קהילתיות שהושלמו\n          query = `\n            SELECT \n              t.title,\n              t.description,\n              t.category,\n              t.updated_at,\n              t.created_at,\n              up.name as completed_by\n            FROM tasks t\n            LEFT JOIN user_profiles up ON up.id = t.created_by\n            WHERE t.status = 'done'\n            ORDER BY t.updated_at DESC\n            LIMIT 500\n          `;\n          break;\n\n        default:\n          return { success: false, error: \"Unknown stat type\" };\n      }\n\n      const { rows } = await this.pool.query(query, params);\n\n      // Cache for 5 minutes\n      await this.redisCache.set(cacheKey, rows, 5 * 60);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Get stat details error:\", error);\n      return { success: false, error: \"Failed to load stat details\" };\n    }\n  }\n\n  /**\n   * Add computed statistics to the stats object\n   * Uses individual caching for each query type to optimize performance\n   * Each metric type has its own cache key and TTL based on data volatility:\n   * - User metrics: 20 minutes (relatively static)\n   * - Donation/Ride metrics: 15 minutes (moderate changes)\n   * - Activity/Chat metrics: 5 minutes (frequent changes)\n   *\n   * @param stats - Stats object to populate\n   * @param city - Optional city filter for location-based stats\n   */\n  private async addComputedStats(stats: any, city?: string) {\n    try {\n      const params = city ? [city] : [];\n      const userCityCondition = city ? \"AND city = $1\" : \"\";\n      const donationCityCondition = city\n        ? \"AND (d.location->>'city' = $1)\"\n        : \"\";\n      const rideCityCondition = city ? \"AND (from_location->>'city' = $1)\" : \"\";\n      const eventCityCondition = city ? \"AND (location->>'city' = $1)\" : \"\";\n\n      // Generate cache keys for individual queries based on city filter\n      const cityKey = city || \"global\";\n      const cacheKeys = {\n        userMetrics: `computed_stats_users_${cityKey}`,\n        donationMetrics: `computed_stats_donations_${cityKey}`,\n        rideMetrics: `computed_stats_rides_${cityKey}`,\n        eventMetrics: `computed_stats_events_${cityKey}`,\n        activityMetrics: `computed_stats_activities_${cityKey}`,\n        chatMetrics: `computed_stats_chat_${cityKey}`,\n        siteVisitsMetrics: `computed_stats_site_visits_${cityKey}`,\n        taskMetrics: `computed_stats_tasks_${cityKey}`,\n      };\n\n      // Try to get all cached metrics at once\n      let cachedMetrics = new Map();\n      try {\n        cachedMetrics = await this.redisCache.getMultiple([\n          cacheKeys.userMetrics,\n          cacheKeys.donationMetrics,\n          cacheKeys.rideMetrics,\n          cacheKeys.eventMetrics,\n          cacheKeys.activityMetrics,\n          cacheKeys.chatMetrics,\n          cacheKeys.siteVisitsMetrics,\n          cacheKeys.taskMetrics,\n        ]);\n      } catch (cacheError) {\n        this.logger.warn(\n          \"Cache getMultiple error, continuing without cache:\",\n          cacheError,\n        );\n      }\n\n      // Helper function to get cached or execute query\n      const getCachedOrQuery = async (\n        cacheKey: string,\n        queryFn: () => Promise<any>,\n        ttl: number = 10 * 60,\n      ) => {\n        const cached = cachedMetrics.get(cacheKey);\n        if (cached) {\n          // Return in the same format as pool.query would\n          return { rows: [cached] };\n        }\n        const result = await queryFn();\n        // Cache only the first row (query results are arrays with one object)\n        if (result && result.rows && result.rows.length > 0) {\n          await this.redisCache.set(cacheKey, result.rows[0], ttl);\n        }\n        return result;\n      };\n\n      // Basic counts and metrics - with individual caching\n      const queries = await Promise.all([\n        // User metrics - from user_profiles only (legacy users table no longer used)\n        getCachedOrQuery(\n          cacheKeys.userMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(DISTINCT LOWER(email)) as total_users,\n          COUNT(DISTINCT CASE WHEN is_active = true AND last_active >= NOW() - INTERVAL '30 days' THEN LOWER(email) END) as active_members,\n          COUNT(DISTINCT CASE WHEN last_active >= NOW() - INTERVAL '1 day' THEN LOWER(email) END) as daily_active_users,\n          COUNT(DISTINCT CASE WHEN last_active >= NOW() - INTERVAL '7 days' THEN LOWER(email) END) as weekly_active_users,\n          COUNT(DISTINCT CASE WHEN join_date >= CURRENT_DATE - INTERVAL '7 days' THEN LOWER(email) END) as new_users_this_week,\n          COUNT(DISTINCT CASE WHEN join_date >= CURRENT_DATE - INTERVAL '30 days' THEN LOWER(email) END) as new_users_this_month,\n          COUNT(DISTINCT CASE WHEN 'org_admin' = ANY(roles) THEN LOWER(email) END) as total_organizations,\n          COUNT(DISTINCT city) as cities_with_users\n        FROM user_profiles\n        WHERE email IS NOT NULL AND email <> ''\n          ${userCityCondition}\n      `,\n              params,\n            ),\n          20 * 60,\n        ), // Cache for 20 minutes - user metrics are relatively static\n\n        // Donation metrics\n        getCachedOrQuery(\n          cacheKeys.donationMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(*) as total_donations,\n          COUNT(CASE WHEN d.created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as donations_this_week,\n          COUNT(CASE WHEN d.created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as donations_this_month,\n          COUNT(CASE WHEN d.status = 'active' THEN 1 END) as active_donations,\n          COUNT(CASE WHEN d.status = 'completed' THEN 1 END) as completed_donations,\n          COUNT(CASE WHEN d.type = 'money' THEN 1 END) as money_donations,\n          COUNT(CASE WHEN d.type = 'item' AND d.status = 'active' THEN 1 END) as item_donations,\n          COUNT(CASE WHEN d.type = 'service' THEN 1 END) as service_donations,\n          COUNT(CASE WHEN d.type = 'time' THEN 1 END) as volunteer_hours,\n          SUM(CASE WHEN d.type = 'money' THEN d.amount ELSE 0 END) as total_money_donated,\n          SUM(CASE WHEN d.type = 'money' AND d.is_recurring = true AND d.status = 'active' THEN d.amount ELSE 0 END) as recurring_donations_amount,\n          COUNT(DISTINCT CASE WHEN d.is_recurring = true AND up.is_active = true THEN d.donor_id END) as unique_donors\n        FROM donations d\n        LEFT JOIN user_profiles up ON up.id = d.donor_id\n        WHERE 1=1 ${donationCityCondition}\n      `,\n              params,\n            ),\n          15 * 60,\n        ), // Cache for 15 minutes\n\n        // Ride metrics\n        getCachedOrQuery(\n          cacheKeys.rideMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(*) as total_rides,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as rides_this_week,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as rides_this_month,\n          COUNT(CASE WHEN status = 'active' THEN 1 END) as active_rides,\n          COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_rides,\n          SUM(available_seats) as total_seats_offered,\n          COUNT(DISTINCT driver_id) as unique_drivers\n        FROM rides \n        WHERE 1=1 ${rideCityCondition}\n      `,\n              params,\n            ),\n          15 * 60,\n        ), // Cache for 15 minutes\n\n        // Event metrics\n        getCachedOrQuery(\n          cacheKeys.eventMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(*) as total_events,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as events_this_week,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as events_this_month,\n          COUNT(CASE WHEN status = 'active' THEN 1 END) as active_events,\n          COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_events,\n          SUM(current_attendees) as total_event_attendees,\n          COUNT(CASE WHEN is_virtual = true THEN 1 END) as virtual_events\n        FROM community_events \n        WHERE 1=1 ${eventCityCondition}\n      `,\n              params,\n            ),\n          10 * 60,\n        ), // Cache for 10 minutes\n\n        // Activity and engagement metrics\n        getCachedOrQuery(\n          cacheKeys.activityMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(*) as total_activities,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '1 day' THEN 1 END) as activities_today,\n          COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as activities_this_week,\n          COUNT(CASE WHEN activity_type = 'login' THEN 1 END) as total_logins,\n          COUNT(CASE WHEN activity_type = 'donation' THEN 1 END) as donation_activities,\n          COUNT(CASE WHEN activity_type = 'chat' THEN 1 END) as chat_activities,\n          COUNT(DISTINCT user_id) as active_users_tracked\n        FROM user_activities \n        WHERE created_at >= CURRENT_DATE - INTERVAL '90 days'\n      `,\n              [],\n            ),\n          5 * 60,\n        ), // Cache for 5 minutes - activities change frequently\n\n        // Chat and social metrics\n        getCachedOrQuery(\n          cacheKeys.chatMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(DISTINCT cm.id) as total_messages,\n          COUNT(DISTINCT cc.id) as total_conversations,\n          COUNT(CASE WHEN cm.created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as messages_this_week,\n          COUNT(CASE WHEN cc.type = 'group' THEN 1 END) as group_conversations,\n          COUNT(CASE WHEN cc.type = 'direct' THEN 1 END) as direct_conversations\n        FROM chat_conversations cc\n        LEFT JOIN chat_messages cm ON cc.id = cm.conversation_id\n        WHERE cm.is_deleted = false\n      `,\n              [],\n            ),\n          5 * 60,\n        ), // Cache for 5 minutes - chat metrics change frequently\n\n        // Site visits - sum of stat_value (each record can represent multiple visits on the same day)\n        // ביקורים באתר - סכום של stat_value (כל רשומה יכולה לייצג מספר ביקורים באותו יום)\n        // Note: If there are 4 records with stat_value=1 each, sum will be 4. If 1 record with stat_value=4, sum will also be 4.\n        // Apply city filter if provided (site_visits are global, so city is NULL)\n        getCachedOrQuery(\n          cacheKeys.siteVisitsMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COALESCE(SUM(stat_value), 0) as site_visits\n        FROM community_stats \n        WHERE stat_type = 'site_visits'\n        ${city ? \"AND city IS NULL\" : \"\"}\n      `,\n              params,\n            ),\n          5 * 60,\n        ), // Cache for 5 minutes\n\n        // Task metrics - community tasks (all tasks are community tasks, not personal)\n        // סטטיסטיקות משימות - משימות קהילתיות (כל המשימות הן קהילתיות ולא אישיות)\n        getCachedOrQuery(\n          cacheKeys.taskMetrics,\n          () =>\n            this.pool.query(\n              `\n        SELECT \n          COUNT(*) as total_tasks,\n          COUNT(CASE WHEN status = 'done' THEN 1 END) as completed_tasks,\n          COUNT(CASE WHEN status = 'open' THEN 1 END) as open_tasks,\n          COUNT(CASE WHEN status = 'in_progress' THEN 1 END) as in_progress_tasks,\n          COUNT(CASE WHEN status = 'done' AND updated_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as completed_tasks_this_week,\n          COUNT(CASE WHEN status = 'done' AND updated_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as completed_tasks_this_month\n        FROM tasks\n      `,\n              [],\n            ),\n          10 * 60,\n        ), // Cache for 10 minutes\n      ]);\n\n      const [\n        userMetrics,\n        donationMetrics,\n        rideMetrics,\n        eventMetrics,\n        activityMetrics,\n        chatMetrics,\n        siteVisitsMetrics,\n        taskMetrics,\n      ] = queries;\n\n      // Map all computed stats\n      const computed = {\n        // User stats\n        total_users: {\n          value: parseInt(userMetrics.rows[0].total_users || \"0\"),\n          days_tracked: 1,\n        },\n        active_members: {\n          value: parseInt(userMetrics.rows[0].active_members || \"0\"),\n          days_tracked: 1,\n        },\n        daily_active_users: {\n          value: parseInt(userMetrics.rows[0].daily_active_users || \"0\"),\n          days_tracked: 1,\n        },\n        weekly_active_users: {\n          value: parseInt(userMetrics.rows[0].weekly_active_users || \"0\"),\n          days_tracked: 1,\n        },\n        new_users_this_week: {\n          value: parseInt(userMetrics.rows[0].new_users_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        new_users_this_month: {\n          value: parseInt(userMetrics.rows[0].new_users_this_month || \"0\"),\n          days_tracked: 1,\n        },\n        total_organizations: {\n          value: parseInt(userMetrics.rows[0].total_organizations || \"0\"),\n          days_tracked: 1,\n        },\n        cities_with_users: {\n          value: parseInt(userMetrics.rows[0].cities_with_users || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Donation stats\n        total_donations: {\n          value: parseInt(donationMetrics.rows[0].total_donations || \"0\"),\n          days_tracked: 1,\n        },\n        donations_this_week: {\n          value: parseInt(donationMetrics.rows[0].donations_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        donations_this_month: {\n          value: parseInt(donationMetrics.rows[0].donations_this_month || \"0\"),\n          days_tracked: 1,\n        },\n        active_donations: {\n          value: parseInt(donationMetrics.rows[0].active_donations || \"0\"),\n          days_tracked: 1,\n        },\n        completed_donations: {\n          value: parseInt(donationMetrics.rows[0].completed_donations || \"0\"),\n          days_tracked: 1,\n        },\n        money_donations: {\n          value: parseInt(donationMetrics.rows[0].money_donations || \"0\"),\n          days_tracked: 1,\n        },\n        item_donations: {\n          value: parseInt(donationMetrics.rows[0].item_donations || \"0\"),\n          days_tracked: 1,\n        },\n        service_donations: {\n          value: parseInt(donationMetrics.rows[0].service_donations || \"0\"),\n          days_tracked: 1,\n        },\n        volunteer_hours: {\n          value: parseInt(donationMetrics.rows[0].volunteer_hours || \"0\"),\n          days_tracked: 1,\n        },\n        total_money_donated: {\n          value: parseFloat(donationMetrics.rows[0].total_money_donated || \"0\"),\n          days_tracked: 1,\n        },\n        recurring_donations_amount: {\n          value: parseFloat(\n            donationMetrics.rows[0].recurring_donations_amount || \"0\",\n          ),\n          days_tracked: 1,\n        },\n        unique_donors: {\n          value: parseInt(donationMetrics.rows[0].unique_donors || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Ride stats\n        total_rides: {\n          value: parseInt(rideMetrics.rows[0].total_rides || \"0\"),\n          days_tracked: 1,\n        },\n        rides_this_week: {\n          value: parseInt(rideMetrics.rows[0].rides_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        rides_this_month: {\n          value: parseInt(rideMetrics.rows[0].rides_this_month || \"0\"),\n          days_tracked: 1,\n        },\n        active_rides: {\n          value: parseInt(rideMetrics.rows[0].active_rides || \"0\"),\n          days_tracked: 1,\n        },\n        completed_rides: {\n          value: parseInt(rideMetrics.rows[0].completed_rides || \"0\"),\n          days_tracked: 1,\n        },\n        total_seats_offered: {\n          value: parseInt(rideMetrics.rows[0].total_seats_offered || \"0\"),\n          days_tracked: 1,\n        },\n        unique_drivers: {\n          value: parseInt(rideMetrics.rows[0].unique_drivers || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Event stats\n        total_events: {\n          value: parseInt(eventMetrics.rows[0].total_events || \"0\"),\n          days_tracked: 1,\n        },\n        events_this_week: {\n          value: parseInt(eventMetrics.rows[0].events_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        events_this_month: {\n          value: parseInt(eventMetrics.rows[0].events_this_month || \"0\"),\n          days_tracked: 1,\n        },\n        active_events: {\n          value: parseInt(eventMetrics.rows[0].active_events || \"0\"),\n          days_tracked: 1,\n        },\n        completed_events: {\n          value: parseInt(eventMetrics.rows[0].completed_events || \"0\"),\n          days_tracked: 1,\n        },\n        total_event_attendees: {\n          value: parseInt(eventMetrics.rows[0].total_event_attendees || \"0\"),\n          days_tracked: 1,\n        },\n        virtual_events: {\n          value: parseInt(eventMetrics.rows[0].virtual_events || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Activity stats\n        total_activities: {\n          value: parseInt(activityMetrics.rows[0].total_activities || \"0\"),\n          days_tracked: 1,\n        },\n        activities_today: {\n          value: parseInt(activityMetrics.rows[0].activities_today || \"0\"),\n          days_tracked: 1,\n        },\n        activities_this_week: {\n          value: parseInt(activityMetrics.rows[0].activities_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        total_logins: {\n          value: parseInt(activityMetrics.rows[0].total_logins || \"0\"),\n          days_tracked: 1,\n        },\n        donation_activities: {\n          value: parseInt(activityMetrics.rows[0].donation_activities || \"0\"),\n          days_tracked: 1,\n        },\n        chat_activities: {\n          value: parseInt(activityMetrics.rows[0].chat_activities || \"0\"),\n          days_tracked: 1,\n        },\n        active_users_tracked: {\n          value: parseInt(activityMetrics.rows[0].active_users_tracked || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Chat stats\n        total_messages: {\n          value: parseInt(chatMetrics.rows[0].total_messages || \"0\"),\n          days_tracked: 1,\n        },\n        total_conversations: {\n          value: parseInt(chatMetrics.rows[0].total_conversations || \"0\"),\n          days_tracked: 1,\n        },\n        messages_this_week: {\n          value: parseInt(chatMetrics.rows[0].messages_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        group_conversations: {\n          value: parseInt(chatMetrics.rows[0].group_conversations || \"0\"),\n          days_tracked: 1,\n        },\n        direct_conversations: {\n          value: parseInt(chatMetrics.rows[0].direct_conversations || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Site visits - use existing value from getCommunityStats if available, otherwise compute\n        // ביקורים באתר - השתמש בערך הקיים מ-getCommunityStats אם קיים, אחרת חשב\n        site_visits: stats.site_visits || {\n          value: parseInt(siteVisitsMetrics.rows[0].site_visits || \"0\"),\n          days_tracked: 1,\n        },\n\n        // Task stats - community tasks (all tasks are community tasks)\n        // סטטיסטיקות משימות קהילתיות\n        total_tasks: {\n          value: parseInt(taskMetrics.rows[0].total_tasks || \"0\"),\n          days_tracked: 1,\n        },\n        completed_tasks: {\n          value: parseInt(taskMetrics.rows[0].completed_tasks || \"0\"),\n          days_tracked: 1,\n        },\n        open_tasks: {\n          value: parseInt(taskMetrics.rows[0].open_tasks || \"0\"),\n          days_tracked: 1,\n        },\n        in_progress_tasks: {\n          value: parseInt(taskMetrics.rows[0].in_progress_tasks || \"0\"),\n          days_tracked: 1,\n        },\n        completed_tasks_this_week: {\n          value: parseInt(taskMetrics.rows[0].completed_tasks_this_week || \"0\"),\n          days_tracked: 1,\n        },\n        completed_tasks_this_month: {\n          value: parseInt(\n            taskMetrics.rows[0].completed_tasks_this_month || \"0\",\n          ),\n          days_tracked: 1,\n        },\n      };\n\n      // Add computed stats to the main stats object\n      Object.assign(stats, computed);\n\n      // Add derived metrics after base stats are set\n      stats.avg_donation_amount = {\n        value:\n          stats.money_donations?.value > 0\n            ? Math.round(\n                stats.total_money_donated.value / stats.money_donations.value,\n              )\n            : 0,\n        days_tracked: 1,\n      };\n      stats.avg_seats_per_ride = {\n        value:\n          stats.total_rides?.value > 0\n            ? Math.round(\n                stats.total_seats_offered.value / stats.total_rides.value,\n              )\n            : 0,\n        days_tracked: 1,\n      };\n      stats.user_engagement_rate = {\n        value:\n          stats.total_users?.value > 0\n            ? Math.round(\n                (stats.weekly_active_users.value / stats.total_users.value) *\n                  100,\n              )\n            : 0,\n        days_tracked: 1,\n      };\n\n      // Legacy compatibility\n      if (!stats.total_contributions) {\n        stats.total_contributions = {\n          value:\n            (stats.money_donations?.value || 0) +\n            (stats.volunteer_hours?.value || 0) +\n            (stats.total_rides?.value || 0),\n          days_tracked: 1,\n        };\n      }\n    } catch (error) {\n      this.logger.error(\"Error in addComputedStats:\", error);\n      // Set default values for all computed stats to prevent undefined errors\n      const defaultStats = {\n        total_users: { value: 0, days_tracked: 1 },\n        active_members: { value: 0, days_tracked: 1 },\n        daily_active_users: { value: 0, days_tracked: 1 },\n        weekly_active_users: { value: 0, days_tracked: 1 },\n        new_users_this_week: { value: 0, days_tracked: 1 },\n        new_users_this_month: { value: 0, days_tracked: 1 },\n        total_organizations: { value: 0, days_tracked: 1 },\n        cities_with_users: { value: 0, days_tracked: 1 },\n        total_donations: { value: 0, days_tracked: 1 },\n        donations_this_week: { value: 0, days_tracked: 1 },\n        donations_this_month: { value: 0, days_tracked: 1 },\n        active_donations: { value: 0, days_tracked: 1 },\n        completed_donations: { value: 0, days_tracked: 1 },\n        money_donations: { value: 0, days_tracked: 1 },\n        item_donations: { value: 0, days_tracked: 1 },\n        service_donations: { value: 0, days_tracked: 1 },\n        volunteer_hours: { value: 0, days_tracked: 1 },\n        total_money_donated: { value: 0, days_tracked: 1 },\n        recurring_donations_amount: { value: 0, days_tracked: 1 },\n        unique_donors: { value: 0, days_tracked: 1 },\n        total_rides: { value: 0, days_tracked: 1 },\n        rides_this_week: { value: 0, days_tracked: 1 },\n        rides_this_month: { value: 0, days_tracked: 1 },\n        active_rides: { value: 0, days_tracked: 1 },\n        completed_rides: { value: 0, days_tracked: 1 },\n        total_seats_offered: { value: 0, days_tracked: 1 },\n        unique_drivers: { value: 0, days_tracked: 1 },\n        total_events: { value: 0, days_tracked: 1 },\n        events_this_week: { value: 0, days_tracked: 1 },\n        events_this_month: { value: 0, days_tracked: 1 },\n        active_events: { value: 0, days_tracked: 1 },\n        completed_events: { value: 0, days_tracked: 1 },\n        total_event_attendees: { value: 0, days_tracked: 1 },\n        virtual_events: { value: 0, days_tracked: 1 },\n        total_activities: { value: 0, days_tracked: 1 },\n        activities_today: { value: 0, days_tracked: 1 },\n        activities_this_week: { value: 0, days_tracked: 1 },\n        total_logins: { value: 0, days_tracked: 1 },\n        donation_activities: { value: 0, days_tracked: 1 },\n        chat_activities: { value: 0, days_tracked: 1 },\n        active_users_tracked: { value: 0, days_tracked: 1 },\n        total_messages: { value: 0, days_tracked: 1 },\n        total_conversations: { value: 0, days_tracked: 1 },\n        messages_this_week: { value: 0, days_tracked: 1 },\n        group_conversations: { value: 0, days_tracked: 1 },\n        direct_conversations: { value: 0, days_tracked: 1 },\n        site_visits: { value: 0, days_tracked: 1 },\n        total_tasks: { value: 0, days_tracked: 1 },\n        completed_tasks: { value: 0, days_tracked: 1 },\n        open_tasks: { value: 0, days_tracked: 1 },\n        in_progress_tasks: { value: 0, days_tracked: 1 },\n        completed_tasks_this_week: { value: 0, days_tracked: 1 },\n        completed_tasks_this_month: { value: 0, days_tracked: 1 },\n        avg_donation_amount: { value: 0, days_tracked: 1 },\n        avg_seats_per_ride: { value: 0, days_tracked: 1 },\n        user_engagement_rate: { value: 0, days_tracked: 1 },\n        total_contributions: { value: 0, days_tracked: 1 },\n      };\n      Object.assign(stats, defaultStats);\n    }\n  }\n\n  @Post(\"community/reset\")\n  @UseGuards(AdminAuthGuard)\n  async resetCommunityStats() {\n    try {\n      // Delete all community_stats records\n      await this.pool.query(`DELETE FROM community_stats`);\n\n      // Clear all stats-related caches\n      await this.clearStatsCaches();\n\n      return {\n        success: true,\n        message: \"Community statistics reset successfully\",\n      };\n    } catch (error) {\n      this.logger.error(\"Reset community stats error:\", error);\n      return { success: false, error: \"Failed to reset community statistics\" };\n    }\n  }\n\n  private async clearStatsCaches(_statType?: string, _city?: string) {\n    // Use the shared method from RedisCacheService\n    await this.redisCache.clearStatsCaches();\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/sync.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":99,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":99,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3130,3133],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3130,3133],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":142,"column":31,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":142,"endColumn":34,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4688,4691],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4688,4691],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":246,"column":33,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":246,"endColumn":36,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8336,8339],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8336,8339],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":295,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":295,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10160,10163],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10160,10163],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":305,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":305,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10449,10452],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10449,10452],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":366,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":366,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12512,12515],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12512,12515],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":420,"column":35,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":420,"endColumn":38,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14778,14781],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14778,14781],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":497,"column":35,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":497,"endColumn":38,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[17853,17856],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[17853,17856],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":544,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":544,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[19704,19707],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[19704,19707],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":574,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":574,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[20561,20564],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[20561,20564],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":628,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":628,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[22338,22341],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[22338,22341],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":11,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Sync Firebase Authentication users to user_profiles table\n// - Provides: Endpoint to sync users automatically (can be called from Firebase Cloud Function)\n// - Security: Should be protected with API key or admin authentication\n\nimport {\n  Controller,\n  Post,\n  Body,\n  Get,\n  Headers,\n  UnauthorizedException,\n  UseGuards,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { AdminAuthGuard } from \"../auth/jwt-auth.guard\";\nimport * as admin from \"firebase-admin\";\n\n@Controller(\"api/sync\")\nexport class SyncController {\n  private readonly logger = new Logger(SyncController.name);\n  // Simple API key check - in production, use proper authentication\n  private readonly SYNC_API_KEY =\n    process.env.SYNC_API_KEY || \"change-me-in-production\";\n  constructor(@Inject(PG_POOL) private readonly pool: Pool) {\n    // Initialize Firebase Admin SDK if not already initialized\n    if (!admin.apps.length) {\n      try {\n        if (process.env.FIREBASE_SERVICE_ACCOUNT_KEY) {\n          const serviceAccount = JSON.parse(\n            process.env.FIREBASE_SERVICE_ACCOUNT_KEY,\n          );\n          admin.initializeApp({\n            credential: admin.credential.cert(serviceAccount),\n          });\n        } else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {\n          admin.initializeApp({\n            credential: admin.credential.applicationDefault(),\n          });\n        }\n      } catch {\n        this.logger.warn(\n          \"⚠️ Firebase Admin SDK not initialized - sync endpoint will not work\",\n        );\n      }\n    }\n  }\n\n  /**\n   * Check API key for sync endpoints\n   */\n  private checkApiKey(apiKey?: string) {\n    if (!apiKey || apiKey !== this.SYNC_API_KEY) {\n      throw new UnauthorizedException(\"Invalid API key\");\n    }\n  }\n\n  /**\n   * Sync a single user from Firebase to user_profiles\n   * Can be called from Firebase Cloud Function when a new user is created\n   *\n   * @param body - { firebase_uid: string } or { email: string }\n   * @param headers - API key in X-API-Key header\n   * @returns Success status\n   */\n  @Post(\"user\")\n  @UseGuards(AdminAuthGuard)\n  async syncUser(\n    @Body() body: { firebase_uid?: string; email?: string },\n    @Headers(\"x-api-key\") apiKey?: string,\n  ) {\n    // Check API key (optional - can be disabled for internal use)\n    if (this.SYNC_API_KEY !== \"change-me-in-production\") {\n      this.checkApiKey(apiKey);\n    }\n    const { firebase_uid, email } = body;\n\n    if (!firebase_uid && !email) {\n      return { success: false, error: \"Must provide firebase_uid or email\" };\n    }\n\n    try {\n      // Get user from Firebase\n      let firebaseUser: admin.auth.UserRecord;\n      try {\n        if (firebase_uid) {\n          firebaseUser = await admin.auth().getUser(firebase_uid);\n        } else if (email) {\n          firebaseUser = await admin.auth().getUserByEmail(email);\n        } else {\n          return {\n            success: false,\n            error: \"Must provide firebase_uid or email\",\n          };\n        }\n      } catch (error: any) {\n        this.logger.error(\"❌ Error fetching user from Firebase:\", error);\n        return { success: false, error: \"User not found in Firebase\" };\n      }\n\n      if (!firebaseUser.email) {\n        return { success: false, error: \"User has no email\" };\n      }\n\n      const normalizedEmail = firebaseUser.email.toLowerCase().trim();\n\n      // Extract Google ID from provider data if available\n      let googleId: string | null = null;\n      const googleProvider = firebaseUser.providerData?.find(\n        (p) => p.providerId === \"google.com\",\n      );\n      if (googleProvider?.uid) {\n        googleId = googleProvider.uid;\n      }\n\n      const client = await this.pool.connect();\n      try {\n        await client.query(\"BEGIN\");\n\n        // Check if user already exists\n        const { rows: existingUsers } = await client.query(\n          `SELECT id, email, firebase_uid, google_id FROM user_profiles \n           WHERE firebase_uid = $1 OR LOWER(email) = LOWER($2)\n           LIMIT 1`,\n          [firebaseUser.uid, normalizedEmail],\n        );\n\n        const creationTime = firebaseUser.metadata.creationTime\n          ? new Date(firebaseUser.metadata.creationTime)\n          : new Date();\n        const lastSignInTime = firebaseUser.metadata.lastSignInTime\n          ? new Date(firebaseUser.metadata.lastSignInTime)\n          : creationTime;\n\n        if (existingUsers.length > 0) {\n          // User exists - update if needed\n          const existingUser = existingUsers[0];\n          const needsUpdate: string[] = [];\n          const updateValues: any[] = [];\n          let paramCount = 1;\n\n          if (\n            !existingUser.firebase_uid ||\n            existingUser.firebase_uid !== firebaseUser.uid\n          ) {\n            needsUpdate.push(`firebase_uid = $${paramCount++}`);\n            updateValues.push(firebaseUser.uid);\n          }\n\n          if (\n            googleId &&\n            (!existingUser.google_id || existingUser.google_id !== googleId)\n          ) {\n            needsUpdate.push(`google_id = $${paramCount++}`);\n            updateValues.push(googleId);\n          }\n\n          if (\n            firebaseUser.displayName &&\n            existingUser.name !== firebaseUser.displayName\n          ) {\n            needsUpdate.push(`name = $${paramCount++}`);\n            updateValues.push(firebaseUser.displayName);\n          }\n\n          if (firebaseUser.photoURL) {\n            needsUpdate.push(`avatar_url = $${paramCount++}`);\n            updateValues.push(firebaseUser.photoURL);\n          }\n\n          if (firebaseUser.emailVerified !== undefined) {\n            needsUpdate.push(`email_verified = $${paramCount++}`);\n            updateValues.push(firebaseUser.emailVerified);\n          }\n\n          if (firebaseUser.metadata.lastSignInTime) {\n            needsUpdate.push(`last_active = $${paramCount++}`);\n            updateValues.push(new Date(firebaseUser.metadata.lastSignInTime));\n          }\n\n          if (needsUpdate.length > 0) {\n            needsUpdate.push(`updated_at = NOW()`);\n            updateValues.push(existingUser.id);\n\n            await client.query(\n              `UPDATE user_profiles \n               SET ${needsUpdate.join(\", \")} \n               WHERE id = $${paramCount}`,\n              updateValues,\n            );\n            await client.query(\"COMMIT\");\n            return {\n              success: true,\n              action: \"updated\",\n              user_id: existingUser.id,\n            };\n          } else {\n            await client.query(\"COMMIT\");\n            return {\n              success: true,\n              action: \"no_changes\",\n              user_id: existingUser.id,\n            };\n          }\n        } else {\n          // User doesn't exist - create new\n          try {\n            const { rows: newUser } = await client.query(\n              `INSERT INTO user_profiles (\n                firebase_uid, google_id, email, name, avatar_url, bio,\n                karma_points, join_date, is_active, last_active,\n                city, country, interests, roles, email_verified, settings\n              ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::text[], $14::text[], $15, $16::jsonb)\n              RETURNING id`,\n              [\n                firebaseUser.uid,\n                googleId,\n                normalizedEmail,\n                firebaseUser.displayName ||\n                  normalizedEmail.split(\"@\")[0] ||\n                  \"User\",\n                firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\",\n                \"משתמש חדש בקארמה קומיוניטי\",\n                0,\n                creationTime,\n                true,\n                lastSignInTime,\n                \"ישראל\",\n                \"Israel\",\n                [],\n                [\"user\"],\n                firebaseUser.emailVerified || false,\n                JSON.stringify({\n                  language: \"he\",\n                  dark_mode: false,\n                  notifications_enabled: true,\n                  privacy: \"public\",\n                }),\n              ],\n            );\n            await client.query(\"COMMIT\");\n            return { success: true, action: \"created\", user_id: newUser[0].id };\n          } catch (insertError: any) {\n            // If google_id column doesn't exist, try without it\n            if (\n              insertError.message &&\n              insertError.message.includes(\"google_id\")\n            ) {\n              const { rows: newUser } = await client.query(\n                `INSERT INTO user_profiles (\n                  firebase_uid, email, name, avatar_url, bio,\n                  karma_points, join_date, is_active, last_active,\n                  city, country, interests, roles, email_verified, settings\n                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb)\n                RETURNING id`,\n                [\n                  firebaseUser.uid,\n                  normalizedEmail,\n                  firebaseUser.displayName ||\n                    normalizedEmail.split(\"@\")[0] ||\n                    \"User\",\n                  firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\",\n                  \"משתמש חדש בקארמה קומיוניטי\",\n                  0,\n                  creationTime,\n                  true,\n                  lastSignInTime,\n                  \"ישראל\",\n                  \"Israel\",\n                  [],\n                  [\"user\"],\n                  firebaseUser.emailVerified || false,\n                  JSON.stringify({\n                    language: \"he\",\n                    dark_mode: false,\n                    notifications_enabled: true,\n                    privacy: \"public\",\n                  }),\n                ],\n              );\n              await client.query(\"COMMIT\");\n              return {\n                success: true,\n                action: \"created\",\n                user_id: newUser[0].id,\n              };\n            } else {\n              throw insertError;\n            }\n          }\n        }\n      } catch (error: any) {\n        await client.query(\"ROLLBACK\");\n        this.logger.error(\"❌ Error syncing user:\", error);\n        return {\n          success: false,\n          error: error.message || \"Failed to sync user\",\n        };\n      } finally {\n        client.release();\n      }\n    } catch (error: any) {\n      this.logger.error(\"❌ Sync user error:\", error);\n      return { success: false, error: error.message || \"Failed to sync user\" };\n    }\n  }\n\n  /**\n   * Sync ALL users from Firebase to user_profiles\n   * This endpoint runs the full sync process - use with caution in production\n   *\n   * @param headers - API key in X-API-Key header (optional if SYNC_API_KEY is not set)\n   * @returns Sync summary with created/updated counts\n   */\n  @Post(\"all\")\n  @UseGuards(AdminAuthGuard)\n  async syncAllUsers(@Headers(\"x-api-key\") apiKey?: string) {\n    // Check API key (optional - can be disabled for internal use)\n    if (this.SYNC_API_KEY !== \"change-me-in-production\") {\n      this.checkApiKey(apiKey);\n    }\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      this.logger.log(\"🔄 Starting full Firebase users sync...\");\n\n      // Get all users from Firebase Authentication\n      let allUsers: admin.auth.UserRecord[] = [];\n      let nextPageToken: string | undefined;\n\n      do {\n        const listUsersResult = await admin\n          .auth()\n          .listUsers(1000, nextPageToken);\n        allUsers = allUsers.concat(listUsersResult.users);\n        nextPageToken = listUsersResult.pageToken;\n        this.logger.log(`📥 Fetched ${allUsers.length} users from Firebase...`);\n      } while (nextPageToken);\n\n      this.logger.log(`✅ Total users in Firebase: ${allUsers.length}`);\n\n      let created = 0;\n      let updated = 0;\n      let skipped = 0;\n      let errors = 0;\n\n      for (const firebaseUser of allUsers) {\n        try {\n          // Skip users without email\n          if (!firebaseUser.email) {\n            this.logger.log(`⚠️ Skipping user ${firebaseUser.uid} - no email`);\n            skipped++;\n            continue;\n          }\n\n          const normalizedEmail = firebaseUser.email.toLowerCase().trim();\n\n          // Extract Google ID from provider data if available\n          let googleId: string | null = null;\n          const googleProvider = firebaseUser.providerData?.find(\n            (p: any) => p.providerId === \"google.com\",\n          );\n          if (googleProvider?.uid) {\n            googleId = googleProvider.uid;\n          }\n\n          const creationTime = firebaseUser.metadata.creationTime\n            ? new Date(firebaseUser.metadata.creationTime).toISOString()\n            : new Date().toISOString();\n          const lastSignInTime = firebaseUser.metadata.lastSignInTime\n            ? new Date(firebaseUser.metadata.lastSignInTime).toISOString()\n            : creationTime;\n\n          // Check if user already exists\n          const { rows: existingUsers } = await client.query(\n            `SELECT id, firebase_uid, email, google_id FROM user_profiles \n             WHERE email = $1 OR firebase_uid = $2 OR (google_id IS NOT NULL AND google_id = $3)\n             LIMIT 1`,\n            [normalizedEmail, firebaseUser.uid, googleId],\n          );\n\n          if (existingUsers.length > 0) {\n            // Update existing user\n            const existingUser = existingUsers[0];\n            try {\n              await client.query(\n                `UPDATE user_profiles SET\n                  firebase_uid = COALESCE($1, firebase_uid),\n                  name = COALESCE($2, name),\n                  avatar_url = COALESCE($3, avatar_url),\n                  email_verified = COALESCE($4, email_verified),\n                  last_active = GREATEST(COALESCE($5, last_active), last_active),\n                  google_id = COALESCE($6, google_id),\n                  updated_at = NOW()\n                WHERE id = $7`,\n                [\n                  firebaseUser.uid,\n                  firebaseUser.displayName ||\n                    existingUser.name ||\n                    normalizedEmail.split(\"@\")[0] ||\n                    \"User\",\n                  firebaseUser.photoURL ||\n                    existingUser.avatar_url ||\n                    \"https://i.pravatar.cc/150?img=1\",\n                  firebaseUser.emailVerified || false,\n                  lastSignInTime,\n                  googleId,\n                  existingUser.id,\n                ],\n              );\n              updated++;\n              this.logger.log(\n                `🔄 Updated user: ${normalizedEmail} (${firebaseUser.uid})`,\n              );\n            } catch (updateError: any) {\n              // If google_id column doesn't exist, try without it\n              if (\n                updateError.message &&\n                updateError.message.includes(\"google_id\")\n              ) {\n                await client.query(\n                  `UPDATE user_profiles SET\n                    firebase_uid = COALESCE($1, firebase_uid),\n                    name = COALESCE($2, name),\n                    avatar_url = COALESCE($3, avatar_url),\n                    email_verified = COALESCE($4, email_verified),\n                    last_active = GREATEST(COALESCE($5, last_active), last_active),\n                    updated_at = NOW()\n                  WHERE id = $6`,\n                  [\n                    firebaseUser.uid,\n                    firebaseUser.displayName ||\n                      existingUser.name ||\n                      normalizedEmail.split(\"@\")[0] ||\n                      \"User\",\n                    firebaseUser.photoURL ||\n                      existingUser.avatar_url ||\n                      \"https://i.pravatar.cc/150?img=1\",\n                    firebaseUser.emailVerified || false,\n                    lastSignInTime,\n                    existingUser.id,\n                  ],\n                );\n                updated++;\n                this.logger.log(\n                  `🔄 Updated user: ${normalizedEmail} (${firebaseUser.uid})`,\n                );\n              } else {\n                throw updateError;\n              }\n            }\n          } else {\n            // Create new user\n            try {\n              await client.query(\n                `INSERT INTO user_profiles (\n                  firebase_uid, email, name, avatar_url, bio,\n                  karma_points, join_date, is_active, last_active,\n                  city, country, interests, roles, email_verified, settings, google_id\n                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb, $16)\n                RETURNING id`,\n                [\n                  firebaseUser.uid,\n                  normalizedEmail,\n                  firebaseUser.displayName ||\n                    normalizedEmail.split(\"@\")[0] ||\n                    \"User\",\n                  firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\",\n                  \"משתמש חדש בקארמה קומיוניטי\",\n                  0,\n                  creationTime,\n                  true,\n                  lastSignInTime,\n                  \"ישראל\",\n                  \"Israel\",\n                  [],\n                  [\"user\"],\n                  firebaseUser.emailVerified || false,\n                  JSON.stringify({\n                    language: \"he\",\n                    dark_mode: false,\n                    notifications_enabled: true,\n                    privacy: \"public\",\n                  }),\n                  googleId,\n                ],\n              );\n              created++;\n              this.logger.log(\n                `✨ Created user: ${normalizedEmail} (${firebaseUser.uid})`,\n              );\n            } catch (insertError: any) {\n              // If google_id column doesn't exist, try without it\n              if (\n                insertError.message &&\n                insertError.message.includes(\"google_id\")\n              ) {\n                await client.query(\n                  `INSERT INTO user_profiles (\n                    firebase_uid, email, name, avatar_url, bio,\n                    karma_points, join_date, is_active, last_active,\n                    city, country, interests, roles, email_verified, settings\n                  ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb)\n                  RETURNING id`,\n                  [\n                    firebaseUser.uid,\n                    normalizedEmail,\n                    firebaseUser.displayName ||\n                      normalizedEmail.split(\"@\")[0] ||\n                      \"User\",\n                    firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\",\n                    \"משתמש חדש בקארמה קומיוניטי\",\n                    0,\n                    creationTime,\n                    true,\n                    lastSignInTime,\n                    \"ישראל\",\n                    \"Israel\",\n                    [],\n                    [\"user\"],\n                    firebaseUser.emailVerified || false,\n                    JSON.stringify({\n                      language: \"he\",\n                      dark_mode: false,\n                      notifications_enabled: true,\n                      privacy: \"public\",\n                    }),\n                  ],\n                );\n                created++;\n                this.logger.log(\n                  `✨ Created user: ${normalizedEmail} (${firebaseUser.uid})`,\n                );\n              } else {\n                throw insertError;\n              }\n            }\n          }\n        } catch (error: any) {\n          this.logger.error(\n            `❌ Error processing user ${firebaseUser.uid}:`,\n            error,\n          );\n          errors++;\n        }\n      }\n\n      await client.query(\"COMMIT\");\n\n      const summary = {\n        success: true,\n        firebase_users: allUsers.length,\n        created,\n        updated,\n        skipped,\n        errors,\n        total_processed: created + updated + skipped,\n      };\n\n      this.logger.log(\"\\n📊 Sync Summary:\");\n      this.logger.log(`   ✅ Created: ${created}`);\n      this.logger.log(`   🔄 Updated: ${updated}`);\n      this.logger.log(`   ⏭️  Skipped: ${skipped}`);\n      this.logger.log(`   ❌ Errors: ${errors}`);\n      this.logger.log(`   📈 Total processed: ${created + updated + skipped}`);\n      this.logger.log(\"\\n✅ Firebase users sync completed!\");\n\n      return summary;\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"❌ Full sync error:\", error);\n      return {\n        success: false,\n        error: error.message || \"Failed to sync all users\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get sync status - check how many users are in Firebase vs user_profiles\n   * Useful for monitoring sync health\n   */\n  @Get(\"status\")\n  @UseGuards(AdminAuthGuard)\n  async getSyncStatus() {\n    try {\n      // Count users in Firebase\n      let firebaseCount = 0;\n      try {\n        let nextPageToken: string | undefined;\n        do {\n          const listUsersResult = await admin\n            .auth()\n            .listUsers(1000, nextPageToken);\n          firebaseCount += listUsersResult.users.length;\n          nextPageToken = listUsersResult.pageToken;\n        } while (nextPageToken);\n      } catch (error) {\n        this.logger.warn(\"⚠️ Could not count Firebase users:\", error);\n      }\n\n      // Count users in user_profiles\n      const { rows: dbCountResult } = await this.pool.query(\n        `SELECT COUNT(*) as count FROM user_profiles WHERE email IS NOT NULL AND email <> ''`,\n      );\n      const dbCount = parseInt(dbCountResult[0]?.count || \"0\");\n\n      // Count users with firebase_uid\n      const { rows: firebaseLinkedResult } = await this.pool.query(\n        `SELECT COUNT(*) as count FROM user_profiles WHERE firebase_uid IS NOT NULL`,\n      );\n      const firebaseLinked = parseInt(firebaseLinkedResult[0]?.count || \"0\");\n\n      return {\n        success: true,\n        firebase_users: firebaseCount,\n        user_profiles_total: dbCount,\n        user_profiles_with_firebase_uid: firebaseLinked,\n        missing_sync: Math.max(0, firebaseCount - firebaseLinked),\n      };\n    } catch (error: any) {\n      this.logger.error(\"❌ Get sync status error:\", error);\n      return {\n        success: false,\n        error: error.message || \"Failed to get sync status\",\n      };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/tasks.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":381,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":381,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13366,13369],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13366,13369],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":737,"column":34,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":737,"endColumn":37,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[26176,26179],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[26176,26179],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1124,"column":65,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1124,"endColumn":68,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[39441,39444],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[39441,39444],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1210,"column":59,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1210,"endColumn":62,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[42126,42129],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[42126,42129],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1317,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1317,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[45495,45498],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[45495,45498],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1326,"column":15,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1326,"endColumn":18,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[45866,45869],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[45866,45869],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1835,"column":65,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1835,"endColumn":68,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[62888,62891],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[62888,62891],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1913,"column":48,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1913,"endColumn":51,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[65123,65126],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[65123,65126],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1918,"column":52,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1918,"endColumn":55,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[65315,65318],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[65315,65318],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1922,"column":48,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1922,"endColumn":51,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[65463,65466],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[65463,65466],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":10,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: CRUD עבור משימות קבוצתיות למנהל האפליקציה\n// - Routes: /api/tasks (GET, POST), /api/tasks/:id (GET, PATCH, DELETE)\n// - Storage: PostgreSQL טבלת tasks (schema.sql)\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Patch,\n  Post,\n  Query,\n  UseGuards,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { UserResolutionService } from \"../services/user-resolution.service\";\nimport { ItemsService } from \"../items/items.service\";\nimport { JwtAuthGuard, AdminAuthGuard } from \"../auth/jwt-auth.guard\";\nimport { randomUUID } from \"crypto\";\n\ntype TaskStatus =\n  | \"open\"\n  | \"in_progress\"\n  | \"done\"\n  | \"archived\"\n  | \"stuck\"\n  | \"testing\"\n  | \"reports\";\ntype TaskPriority = \"low\" | \"medium\" | \"high\";\n\n@Controller(\"/api/tasks\")\nexport class TasksController {\n  private readonly logger = new Logger(TasksController.name);\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n    private readonly userResolutionService: UserResolutionService,\n    private readonly itemsService: ItemsService,\n  ) {}\n\n  /**\n   * Resolve any user identifier (email, firebase_uid, google_id, UUID string) to UUID\n   * Now delegates to UserResolutionService for consistency\n   */\n  private async resolveUserIdToUUID(userId: string): Promise<string | null> {\n    return this.userResolutionService.resolveUserId(userId, {\n      throwOnNotFound: false,\n      cacheResult: true,\n      logError: false,\n    });\n  }\n\n  /**\n   * Ensure posts table exists with correct schema, create/migrate if needed\n   * This is a fallback in case schema.sql wasn't run or table has legacy structure\n   */\n  private async ensurePostsTable() {\n    try {\n      // Check if posts table exists and has correct structure\n      const tableCheck = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT 1 FROM information_schema.tables \n          WHERE table_name = 'posts'\n        ) AS exists;\n      `);\n\n      if (tableCheck.rows[0]?.exists) {\n        // Check if it has the correct structure (author_id column)\n        const columnCheck = await this.pool.query(`\n          SELECT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name = 'posts' AND column_name = 'author_id'\n          ) AS exists;\n        `);\n\n        if (!columnCheck.rows[0]?.exists) {\n          // Legacy table exists with wrong structure - drop and recreate\n          this.logger.log(\n            \"⚠️  Detected legacy posts table structure - recreating with correct schema\",\n          );\n          await this.pool.query(\"DROP TABLE IF EXISTS posts CASCADE;\");\n        } else {\n          // Table exists with correct structure\n          return;\n        }\n      }\n\n      // Create posts table with correct schema\n      await this.pool.query(`\n        CREATE TABLE IF NOT EXISTS posts (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          author_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n          task_id UUID REFERENCES tasks(id) ON DELETE SET NULL,\n          title VARCHAR(255) NOT NULL,\n          description TEXT,\n          images TEXT[],\n          likes INTEGER DEFAULT 0,\n          comments INTEGER DEFAULT 0,\n          post_type VARCHAR(50) DEFAULT 'task_completion',\n          metadata JSONB DEFAULT '{}'::jsonb,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        )\n      `);\n\n      // SEC-002.4: Create indexes individually — no string interpolation in SQL\n      const indexQueries = [\n        \"CREATE INDEX IF NOT EXISTS idx_posts_author_id ON posts(author_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_task_id ON posts(task_id)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_created_at ON posts(created_at DESC)\",\n        \"CREATE INDEX IF NOT EXISTS idx_posts_post_type ON posts(post_type)\",\n      ];\n\n      for (const q of indexQueries) {\n        try {\n          await this.pool.query(q);\n        } catch {\n          // index may already exist\n        }\n      }\n\n      // Create trigger for updated_at\n      try {\n        await this.pool.query(`\n          DROP TRIGGER IF EXISTS update_posts_updated_at ON posts;\n          CREATE TRIGGER update_posts_updated_at \n            BEFORE UPDATE ON posts \n            FOR EACH ROW \n            EXECUTE FUNCTION update_updated_at_column();\n        `);\n      } catch {\n        this.logger.log(\n          \"⚠️ Could not create update_posts_updated_at trigger (function might not exist)\",\n        );\n      }\n\n      this.logger.log(\"✅ Posts table ensured with correct schema\");\n    } catch (error) {\n      this.logger.error(\"❌ Failed to ensure posts table:\", error);\n      // Don't throw - allow code to continue, but log the error\n    }\n  }\n\n  /**\n   * Ensure tasks table exists, create it if missing\n   * This is a fallback in case schema.sql wasn't run\n   */\n  private async ensureTasksTable() {\n    try {\n      // 1. Ensure TASKS table exists (Idempotent)\n      await this.pool.query(`\n        CREATE TABLE IF NOT EXISTS tasks (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          title VARCHAR(255) NOT NULL,\n          description TEXT,\n          status VARCHAR(20) NOT NULL DEFAULT 'open',\n          priority VARCHAR(10) NOT NULL DEFAULT 'medium',\n          category VARCHAR(50),\n          due_date TIMESTAMPTZ,\n          assignees UUID[] DEFAULT ARRAY[]::UUID[],\n          tags TEXT[] DEFAULT ARRAY[]::TEXT[],\n          checklist JSONB,\n          created_by UUID, -- REFERENCES user_profiles(id)\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        )\n      `);\n\n      // 2. Ensure estimated_hours column exists (for existing tables)\n      try {\n        await this.pool.query(`\n          DO $$\n          BEGIN\n            IF NOT EXISTS (\n              SELECT 1 FROM information_schema.columns \n              WHERE table_name = 'tasks' AND column_name = 'estimated_hours'\n            ) THEN\n              ALTER TABLE tasks ADD COLUMN estimated_hours NUMERIC(10,2);\n              -- Set default value of 0 for existing tasks\n              UPDATE tasks SET estimated_hours = 0 WHERE estimated_hours IS NULL;\n            END IF;\n          END $$;\n        `);\n      } catch (e) {\n        this.logger.warn(\"⚠️ Could not ensure estimated_hours column:\", e);\n      }\n\n      // 3. Ensure INDEXES (Idempotent)\n      // SEC-002.4: Create indexes individually — no string interpolation in SQL\n      const indexQueries = [\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks (status)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_priority ON tasks (priority)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_category ON tasks (category)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_due_date ON tasks (due_date)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_created_at ON tasks (created_at)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_assignees_gin ON tasks USING GIN (assignees)\",\n        \"CREATE INDEX IF NOT EXISTS idx_tasks_tags_gin ON tasks USING GIN (tags)\",\n      ];\n      for (const q of indexQueries) {\n        try {\n          await this.pool.query(q);\n        } catch {\n          /* ignore */\n        }\n      }\n\n      // 4. Ensure task_time_logs table exists\n      try {\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS task_time_logs (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,\n            user_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n            actual_hours NUMERIC(10,2) NOT NULL CHECK (actual_hours > 0),\n            logged_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            UNIQUE(task_id, user_id)\n          )\n        `);\n\n        // Create indexes for task_time_logs\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_task_time_logs_task_id ON task_time_logs(task_id)`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_task_time_logs_user_id ON task_time_logs(user_id)`,\n        );\n        await this.pool.query(\n          `CREATE INDEX IF NOT EXISTS idx_task_time_logs_logged_at ON task_time_logs(logged_at DESC)`,\n        );\n      } catch (e) {\n        this.logger.warn(\"⚠️ Could not ensure task_time_logs table:\", e);\n      }\n\n      // 5. Ensure NOTIFICATIONS table (Idempotent)\n      await this.pool.query(`\n        CREATE TABLE IF NOT EXISTS notifications (\n            user_id TEXT NOT NULL,\n            item_id TEXT NOT NULL,\n            data JSONB NOT NULL,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW(),\n            PRIMARY KEY (user_id, item_id)\n        );\n      `);\n    } catch (error) {\n      this.logger.error(\"❌ Error ensuring tables (non-fatal):\", error);\n      // Do not throw. If standard tables exist, we can proceed.\n    }\n  }\n\n  /**\n   * Get the root admin user ID from ROOT_ADMIN_EMAIL env var\n   * SEC-003.1: No hardcoded emails — uses env var\n   */\n  private async getSuperAdminId(): Promise<string | null> {\n    try {\n      const rootEmail = process.env.ROOT_ADMIN_EMAIL;\n      if (!rootEmail) {\n        this.logger.warn(\n          \"⚠️ ROOT_ADMIN_EMAIL not set — cannot resolve super admin\",\n        );\n        return null;\n      }\n      const { rows } = await this.pool.query(\n        `SELECT id FROM user_profiles WHERE email = $1 LIMIT 1`,\n        [rootEmail],\n      );\n      return rows[0]?.id || null;\n    } catch (error) {\n      this.logger.error(\"❌ Error getting super admin ID:\", error);\n      return null;\n    }\n  }\n\n  /**\n   * Check if a manager can assign tasks to a specific user\n   * Super admin can assign to anyone\n   * Other managers can only assign to their direct/indirect subordinates\n   */\n  private async canAssignToUser(\n    managerId: string,\n    targetUserId: string,\n  ): Promise<boolean> {\n    try {\n      // If assigning to self, always allowed\n      if (managerId === targetUserId) {\n        return true;\n      }\n\n      // SEC-003.1: Check if manager is super_admin by role, not by email\n      const { rows: superCheck } = await this.pool.query(\n        `SELECT 1 FROM user_profiles WHERE id = $1 AND 'super_admin' = ANY(roles)`,\n        [managerId],\n      );\n      if (superCheck.length > 0) {\n        return true;\n      }\n\n      // Check if targetUser is in manager's hierarchy (recursive - all levels down)\n      const { rows } = await this.pool.query(\n        `\n        WITH RECURSIVE subordinates AS (\n          -- Base case: direct subordinates of manager\n          SELECT id, 1 as depth FROM user_profiles WHERE parent_manager_id = $1\n          UNION ALL\n          -- Recursive: subordinates of subordinates\n          SELECT u.id, s.depth + 1\n          FROM user_profiles u\n          INNER JOIN subordinates s ON u.parent_manager_id = s.id\n          WHERE s.depth < 100\n        )\n        SELECT 1 FROM subordinates WHERE id = $2 LIMIT 1\n      `,\n        [managerId, targetUserId],\n      );\n\n      const canAssign = rows.length > 0;\n      this.logger.log(\n        `🔐 Manager ${managerId} ${canAssign ? \"CAN\" : \"CANNOT\"} assign to ${targetUserId}`,\n      );\n      return canAssign;\n    } catch (error) {\n      this.logger.error(\"❌ Error checking hierarchy permissions:\", error);\n      // On error, deny assignment to be safe\n      return false;\n    }\n  }\n\n  /**\n   * List tasks with filtering and pagination\n   * Cache TTL: 10 minutes (tasks change moderately frequently)\n   */\n  @Get()\n  @UseGuards(JwtAuthGuard)\n  async listTasks(\n    @Query(\"status\") status?: TaskStatus,\n    @Query(\"priority\") priority?: TaskPriority,\n    @Query(\"category\") category?: string,\n    @Query(\"assignee\") assignee?: string,\n    @Query(\"q\") searchQuery?: string,\n    @Query(\"limit\") limitParam?: string,\n    @Query(\"offset\") offsetParam?: string,\n  ) {\n    try {\n      // Ensure table exists before querying\n      await this.ensureTasksTable();\n\n      // Parse limit and offset - handle 0 correctly\n      const limitNum = limitParam ? parseInt(String(limitParam), 10) : 100;\n      const offsetNum = offsetParam ? parseInt(String(offsetParam), 10) : 0;\n      const limit = Math.min(\n        Math.max(isNaN(limitNum) ? 100 : limitNum, 1),\n        500,\n      );\n      const offset = Math.max(isNaN(offsetNum) ? 0 : offsetNum, 0);\n\n      // Build cache key from query parameters (include search query if present)\n      const cacheKey = `tasks_list_${status || \"all\"}_${priority || \"all\"}_${category || \"all\"}_${assignee || \"all\"}_${searchQuery || \"all\"}_${limit}_${offset}`;\n\n      // Cache restored - race condition was fixed by awaiting cache clearing in create/update/delete\n      // Try to get from cache (but don't fail if Redis is unavailable)\n      let cached = null;\n      try {\n        cached = await this.redisCache.get(cacheKey);\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache error (non-fatal):\", cacheError);\n      }\n\n      if (cached) {\n        this.logger.log(\"✅ Returning cached tasks list\");\n        return { success: true, data: cached };\n      }\n\n      const filters: string[] = [];\n      const params: any[] = [];\n\n      if (status) {\n        params.push(status);\n        filters.push(`status = $${params.length}`);\n      }\n\n      if (priority) {\n        params.push(priority);\n        filters.push(`priority = $${params.length}`);\n      }\n\n      if (category) {\n        params.push(category);\n        filters.push(`category = $${params.length}`);\n      }\n\n      if (assignee) {\n        // Assume assignee is UUID for now. If email, we'd need to resolve it.\n        // Ideally we resolve it to be safe.\n        // But for performance, let's assume UUID if it looks like one.\n        const uuidRegex =\n          /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n        let assigneeUuid = assignee;\n\n        if (!uuidRegex.test(assignee)) {\n          // Try to resolve if not UUID (e.g. email)\n          const resolved = await this.resolveUserIdToUUID(assignee);\n          if (resolved) {\n            this.logger.log(\n              `👤 Resolved list filter assignee ${assignee} -> ${resolved}`,\n            );\n            assigneeUuid = resolved;\n          } else {\n            this.logger.warn(\n              `⚠️ Could not resolve list filter assignee: ${assignee}`,\n            );\n          }\n        }\n\n        params.push(assigneeUuid);\n        // \"assigneeUuid = ANY(assignees)\" checks if uuid is in the array\n        // Cast both sides to UUID to ensure type compatibility\n        filters.push(`$${params.length}::UUID = ANY(assignees::UUID[])`);\n      }\n\n      // Add text search if query parameter is provided\n      if (searchQuery && searchQuery.trim()) {\n        const searchTerm = `%${searchQuery.trim()}%`;\n        params.push(searchTerm);\n        const searchParamIndex = params.length;\n        filters.push(\n          `(title ILIKE $${searchParamIndex} OR description ILIKE $${searchParamIndex})`,\n        );\n      }\n\n      const where = filters.length ? `WHERE ${filters.join(\" AND \")}` : \"\";\n\n      // Check if task_time_logs table exists\n      const tableExists = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'task_time_logs'\n        )\n      `);\n      const hasTimeLogs = tableExists.rows[0].exists;\n\n      const actualHoursSubquery = hasTimeLogs\n        ? `COALESCE((SELECT SUM(actual_hours)::NUMERIC FROM task_time_logs WHERE task_id = t.id), 0) as actual_hours`\n        : `0::NUMERIC as actual_hours`;\n\n      const sql = `\n        SELECT \n            t.id, t.title, t.description, t.status, t.priority, t.category, t.due_date, t.assignees, t.tags, t.checklist, t.parent_task_id, t.estimated_hours, t.created_at, t.updated_at,\n            (SELECT json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url) \n             FROM user_profiles u \n             WHERE u.id::text = t.created_by::text \n                OR u.firebase_uid = t.created_by::text\n                OR u.google_id = t.created_by::text\n             LIMIT 1) as creator_details,\n            (SELECT json_agg(json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url)) \n             FROM user_profiles u WHERE u.id = ANY(t.assignees::UUID[])) as assignees_details,\n            (SELECT COUNT(*) FROM tasks st WHERE st.parent_task_id = t.id) as subtask_count,\n            (SELECT json_build_object('id', pt.id, 'title', pt.title) \n             FROM tasks pt WHERE pt.id = t.parent_task_id) as parent_task_details,\n            ${actualHoursSubquery}\n        FROM tasks t\n        ${where}\n        ORDER BY \n          CASE priority WHEN 'high' THEN 0 WHEN 'medium' THEN 1 ELSE 2 END ASC,\n          status ASC,\n          created_at DESC\n        LIMIT $${params.length + 1}\n        OFFSET $${params.length + 2}\n      `;\n      params.push(limit, offset);\n\n      this.logger.log(\n        `🚀 Executing LIST SQL:`,\n        sql.replace(/\\s+/g, \" \").trim(),\n      );\n      this.logger.log(`params:`, params);\n\n      const { rows } = await this.pool.query(sql, params);\n      this.logger.log(`✅ Found ${rows.length} tasks`);\n\n      // Try to cache the result (but don't fail if Redis is unavailable)\n      try {\n        await this.redisCache.set(cacheKey, rows, 10 * 60);\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache set error (non-fatal):\", cacheError);\n      }\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error listing tasks:\", error);\n\n      // Check if error is about missing table/columns\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      if (\n        errorMessage.includes(\"does not exist\") ||\n        errorMessage.includes(\"column\")\n      ) {\n        return {\n          success: false,\n          error:\n            \"Database table structure issue. Please contact administrator or check server logs.\",\n        };\n      }\n\n      return {\n        success: false,\n        error: errorMessage || \"Failed to list tasks\",\n      };\n    }\n  }\n\n  /**\n   * Manual endpoint to create tasks table\n   * Useful for production when automatic creation fails\n   * GET /api/tasks/init-table\n   */\n  @Get(\"init-table\")\n  @UseGuards(AdminAuthGuard)\n  async initTasksTable() {\n    try {\n      await this.ensureTasksTable();\n      return {\n        success: true,\n        message: \"Tasks table initialized successfully\",\n      };\n    } catch (error) {\n      this.logger.error(\"Failed to initialize tasks table:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error\n            ? error.message\n            : \"Failed to initialize tasks table\",\n      };\n    }\n  }\n\n  /**\n   * Get a single task by ID\n   * Cache TTL: 15 minutes\n   */\n  @Get(\":id\")\n  @UseGuards(JwtAuthGuard)\n  async getTask(@Param(\"id\") id: string) {\n    try {\n      // Ensure table exists before querying\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(id)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      const cacheKey = `task_${id}`;\n\n      // Try to get from cache (but don't fail if Redis is unavailable)\n      let cached = null;\n      try {\n        cached = await this.redisCache.get(cacheKey);\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache error (non-fatal):\", cacheError);\n      }\n\n      if (cached) {\n        return { success: true, data: cached };\n      }\n\n      const { rows } = await this.pool.query(\n        `SELECT \n            t.id, t.title, t.description, t.status, t.priority, t.category, t.due_date, t.assignees, t.tags, t.checklist, t.created_by, t.parent_task_id, t.estimated_hours, t.created_at, t.updated_at,\n            (SELECT json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url) \n             FROM user_profiles u \n             WHERE u.id::text = t.created_by::text \n                OR u.firebase_uid = t.created_by::text\n                OR u.google_id = t.created_by::text\n             LIMIT 1) as creator_details,\n            (SELECT json_agg(json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url)) \n             FROM user_profiles u WHERE u.id = ANY(t.assignees::UUID[])) as assignees_details,\n            COALESCE((SELECT SUM(actual_hours)::NUMERIC FROM task_time_logs WHERE task_id = t.id), 0) as actual_hours\n         FROM tasks t WHERE t.id = $1`,\n        [id],\n      );\n      if (!rows.length) {\n        return { success: false, error: \"Task not found\" };\n      }\n\n      // Try to cache the result (but don't fail if Redis is unavailable)\n      try {\n        await this.redisCache.set(cacheKey, rows[0], 15 * 60);\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache set error (non-fatal):\", cacheError);\n      }\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error getting task:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to get task\",\n      };\n    }\n  }\n\n  /**\n   * Get subtasks of a specific task\n   * GET /api/tasks/:id/subtasks\n   */\n  @Get(\":id/subtasks\")\n  @UseGuards(JwtAuthGuard)\n  async getSubtasks(@Param(\"id\") parentId: string) {\n    try {\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(parentId)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      const { rows } = await this.pool.query(\n        `\n        SELECT \n          t.id, t.title, t.description, t.status, t.priority, t.category, \n          t.due_date, t.assignees, t.tags, t.checklist, t.parent_task_id, t.estimated_hours,\n          t.created_at, t.updated_at,\n          (SELECT json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url) \n           FROM user_profiles u WHERE u.id = CAST(t.created_by AS UUID)) as creator_details,\n          (SELECT json_agg(json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url)) \n           FROM user_profiles u WHERE u.id = ANY(t.assignees::UUID[])) as assignees_details,\n          (SELECT COUNT(*) FROM tasks st WHERE st.parent_task_id = t.id) as subtask_count,\n          COALESCE((SELECT SUM(actual_hours)::NUMERIC FROM task_time_logs WHERE task_id = t.id), 0) as actual_hours\n        FROM tasks t\n        WHERE t.parent_task_id = $1\n        ORDER BY \n          CASE priority WHEN 'high' THEN 0 WHEN 'medium' THEN 1 ELSE 2 END ASC,\n          created_at DESC\n      `,\n        [parentId],\n      );\n\n      this.logger.log(`📋 Found ${rows.length} subtasks for task ${parentId}`);\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error getting subtasks:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to get subtasks\",\n      };\n    }\n  }\n\n  /**\n   * Get full task tree (recursive - all subtasks at all levels)\n   * GET /api/tasks/:id/tree\n   */\n  @Get(\":id/tree\")\n  @UseGuards(JwtAuthGuard)\n  async getTaskTree(@Param(\"id\") rootId: string) {\n    try {\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(rootId)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      // Use recursive CTE to get all subtasks at all levels\n      const { rows } = await this.pool.query(\n        `\n        WITH RECURSIVE task_tree AS (\n          -- Base case: the root task\n          SELECT \n            t.id, t.title, t.description, t.status, t.priority, t.category, \n            t.due_date, t.assignees, t.tags, t.checklist, t.parent_task_id, \n            t.estimated_hours, t.created_by, t.created_at, t.updated_at,\n            0 as level,\n            ARRAY[t.id] as path\n          FROM tasks t\n          WHERE t.id = $1\n          \n          UNION ALL\n          \n          -- Recursive: get children\n          SELECT \n            t.id, t.title, t.description, t.status, t.priority, t.category, \n            t.due_date, t.assignees, t.tags, t.checklist, t.parent_task_id, \n            t.estimated_hours, t.created_by, t.created_at, t.updated_at,\n            tt.level + 1,\n            tt.path || t.id\n          FROM tasks t\n          INNER JOIN task_tree tt ON t.parent_task_id = tt.id\n          WHERE tt.level < 10  -- Max depth to prevent infinite loops\n        )\n        SELECT \n          tt.*,\n          (SELECT json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url) \n           FROM user_profiles u WHERE u.id = CAST(tt.created_by AS UUID)) as creator_details,\n          (SELECT json_agg(json_build_object('id', u.id, 'name', u.name, 'email', u.email, 'avatar_url', u.avatar_url)) \n           FROM user_profiles u WHERE u.id = ANY(tt.assignees::UUID[])) as assignees_details,\n          (SELECT COUNT(*) FROM tasks st WHERE st.parent_task_id = tt.id) as subtask_count\n        FROM task_tree tt\n        ORDER BY tt.path\n      `,\n        [rootId],\n      );\n\n      this.logger.log(\n        `🌳 Found ${rows.length} tasks in tree for root ${rootId}`,\n      );\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Error getting task tree:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to get task tree\",\n      };\n    }\n  }\n\n  @Post()\n  @UseGuards(JwtAuthGuard, AdminAuthGuard)\n  async createTask(@Body() body: any) {\n    try {\n      // Ensure table exists before inserting\n      await this.ensureTasksTable();\n\n      const {\n        title,\n        description = null,\n        status = \"open\",\n        priority = \"medium\",\n        category = null,\n        due_date = null,\n        assignees = [],\n        assigneesEmails = [],\n        tags = [],\n        checklist = null,\n        created_by = null,\n        parent_task_id = null,\n        estimated_hours = null,\n      } = body || {};\n\n      if (!title || typeof title !== \"string\" || !title.trim()) {\n        return {\n          success: false,\n          error: \"title is required and cannot be empty\",\n        };\n      }\n\n      // Validate status\n      // Validate status\n      if (\n        status &&\n        ![\n          \"open\",\n          \"in_progress\",\n          \"done\",\n          \"archived\",\n          \"stuck\",\n          \"testing\",\n          \"reports\",\n        ].includes(status)\n      ) {\n        return { success: false, error: \"Invalid status value\" };\n      }\n\n      // Validate priority\n      if (priority && ![\"low\", \"medium\", \"high\"].includes(priority)) {\n        return { success: false, error: \"Invalid priority value\" };\n      }\n\n      this.logger.log(`📝 POST /api/tasks payload:`, JSON.stringify(body));\n\n      // Resolve created_by to UUID - REQUIRED field\n      let createdByUuid: string | null = null;\n      if (created_by) {\n        const resolutionStart = Date.now();\n        createdByUuid = await this.resolveUserIdToUUID(created_by);\n        this.logger.log(\n          `👤 Resolved created_by ${created_by} to ${createdByUuid} in ${Date.now() - resolutionStart}ms`,\n        );\n        if (!createdByUuid) {\n          return {\n            success: false,\n            error: \"Could not resolve created_by user - invalid user ID\",\n          };\n        }\n      } else {\n        this.logger.log(\n          `❌ No created_by provided in payload - this is required`,\n        );\n        return {\n          success: false,\n          error: \"created_by is required - every task must have a creator\",\n        };\n      }\n\n      this.logger.log(`👤 Final createdByUuid:`, createdByUuid);\n\n      // Validate and parse due_date if provided\n      let parsedDueDate = null;\n      if (due_date) {\n        if (typeof due_date === \"string\") {\n          const date = new Date(due_date);\n          if (isNaN(date.getTime())) {\n            return { success: false, error: \"Invalid due_date format\" };\n          }\n          parsedDueDate = date.toISOString();\n        } else {\n          parsedDueDate = due_date;\n        }\n      }\n\n      // Convert emails to UUIDs if assigneesEmails is provided\n      let assigneeUUIDs: string[] = [];\n\n      // If assigneesEmails is provided (array of emails), convert to UUIDs\n      if (Array.isArray(assigneesEmails) && assigneesEmails.length > 0) {\n        this.logger.log(\n          \"📧 Processing assigneesEmails (POST):\",\n          assigneesEmails,\n        );\n        const emailList = assigneesEmails.filter(\n          (e) => typeof e === \"string\" && e.trim(),\n        );\n        if (emailList.length > 0) {\n          const emailQuery = `\n            SELECT id FROM user_profiles \n            WHERE email = ANY($1::TEXT[])\n          `;\n          const { rows: userRows } = await this.pool.query(emailQuery, [\n            emailList,\n          ]);\n          assigneeUUIDs = userRows.map((row) => row.id);\n          this.logger.log(\"📧 Resolved emails to UUIDs:\", assigneeUUIDs);\n        }\n      }\n      // Otherwise, use assignees if provided (should be UUIDs)\n      else if (Array.isArray(assignees) && assignees.length > 0) {\n        this.logger.log(\"👥 Processing assignees (POST):\", assignees);\n        assigneeUUIDs = assignees;\n      }\n\n      // DEFAULT ASSIGNEES: If no assignees provided, assign to creator + super admin\n      if (assigneeUUIDs.length === 0) {\n        this.logger.log(\n          \"📋 No assignees provided - setting default (creator + super admin)\",\n        );\n\n        // Add creator as assignee\n        if (createdByUuid) {\n          assigneeUUIDs.push(createdByUuid);\n        }\n\n        // Add super admin if different from creator\n        const superAdminId = await this.getSuperAdminId();\n        if (superAdminId && superAdminId !== createdByUuid) {\n          assigneeUUIDs.push(superAdminId);\n        }\n\n        this.logger.log(\"📋 Default assignees set:\", assigneeUUIDs);\n      }\n\n      // HIERARCHY PERMISSION CHECK: Verify creator can assign to all assignees\n      for (const assigneeId of assigneeUUIDs) {\n        if (assigneeId !== createdByUuid) {\n          const canAssign = await this.canAssignToUser(\n            createdByUuid!,\n            assigneeId,\n          );\n          if (!canAssign) {\n            this.logger.log(\n              `❌ Permission denied: ${createdByUuid} cannot assign to ${assigneeId}`,\n            );\n            return {\n              success: false,\n              error:\n                \"אין לך הרשאה להקצות משימה למשתמש זה - ניתן להקצות רק לעובדים שלך\",\n            };\n          }\n        }\n      }\n      this.logger.log(\"✅ Hierarchy permission check passed for all assignees\");\n\n      // Validate estimated_hours if provided\n      let parsedEstimatedHours = null;\n      if (estimated_hours !== null && estimated_hours !== undefined) {\n        const hours = parseFloat(String(estimated_hours));\n        if (isNaN(hours) || hours < 0) {\n          return {\n            success: false,\n            error: \"estimated_hours must be a non-negative number\",\n          };\n        }\n        parsedEstimatedHours = hours;\n      }\n\n      const sql = `\n        INSERT INTO tasks (title, description, status, priority, category, due_date, assignees, tags, checklist, created_by, parent_task_id, estimated_hours)\n        VALUES ($1, $2, $3, $4, $5, $6, $7::UUID[], $8::TEXT[], $9::JSONB, $10::UUID, $11::UUID, $12::NUMERIC)\n        RETURNING id, title, description, status, priority, category, due_date, assignees, tags, checklist, created_by, parent_task_id, estimated_hours, created_at, updated_at\n      `;\n      const params = [\n        title.trim(),\n        description,\n        status,\n        priority,\n        category,\n        parsedDueDate,\n        assigneeUUIDs,\n        Array.isArray(tags) ? tags : [],\n        checklist,\n        createdByUuid,\n        parent_task_id || null,\n        parsedEstimatedHours,\n      ];\n\n      this.logger.log(\n        `🚀 Executing INSERT SQL with params:`,\n        JSON.stringify(params),\n      );\n\n      const { rows } = await this.pool.query(sql, params);\n      const newTask = rows[0];\n      this.logger.log(\"✅ Task inserted successfully:\", newTask.id);\n\n      // NOTIFICATION: Notify assignees\n      if (assigneeUUIDs.length > 0) {\n        const timestamp = new Date().toISOString();\n        this.logger.log(\n          `🔔 Preparing to notify ${assigneeUUIDs.length} assignees...`,\n        );\n\n        for (const assigneeId of assigneeUUIDs) {\n          try {\n            // Check if notifications table exists first (quick safeguard)\n            // Actually, just try to create and catch error\n\n            this.logger.log(\n              `🔔 Sending new task notification to ${assigneeId}`,\n            ); // Log BEFORE attempt\n\n            await this.itemsService.create(\n              \"notifications\",\n              assigneeId,\n              randomUUID(),\n              {\n                title: \"משימה חדשה\",\n                body: `הוקצתה לך משימה חדשה: ${newTask.title}`,\n                type: \"system\",\n                timestamp,\n                read: false,\n                userId: assigneeId,\n                data: { taskId: newTask.id },\n              },\n            );\n            this.logger.log(`✅ Notification sent to ${assigneeId}`);\n          } catch (itemError) {\n            this.logger.error(\n              `❌ Failed to create notification for ${assigneeId}. It is likely the 'notifications' table does not exist.`,\n              itemError,\n            );\n            // Verify table existence - if it fails here, we should probably auto-create it or warn loudly\n          }\n        }\n\n        // AUTO-POST: Create posts for task assignment\n        // Track post creation results for response\n        const postResults = { created: 0, failed: 0, errors: [] as string[] };\n\n        try {\n          // Ensure posts table exists before creating posts\n          await this.ensurePostsTable();\n\n          // Track who already got a post to avoid duplicates\n          const postCreatedFor = new Set<string>();\n\n          // 1. Create post for the CREATOR first (if they exist)\n          if (createdByUuid) {\n            try {\n              await this.pool.query(\n                `\n                INSERT INTO posts (author_id, task_id, title, description, post_type)\n                VALUES ($1, $2, $3, $4, 'task_assignment')\n              `,\n                [\n                  createdByUuid,\n                  newTask.id,\n                  `יצרת משימה חדשה: ${newTask.title}`,\n                  newTask.description\n                    ? `יצרת משימה חדשה: ${newTask.description}`\n                    : `יצרת משימה חדשה: ${newTask.title}`,\n                ],\n              );\n              postResults.created++;\n              postCreatedFor.add(createdByUuid);\n              this.logger.log(`✅ Post created for creator ${createdByUuid}`);\n            } catch (postError) {\n              postResults.failed++;\n              const errorMsg =\n                postError instanceof Error\n                  ? postError.message\n                  : \"Unknown error\";\n              postResults.errors.push(\n                `Failed for creator ${createdByUuid}: ${errorMsg}`,\n              );\n              this.logger.error(\n                `❌ Failed to create post for creator ${createdByUuid}:`,\n                postError,\n              );\n            }\n          }\n\n          // 2. Create posts for ASSIGNEES (skip if already got post as creator)\n          this.logger.log(\n            `📝 Creating posts for ${assigneeUUIDs.length} assignees...`,\n          );\n          for (const assigneeId of assigneeUUIDs) {\n            // Skip if this assignee already got a post (e.g., they are also the creator)\n            if (postCreatedFor.has(assigneeId)) {\n              this.logger.log(\n                `⏭️ Skipping post for ${assigneeId} - already created as creator`,\n              );\n              continue;\n            }\n\n            try {\n              await this.pool.query(\n                `\n                INSERT INTO posts (author_id, task_id, title, description, post_type)\n                VALUES ($1, $2, $3, $4, 'task_assignment')\n              `,\n                [\n                  assigneeId,\n                  newTask.id,\n                  `משימה חדשה: ${newTask.title}`,\n                  newTask.description\n                    ? `הוקצתה לך משימה חדשה: ${newTask.description}`\n                    : `הוקצתה לך משימה חדשה: ${newTask.title}`,\n                ],\n              );\n              postResults.created++;\n              postCreatedFor.add(assigneeId);\n              this.logger.log(`✅ Post created for assignee ${assigneeId}`);\n            } catch (postError) {\n              postResults.failed++;\n              const errorMsg =\n                postError instanceof Error\n                  ? postError.message\n                  : \"Unknown error\";\n              postResults.errors.push(`Failed for ${assigneeId}: ${errorMsg}`);\n              this.logger.error(\n                `❌ Failed to create post for assignee ${assigneeId}:`,\n                postError,\n              );\n            }\n          }\n\n          this.logger.log(\n            `📊 Post creation summary: ${postResults.created} created, ${postResults.failed} failed`,\n          );\n\n          // Clear posts cache after creating posts\n          if (postResults.created > 0) {\n            try {\n              await this.clearPostsCaches();\n              this.logger.log(\"✅ Posts caches cleared after post creation\");\n            } catch (cacheErr) {\n              this.logger.warn(\n                \"Error clearing posts caches after creation (non-fatal):\",\n                cacheErr,\n              );\n            }\n          }\n        } catch (tableError) {\n          this.logger.error(\"❌ Failed to ensure posts table:\", tableError);\n          postResults.errors.push(\"Posts table initialization failed\");\n        }\n      }\n\n      // Clear task list caches (blocking to prevent race condition)\n      try {\n        await this.clearTaskCaches();\n        this.logger.log(\"✅ Task caches cleared after creation\");\n      } catch (cacheErr) {\n        this.logger.warn(\n          \"Error clearing caches after task creation (non-fatal):\",\n          cacheErr,\n        );\n      }\n\n      return { success: true, data: newTask };\n    } catch (error) {\n      this.logger.error(\"Error creating task:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to create task\",\n      };\n    }\n  }\n\n  /**\n   * Log hours worked on a task\n   * POST /api/tasks/:id/log-hours\n   * Note: Must be before @Patch(':id') to ensure proper route matching\n   */\n  @Post(\":id/log-hours\")\n  @UseGuards(JwtAuthGuard)\n  async logTaskHours(@Param(\"id\") taskId: string, @Body() body: any) {\n    try {\n      // Ensure task_time_logs table exists\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(taskId)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      const { hours, user_id } = body || {};\n\n      if (!hours || typeof hours !== \"number\" || hours <= 0) {\n        return { success: false, error: \"hours must be a positive number\" };\n      }\n\n      if (!user_id) {\n        return { success: false, error: \"user_id is required\" };\n      }\n\n      // Resolve user_id to UUID\n      const userIdUuid = await this.resolveUserIdToUUID(user_id);\n      if (!userIdUuid) {\n        return { success: false, error: \"Invalid user_id\" };\n      }\n\n      // Verify task exists\n      const taskCheck = await this.pool.query(\n        \"SELECT id FROM tasks WHERE id = $1\",\n        [taskId],\n      );\n      if (!taskCheck.rows[0]) {\n        return { success: false, error: \"Task not found\" };\n      }\n\n      // Check if table exists before inserting\n      const tableExists = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'task_time_logs'\n        )\n      `);\n\n      if (!tableExists.rows[0].exists) {\n        return {\n          success: false,\n          error: \"Time logging is not available - table not initialized\",\n        };\n      }\n\n      // Insert or update time log (using ON CONFLICT for unique constraint)\n      const { rows } = await this.pool.query(\n        `\n        INSERT INTO task_time_logs (task_id, user_id, actual_hours, logged_at)\n        VALUES ($1, $2, $3::NUMERIC, NOW())\n        ON CONFLICT (task_id, user_id)\n        DO UPDATE SET actual_hours = EXCLUDED.actual_hours, logged_at = NOW()\n        RETURNING id, task_id, user_id, actual_hours, logged_at, created_at\n      `,\n        [taskId, userIdUuid, hours],\n      );\n\n      // Clear task cache\n      try {\n        await this.redisCache.delete(`task_${taskId}`);\n        await this.clearTaskCaches();\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache delete error (non-fatal):\", cacheError);\n      }\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error logging task hours:\", error);\n      return {\n        success: false,\n        error:\n          error instanceof Error ? error.message : \"Failed to log task hours\",\n      };\n    }\n  }\n\n  @Patch(\":id\")\n  @UseGuards(JwtAuthGuard, AdminAuthGuard)\n  async updateTask(@Param(\"id\") id: string, @Body() body: any) {\n    try {\n      // Ensure table exists before updating\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(id)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      // Fetch OLD task to compare assignees and check current status\n      const oldTaskRes = await this.pool.query(\n        \"SELECT assignees, status FROM tasks WHERE id = $1\",\n        [id],\n      );\n      if (!oldTaskRes.rows[0]) {\n        return { success: false, error: \"Task not found\" };\n      }\n      const oldAssignees: string[] = oldTaskRes.rows[0]?.assignees || [];\n      const oldStatus: string = oldTaskRes.rows[0]?.status || \"open\";\n\n      // Validate status if provided\n      if (\n        body.status &&\n        ![\n          \"open\",\n          \"in_progress\",\n          \"done\",\n          \"archived\",\n          \"stuck\",\n          \"testing\",\n        ].includes(body.status)\n      ) {\n        return { success: false, error: \"Invalid status value\" };\n      }\n\n      // Check if status is changing to 'done' - require time log (only if table exists)\n      if (body.status === \"done\" && oldStatus !== \"done\") {\n        const tableExists = await this.pool.query(`\n          SELECT EXISTS (\n            SELECT FROM information_schema.tables \n            WHERE table_schema = 'public' \n            AND table_name = 'task_time_logs'\n          )\n        `);\n\n        if (tableExists.rows[0].exists) {\n          // Check if there's a time log for this task\n          const timeLogCheck = await this.pool.query(\n            \"SELECT COUNT(*) as count FROM task_time_logs WHERE task_id = $1\",\n            [id],\n          );\n          const hasTimeLog =\n            parseInt(timeLogCheck.rows[0]?.count || \"0\", 10) > 0;\n          if (!hasTimeLog) {\n            return {\n              success: false,\n              error:\n                \"נדרש לרשום שעות עבודה לפני סימון המשימה כבוצעה. אנא מלא את שעות העבודה בפועל.\",\n              requiresHoursLog: true,\n            };\n          }\n        }\n        // If table doesn't exist, skip the time log requirement\n      }\n\n      // Validate priority if provided\n      if (body.priority && ![\"low\", \"medium\", \"high\"].includes(body.priority)) {\n        return { success: false, error: \"Invalid priority value\" };\n      }\n\n      // Validate and parse due_date if provided\n      let parsedDueDate = null;\n      if (body.due_date !== undefined && body.due_date !== null) {\n        if (typeof body.due_date === \"string\") {\n          const date = new Date(body.due_date);\n          if (isNaN(date.getTime())) {\n            return { success: false, error: \"Invalid due_date format\" };\n          }\n          parsedDueDate = date.toISOString();\n        } else {\n          parsedDueDate = body.due_date;\n        }\n      }\n\n      this.logger.log(\n        `📝 PATCH /api/tasks/${id} payload:`,\n        JSON.stringify(body),\n      );\n\n      // Build partial update dynamically\n      const allowed = [\n        \"title\",\n        \"description\",\n        \"status\",\n        \"priority\",\n        \"category\",\n        \"due_date\",\n        \"assignees\",\n        \"assigneesEmails\",\n        \"tags\",\n        \"checklist\",\n        \"estimated_hours\",\n      ] as const;\n      const sets: string[] = [];\n      const params: any[] = [];\n\n      // Handle assigneesEmails conversion to UUIDs if provided\n      let shouldUpdateAssignees = false;\n      let assigneeUUIDs: string[] = [];\n\n      if (\"assigneesEmails\" in body && Array.isArray(body.assigneesEmails)) {\n        this.logger.log(\"📧 Processing assigneesEmails update\");\n        const emailList = body.assigneesEmails.filter(\n          (e: any) => typeof e === \"string\" && e.trim(),\n        );\n        if (emailList.length > 0) {\n          const emailQuery = `\n            SELECT id FROM user_profiles \n            WHERE email = ANY($1::TEXT[])\n          `;\n          const { rows: userRows } = await this.pool.query(emailQuery, [\n            emailList,\n          ]);\n          assigneeUUIDs = userRows.map((row) => row.id);\n        }\n        shouldUpdateAssignees = true;\n      } else if (\"assignees\" in body) {\n        // Handle assignees update explicitly if key exists\n        this.logger.log(\"👥 Processing assignees update:\", body.assignees);\n        if (Array.isArray(body.assignees)) {\n          assigneeUUIDs = body.assignees;\n          shouldUpdateAssignees = true;\n        }\n      }\n\n      // Build SET clause\n      for (const key of allowed) {\n        if (key === \"assignees\" || key === \"assigneesEmails\") {\n          // Skip, handled above\n          continue;\n        }\n\n        if (key === \"due_date\") {\n          // Handle due_date separately with parsed value\n          if (body.due_date !== undefined) {\n            params.push(parsedDueDate);\n            sets.push(`due_date = $${params.length}`);\n          }\n          continue;\n        }\n\n        if (key === \"estimated_hours\") {\n          // Handle estimated_hours separately with validation\n          if (body.estimated_hours !== undefined) {\n            let parsedHours = null;\n            if (body.estimated_hours !== null) {\n              const hours = parseFloat(String(body.estimated_hours));\n              if (isNaN(hours) || hours < 0) {\n                return {\n                  success: false,\n                  error: \"estimated_hours must be a non-negative number\",\n                };\n              }\n              parsedHours = hours;\n            }\n            params.push(parsedHours);\n            sets.push(`estimated_hours = $${params.length}::NUMERIC`);\n          }\n          continue;\n        }\n\n        if (key in body) {\n          params.push(\n            key === \"tags\"\n              ? Array.isArray(body[key])\n                ? body[key]\n                : []\n              : body[key],\n          );\n          const idx = params.length;\n          if (key === \"tags\") {\n            sets.push(`tags = $${idx}::TEXT[]`);\n          } else if (key === \"checklist\") {\n            sets.push(`checklist = $${idx}::JSONB`);\n          } else {\n            sets.push(`${key} = $${idx}`);\n          }\n        }\n      }\n\n      if (shouldUpdateAssignees) {\n        this.logger.log(\"👥 Updating assignees to set:\", assigneeUUIDs);\n\n        // HIERARCHY PERMISSION CHECK: Get the task's created_by and verify permissions\n        const taskCreatorRes = await this.pool.query(\n          \"SELECT created_by FROM tasks WHERE id = $1\",\n          [id],\n        );\n        const taskCreatorId = taskCreatorRes.rows[0]?.created_by;\n\n        if (taskCreatorId) {\n          // Check permissions for new assignees only (not ones that were already there)\n          const safeOldAssignees = (oldAssignees || []).filter(Boolean);\n          const newlyAddedAssignees = assigneeUUIDs.filter(\n            (uid: string) => !safeOldAssignees.includes(uid),\n          );\n\n          for (const assigneeId of newlyAddedAssignees) {\n            if (assigneeId !== taskCreatorId) {\n              const canAssign = await this.canAssignToUser(\n                taskCreatorId,\n                assigneeId,\n              );\n              if (!canAssign) {\n                this.logger.log(\n                  `❌ Permission denied: ${taskCreatorId} cannot assign to ${assigneeId}`,\n                );\n                return {\n                  success: false,\n                  error:\n                    \"אין לך הרשאה להקצות משימה למשתמש זה - ניתן להקצות רק לעובדים שלך\",\n                };\n              }\n            }\n          }\n          this.logger.log(\n            \"✅ Hierarchy permission check passed for updated assignees\",\n          );\n        }\n\n        params.push(assigneeUUIDs);\n        sets.push(`assignees = $${params.length}::UUID[]`);\n      }\n\n      if (!sets.length) {\n        return { success: false, error: \"No valid fields to update\" };\n      }\n\n      params.push(id);\n      const sql = `\n        UPDATE tasks SET ${sets.join(\", \")}, updated_at = NOW()\n        WHERE id = $${params.length}\n        RETURNING id, title, description, status, priority, category, due_date, assignees, tags, checklist, created_by, parent_task_id, estimated_hours, created_at, updated_at\n      `;\n\n      this.logger.log(\"🚀 Executing SQL:\", sql, params);\n\n      const { rows } = await this.pool.query(sql, params);\n      if (!rows.length) {\n        return { success: false, error: \"Task not found\" };\n      }\n\n      const updatedTask = rows[0];\n\n      // CHECK NOTIFICATIONS\n      if (shouldUpdateAssignees) {\n        const newAssignees = updatedTask.assignees || [];\n        // Handle case where oldAssignees might be null/undefined or contains nulls\n        const safeOldAssignees = (oldAssignees || []).filter(Boolean);\n        const addedAssignees = newAssignees.filter(\n          (uid: string) => !safeOldAssignees.includes(uid),\n        );\n\n        this.logger.log(\"🔔 Notification check:\", {\n          safeOld: safeOldAssignees,\n          new: newAssignees,\n          added: addedAssignees,\n        });\n\n        if (addedAssignees.length > 0) {\n          const timestamp = new Date().toISOString();\n          this.logger.log(\n            `🔔 Found ${addedAssignees.length} new assignees to notify...`,\n          );\n\n          for (const assigneeId of addedAssignees) {\n            try {\n              this.logger.log(`🔔 Sending notification to ${assigneeId}`);\n\n              await this.itemsService.create(\n                \"notifications\",\n                assigneeId,\n                randomUUID(),\n                {\n                  title: \"משימה חדשה\",\n                  body: `הוקצתה לך משימה חדשה: ${updatedTask.title}`,\n                  type: \"system\",\n                  timestamp,\n                  read: false,\n                  userId: assigneeId,\n                  data: { taskId: updatedTask.id },\n                },\n              );\n              this.logger.log(`✅ Notification sent to ${assigneeId}`);\n            } catch (err) {\n              this.logger.error(\n                `❌ Failed to create notification for ${assigneeId}`,\n                err,\n              );\n            }\n          }\n\n          // AUTO-POST: Create posts for newly assigned users\n          const assignPostResults = { created: 0, failed: 0 };\n\n          try {\n            // Ensure posts table exists before creating posts\n            await this.ensurePostsTable();\n\n            this.logger.log(\n              `📝 Creating posts for ${addedAssignees.length} newly assigned users...`,\n            );\n            for (const assigneeId of addedAssignees) {\n              try {\n                await this.pool.query(\n                  `\n                  INSERT INTO posts (author_id, task_id, title, description, post_type)\n                  VALUES ($1, $2, $3, $4, 'task_assignment')\n                `,\n                  [\n                    assigneeId,\n                    updatedTask.id,\n                    `משימה חדשה: ${updatedTask.title}`,\n                    updatedTask.description\n                      ? `הוקצתה לך משימה חדשה: ${updatedTask.description}`\n                      : `הוקצתה לך משימה חדשה: ${updatedTask.title}`,\n                  ],\n                );\n                assignPostResults.created++;\n                this.logger.log(\n                  `✅ Post created for newly assigned user ${assigneeId}`,\n                );\n              } catch (postError) {\n                assignPostResults.failed++;\n                this.logger.error(\n                  `❌ Failed to create post for assignee ${assigneeId}:`,\n                  postError,\n                );\n              }\n            }\n            this.logger.log(\n              `📊 Assignment post summary: ${assignPostResults.created} created, ${assignPostResults.failed} failed`,\n            );\n\n            // Clear posts cache after creating posts\n            if (assignPostResults.created > 0) {\n              try {\n                await this.clearPostsCaches();\n                this.logger.log(\n                  \"✅ Posts caches cleared after assignment post creation\",\n                );\n              } catch (cacheErr) {\n                this.logger.warn(\n                  \"Error clearing posts caches after assignment (non-fatal):\",\n                  cacheErr,\n                );\n              }\n            }\n          } catch (tableError) {\n            this.logger.error(\n              \"❌ Failed to ensure posts table for assignment posts:\",\n              tableError,\n            );\n          }\n        }\n      }\n\n      // Clear task caches (blocking to prevent race condition)\n      try {\n        await this.redisCache.delete(`task_${id}`);\n        await this.clearTaskCaches();\n        this.logger.log(\"✅ Task caches cleared after update\");\n      } catch (cacheErr) {\n        this.logger.warn(\n          \"Error clearing caches after task update (non-fatal):\",\n          cacheErr,\n        );\n      }\n\n      if (rows.length > 0 && body.status === \"done\") {\n        const task = rows[0];\n        // AUTO-POST: Create posts for task completion\n        const completionPostResults = { created: 0, failed: 0 };\n\n        try {\n          // Ensure posts table exists before creating posts\n          await this.ensurePostsTable();\n\n          this.logger.log(\n            `📝 Creating completion posts for task ${task.id}...`,\n          );\n\n          // 1. Post for creator\n          if (task.created_by) {\n            try {\n              await this.pool.query(\n                `\n                INSERT INTO posts (author_id, task_id, title, description, post_type)\n                VALUES ($1, $2, $3, $4, 'task_completion')\n              `,\n                [\n                  task.created_by,\n                  task.id,\n                  `משימה הושלמה: ${task.title}`,\n                  task.description\n                    ? `המשימה \"${task.title}\" הושלמה בהצלחה! ${task.description}`\n                    : `המשימה \"${task.title}\" הושלמה בהצלחה!`,\n                ],\n              );\n              completionPostResults.created++;\n              this.logger.log(\n                `✅ Completion post created for creator ${task.created_by}`,\n              );\n            } catch (creatorPostError) {\n              completionPostResults.failed++;\n              this.logger.error(\n                `❌ Failed to create completion post for creator ${task.created_by}:`,\n                creatorPostError,\n              );\n            }\n          }\n\n          // 2. Post for assignees\n          if (task.assignees && task.assignees.length > 0) {\n            for (const assigneeId of task.assignees) {\n              if (assigneeId !== task.created_by) {\n                // Avoid duplicate if assigned to creator\n                try {\n                  await this.pool.query(\n                    `\n                    INSERT INTO posts (author_id, task_id, title, description, post_type)\n                    VALUES ($1, $2, $3, $4, 'task_completion')\n                  `,\n                    [\n                      assigneeId,\n                      task.id,\n                      `ביצעתי משימה: ${task.title}`,\n                      task.description\n                        ? `השלמתי את המשימה \"${task.title}\" בהצלחה! ${task.description}`\n                        : `השלמתי את המשימה \"${task.title}\" בהצלחה!`,\n                    ],\n                  );\n                  completionPostResults.created++;\n                  this.logger.log(\n                    `✅ Completion post created for assignee ${assigneeId}`,\n                  );\n                } catch (assigneePostError) {\n                  completionPostResults.failed++;\n                  this.logger.error(\n                    `❌ Failed to create completion post for assignee ${assigneeId}:`,\n                    assigneePostError,\n                  );\n                }\n              }\n            }\n          }\n          this.logger.log(\n            `📊 Completion post summary: ${completionPostResults.created} created, ${completionPostResults.failed} failed`,\n          );\n\n          // Clear posts cache after creating posts\n          if (completionPostResults.created > 0) {\n            try {\n              await this.clearPostsCaches();\n              this.logger.log(\n                \"✅ Posts caches cleared after completion post creation\",\n              );\n            } catch (cacheErr) {\n              this.logger.warn(\n                \"Error clearing posts caches after completion (non-fatal):\",\n                cacheErr,\n              );\n            }\n          }\n        } catch (tableError) {\n          this.logger.error(\n            \"❌ Failed to ensure posts table for completion posts:\",\n            tableError,\n          );\n        }\n      }\n\n      return { success: true, data: rows[0] };\n    } catch (error) {\n      this.logger.error(\"Error updating task:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to update task\",\n      };\n    }\n  }\n\n  @Delete(\":id\")\n  @UseGuards(JwtAuthGuard, AdminAuthGuard)\n  async deleteTask(@Param(\"id\") id: string) {\n    try {\n      // Ensure table exists before deleting\n      await this.ensureTasksTable();\n\n      // Validate UUID format\n      const uuidRegex =\n        /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;\n      if (!uuidRegex.test(id)) {\n        return { success: false, error: \"Invalid task ID format\" };\n      }\n\n      const { rowCount } = await this.pool.query(\n        \"DELETE FROM tasks WHERE id = $1\",\n        [id],\n      );\n      if (!rowCount) {\n        return { success: false, error: \"Task not found\" };\n      }\n\n      // Try to clear task caches (but don't fail if Redis is unavailable)\n      try {\n        await this.redisCache.delete(`task_${id}`);\n        await this.clearTaskCaches();\n      } catch (cacheError) {\n        this.logger.warn(\"Redis cache delete error (non-fatal):\", cacheError);\n      }\n\n      return { success: true, message: \"Task deleted\" };\n    } catch (error) {\n      this.logger.error(\"Error deleting task:\", error);\n      return {\n        success: false,\n        error: error instanceof Error ? error.message : \"Failed to delete task\",\n      };\n    }\n  }\n\n  /**\n   * Clear all task-related caches\n   * Called after create/update/delete operations to ensure data consistency\n   */\n  private async clearTaskCaches() {\n    try {\n      await this.redisCache.invalidatePattern(\"tasks_list_*\");\n    } catch (cacheError) {\n      this.logger.warn(\n        \"Redis cache invalidation error (non-fatal):\",\n        cacheError,\n      );\n    }\n  }\n\n  /**\n   * Clear all posts-related caches\n   * Called after creating posts to ensure data consistency\n   */\n  private async clearPostsCaches() {\n    try {\n      await this.redisCache.invalidatePattern(\"posts_list_*\");\n      await this.redisCache.invalidatePattern(\"user_posts_*\");\n    } catch (cacheError) {\n      this.logger.warn(\n        \"Redis cache invalidation error for posts (non-fatal):\",\n        cacheError,\n      );\n    }\n  }\n\n  /**\n   * Get hours report for a manager and their team\n   * GET /api/tasks/hours-report/:managerId\n   */\n  @Get(\"hours-report/:managerId\")\n  @UseGuards(JwtAuthGuard)\n  async getHoursReport(@Param(\"managerId\") managerId: string) {\n    try {\n      // Ensure task_time_logs table exists\n      await this.ensureTasksTable();\n\n      // Check if task_time_logs table exists\n      const tableExists = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'task_time_logs'\n        )\n      `);\n\n      if (!tableExists.rows[0].exists) {\n        // Table doesn't exist - return empty report\n        return {\n          success: true,\n          data: {\n            manager_hours: 0,\n            team_total_hours: 0,\n            by_task: [],\n            by_period: [],\n            by_user: [],\n          },\n        };\n      }\n\n      // Resolve managerId to UUID\n      const managerUuid = await this.resolveUserIdToUUID(managerId);\n      if (!managerUuid) {\n        return { success: false, error: \"Invalid manager ID\" };\n      }\n\n      // Get all subordinates (recursive)\n      const { rows: subordinates } = await this.pool.query(\n        `\n        WITH RECURSIVE subordinates AS (\n          SELECT id, name, email\n          FROM user_profiles\n          WHERE parent_manager_id = $1\n          \n          UNION ALL\n          \n          SELECT u.id, u.name, u.email\n          FROM user_profiles u\n          INNER JOIN subordinates s ON u.parent_manager_id = s.id\n        )\n        SELECT id, name, email FROM subordinates\n      `,\n        [managerUuid],\n      );\n\n      const teamUserIds = [managerUuid, ...subordinates.map((s: any) => s.id)];\n\n      // Get manager's own hours\n      const managerHoursRes = await this.pool.query(\n        `\n        SELECT COALESCE(SUM(actual_hours), 0)::NUMERIC as total_hours\n        FROM task_time_logs\n        WHERE user_id = $1\n      `,\n        [managerUuid],\n      );\n      const managerHours = parseFloat(\n        managerHoursRes.rows[0]?.total_hours || \"0\",\n      );\n\n      // Get team total hours\n      const teamHoursRes = await this.pool.query(\n        `\n        SELECT COALESCE(SUM(actual_hours), 0)::NUMERIC as total_hours\n        FROM task_time_logs\n        WHERE user_id = ANY($1::UUID[])\n      `,\n        [teamUserIds],\n      );\n      const teamTotalHours = parseFloat(\n        teamHoursRes.rows[0]?.total_hours || \"0\",\n      );\n\n      // Get hours by task\n      const hoursByTaskRes = await this.pool.query(\n        `\n        SELECT \n          t.id as task_id,\n          t.title as task_title,\n          COALESCE(SUM(ttl.actual_hours), 0)::NUMERIC as hours\n        FROM tasks t\n        INNER JOIN task_time_logs ttl ON t.id = ttl.task_id\n        WHERE ttl.user_id = ANY($1::UUID[])\n        GROUP BY t.id, t.title\n        ORDER BY hours DESC\n      `,\n        [teamUserIds],\n      );\n\n      // Get hours by period (month)\n      const hoursByPeriodRes = await this.pool.query(\n        `\n        SELECT \n          TO_CHAR(logged_at, 'YYYY-MM') as period,\n          COALESCE(SUM(actual_hours), 0)::NUMERIC as hours\n        FROM task_time_logs\n        WHERE user_id = ANY($1::UUID[])\n        GROUP BY TO_CHAR(logged_at, 'YYYY-MM')\n        ORDER BY period DESC\n        LIMIT 12\n      `,\n        [teamUserIds],\n      );\n\n      // Get hours by user\n      const hoursByUserRes = await this.pool.query(\n        `\n        SELECT \n          u.id as user_id,\n          u.name as user_name,\n          COALESCE(SUM(ttl.actual_hours), 0)::NUMERIC as hours\n        FROM user_profiles u\n        LEFT JOIN task_time_logs ttl ON u.id = ttl.user_id\n        WHERE u.id = ANY($1::UUID[])\n        GROUP BY u.id, u.name\n        ORDER BY hours DESC\n      `,\n        [teamUserIds],\n      );\n\n      const report = {\n        manager_hours: managerHours,\n        team_total_hours: teamTotalHours,\n        by_task: hoursByTaskRes.rows.map((row: any) => ({\n          task_id: row.task_id,\n          task_title: row.task_title,\n          hours: parseFloat(row.hours || \"0\"),\n        })),\n        by_period: hoursByPeriodRes.rows.map((row: any) => ({\n          period: row.period,\n          hours: parseFloat(row.hours || \"0\"),\n        })),\n        by_user: hoursByUserRes.rows.map((row: any) => ({\n          user_id: row.user_id,\n          user_name: row.user_name,\n          hours: parseFloat(row.hours || \"0\"),\n        })),\n      };\n\n      return { success: true, data: report };\n    } catch (error) {\n      this.logger.error(\"Error getting hours report:\", error);\n      // Return empty report on error instead of failing\n      return {\n        success: true,\n        data: {\n          manager_hours: 0,\n          team_total_hours: 0,\n          by_task: [],\n          by_period: [],\n          by_user: [],\n        },\n      };\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/controllers/users.controller.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":378,"column":43,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":378,"endColumn":46,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13556,13559],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13556,13559],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":408,"column":37,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":408,"endColumn":40,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[14589,14592],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[14589,14592],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":447,"column":49,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":447,"endColumn":52,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16019,16022],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16019,16022],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":452,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":452,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16171,16174],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16171,16174],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":513,"column":49,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":513,"endColumn":52,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[18478,18481],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[18478,18481],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":518,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":518,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[18630,18633],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[18630,18633],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1329,"column":27,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1329,"endColumn":30,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[46898,46901],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[46898,46901],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1336,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1336,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[47149,47152],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[47149,47152],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1343,"column":50,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1343,"endColumn":53,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[47507,47510],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[47507,47510],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1376,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1376,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[48585,48588],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[48585,48588],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1383,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1383,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[48852,48855],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[48852,48855],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1390,"column":46,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1390,"endColumn":49,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[49226,49229],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[49226,49229],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1542,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1542,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[54191,54194],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[54191,54194],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1632,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1632,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[57461,57464],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[57461,57464],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1675,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1675,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[59240,59243],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[59240,59243],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1737,"column":10,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1737,"endColumn":13,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[61709,61712],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[61709,61712],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1838,"column":40,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1838,"endColumn":43,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[65244,65247],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[65244,65247],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1971,"column":38,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1971,"endColumn":41,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[70144,70147],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[70144,70147],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2099,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2099,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[74605,74608],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[74605,74608],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2143,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2143,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[76334,76337],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[76334,76337],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2218,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2218,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[79195,79198],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[79195,79198],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2234,"column":65,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2234,"endColumn":68,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[79638,79641],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[79638,79641],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2281,"column":27,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2281,"endColumn":30,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[81310,81313],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[81310,81313],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2457,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2457,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[87813,87816],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[87813,87816],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2498,"column":15,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2498,"endColumn":18,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[89003,89006],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[89003,89006],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2542,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2542,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[90893,90896],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[90893,90896],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2661,"column":24,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2661,"endColumn":27,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[95181,95184],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[95181,95184],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2662,"column":20,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2662,"endColumn":23,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[95205,95208],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[95205,95208],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2663,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2663,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[95232,95235],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[95232,95235],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2744,"column":69,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2744,"endColumn":72,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[97652,97655],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[97652,97655],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2813,"column":73,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2813,"endColumn":76,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[99527,99530],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[99527,99530],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2933,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2933,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[103327,103330],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[103327,103330],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2952,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2952,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[103908,103911],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[103908,103911],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2956,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2956,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[104038,104041],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[104038,104041],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":2964,"column":33,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":2964,"endColumn":36,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[104502,104505],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[104502,104505],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":3006,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":3006,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[106000,106003],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[106000,106003],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":3083,"column":41,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":3083,"endColumn":44,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[109612,109615],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[109612,109615],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":3197,"column":27,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":3197,"endColumn":30,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[114459,114462],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[114459,114462],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":3283,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":3283,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[117548,117551],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[117548,117551],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":39,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Users API for register/login (relational), get/update profile, list users, activities/stats, and follow/unfollow.\n// - Reached from: Routes under '/api/users'.\n// - Provides: Endpoints for CRUD-like operations and analytics; uses Redis caching for profiles/lists.\n// - Storage: `user_profiles`, `user_follows`, `user_activities` (and joins to donations/rides).\n\n// TODO: CRITICAL - This file is too long (509 lines). Split into multiple services:\n//   - UserService for business logic\n//   - UserProfileService for profile operations\n//   - UserStatsService for analytics\n//   - UserFollowService for follow/unfollow logic\n// TODO: Add comprehensive DTO validation for all endpoints\n// TODO: Implement proper pagination with cursor-based approach instead of offset\n// TODO: Add comprehensive error handling with proper HTTP status codes\n// TODO: Standardize response format across all endpoints\n// TODO: Add proper database constraint validation and conflict handling\n// TODO: Implement soft deletes instead of hard deletes where applicable\n// TODO: Add comprehensive logging and monitoring\n// TODO: Add unit and integration tests for all endpoints\n// TODO: Optimize database queries - many N+1 query problems\nimport {\n  Body,\n  Controller,\n  Delete,\n  Get,\n  Param,\n  Post,\n  Put,\n  Query,\n  UseGuards,\n  Logger,\n} from \"@nestjs/common\";\nimport { Inject } from \"@nestjs/common\";\nimport { ConfigService } from \"@nestjs/config\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\nimport { JwtAuthGuard } from \"../auth/jwt-auth.guard\";\nimport { JwtService } from \"../auth/jwt.service\";\nimport * as argon2 from \"argon2\";\nimport { randomUUID } from \"crypto\";\nimport * as admin from \"firebase-admin\";\n\n@Controller(\"api/users\")\nexport class UsersController {\n  private readonly logger = new Logger(UsersController.name);\n  // TODO: Move constants to a dedicated constants file\n  // TODO: Make cache TTL configurable through environment variables\n  // TODO: Implement different TTL values for different types of data\n  private readonly CACHE_TTL = 15 * 60; // 15 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n    private readonly jwtService: JwtService,\n    private readonly configService: ConfigService,\n  ) {}\n\n  /** Root admin email from env - the only protected user (cannot be demoted/modified). */\n  private getRootAdminEmail(): string {\n    return (this.configService.get<string>(\"ROOT_ADMIN_EMAIL\") || \"\")\n      .toLowerCase()\n      .trim();\n  }\n\n  // ================================================================\n  // Phase 2+ Methods: Admin Hierarchy, Complex RBAC, Analytics\n  // Disabled for MVP — DO NOT DELETE. Re-enable per roadmap phases.\n  // ================================================================\n  /**\n   * Ensure salary and seniority_start_date columns exist in user_profiles table\n   * Creates them if missing (idempotent)\n   */\n  private async ensureSalarySeniorityColumns(): Promise<void> {\n    try {\n      const client = await this.pool.connect();\n      try {\n        // Check if columns exist\n        const checkResult = await client.query(`\n          SELECT column_name \n          FROM information_schema.columns \n          WHERE table_name = 'user_profiles' \n          AND column_name IN ('salary', 'seniority_start_date', 'parent_manager_id')\n        `);\n\n        const existingColumns = checkResult.rows.map((r) => r.column_name);\n\n        if (!existingColumns.includes(\"salary\")) {\n          this.logger.log(\"📋 Adding salary column to user_profiles...\");\n          await client.query(`\n            ALTER TABLE user_profiles \n            ADD COLUMN salary DECIMAL(10,2) DEFAULT 0\n          `);\n          this.logger.log(\"✅ Added salary column\");\n        }\n\n        if (!existingColumns.includes(\"seniority_start_date\")) {\n          this.logger.log(\n            \"📋 Adding seniority_start_date column to user_profiles...\",\n          );\n          await client.query(`\n            ALTER TABLE user_profiles \n            ADD COLUMN seniority_start_date DATE DEFAULT CURRENT_DATE\n          `);\n          this.logger.log(\"✅ Added seniority_start_date column\");\n        }\n\n        if (!existingColumns.includes(\"parent_manager_id\")) {\n          this.logger.log(\n            \"📋 Adding parent_manager_id column to user_profiles...\",\n          );\n          await client.query(`\n            ALTER TABLE user_profiles \n            ADD COLUMN parent_manager_id UUID REFERENCES user_profiles(id) ON DELETE SET NULL\n          `);\n          await client.query(`\n            CREATE INDEX IF NOT EXISTS idx_user_profiles_parent_manager ON user_profiles(parent_manager_id)\n          `);\n          this.logger.log(\"✅ Added parent_manager_id column\");\n        }\n      } finally {\n        client.release();\n      }\n    } catch (error) {\n      this.logger.error(\"❌ Error ensuring user profile columns:\", error);\n      // Don't throw - allow fallback query to work\n    }\n  }\n\n  /**\n   * Search users for autocomplete (lightweight)\n   * GET /api/users/search?q=...\n   */\n  @Get(\"search\")\n  async searchUsers(@Query(\"q\") query: string) {\n    if (!query || query.length < 2) {\n      return { success: true, data: [] };\n    }\n\n    try {\n      const { rows } = await this.pool.query(\n        `\n        SELECT id, name, email, avatar_url, roles\n        FROM user_profiles\n        WHERE (name ILIKE $1 OR email ILIKE $1)\n        AND is_active = true\n        LIMIT 20\n      `,\n        [`%${query}%`],\n      );\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Search users error:\", error);\n      return { success: false, error: \"Failed to search users\" };\n    }\n  }\n\n  /**\n   * Set parent manager for a user\n   * POST /api/users/:id/set-manager\n   * Body: { managerId: string | null, requestingUserId?: string }\n   */\n  @Post(\":id/set-manager\")\n  @UseGuards(JwtAuthGuard)\n  async setManager(\n    @Param(\"id\") id: string,\n    @Body()\n    body: { managerId: string | null | undefined; requestingUserId?: string },\n  ) {\n    try {\n      const { managerId, requestingUserId } = body;\n\n      this.logger.log(\n        `[setManager] Setting manager for user ${id}: managerId=${managerId} (type: ${typeof managerId}), requestingUserId=${requestingUserId}`,\n      );\n      this.logger.log(`[setManager] Full body:`, JSON.stringify(body));\n\n      // Permission check: only admin or super admin can change manager assignments\n      if (requestingUserId) {\n        const { rows: reqUser } = await this.pool.query(\n          `SELECT id, email, roles FROM user_profiles WHERE id = $1`,\n          [requestingUserId],\n        );\n\n        if (reqUser.length > 0) {\n          const isAdmin =\n            (reqUser[0].roles || []).includes(\"admin\") ||\n            (reqUser[0].roles || []).includes(\"super_admin\");\n\n          if (!isAdmin) {\n            this.logger.log(\n              `[setManager] Permission denied for user ${requestingUserId}`,\n            );\n            return {\n              success: false,\n              error: \"אין לך הרשאה לבצע פעולה זו - נדרשות הרשאות מנהל\",\n            };\n          }\n        }\n      }\n\n      // CRITICAL: Protect root admin (from env) - cannot be changed\n      const rootEmail = this.getRootAdminEmail();\n      const { rows: targetUserCheck } = await this.pool.query(\n        \"SELECT email FROM user_profiles WHERE id = $1\",\n        [id],\n      );\n\n      if (\n        rootEmail &&\n        targetUserCheck.length > 0 &&\n        (targetUserCheck[0].email || \"\").toLowerCase().trim() === rootEmail\n      ) {\n        this.logger.log(\n          `[setManager] ❌ BLOCKED: Attempt to modify root admin`,\n        );\n        return {\n          success: false,\n          error: \"לא ניתן לשנות את המנהל הראשי - הוא המנהל הראשי\",\n        };\n      }\n\n      // If managerId is null or undefined, we're removing the manager assignment\n      if (\n        managerId === null ||\n        managerId === undefined ||\n        managerId === \"null\" ||\n        managerId === \"\"\n      ) {\n        // Check current state\n        const { rows: currentUser } = await this.pool.query(\n          \"SELECT parent_manager_id FROM user_profiles WHERE id = $1\",\n          [id],\n        );\n\n        if (currentUser.length === 0) {\n          this.logger.log(`[setManager] User not found: ${id}`);\n          return { success: false, error: \"User not found\" };\n        }\n\n        // Logic: When removing a manager assignment:\n        // - If user is NOT an admin, remove 'volunteer' role (becomes regular user)\n        // - If user IS an admin, remove 'admin' role too (admin must have a manager, except root admin)\n        const currentManagerId = currentUser[0].parent_manager_id;\n        this.logger.log(\n          `[setManager] Removing manager assignment for user ${id}, current manager: ${currentManagerId}`,\n        );\n\n        // Check if user is an admin\n        const { rows: userData } = await this.pool.query(\n          \"SELECT roles, email FROM user_profiles WHERE id = $1\",\n          [id],\n        );\n        const isAdmin =\n          userData.length > 0 &&\n          ((userData[0].roles || []).includes(\"admin\") ||\n            (userData[0].roles || []).includes(\"super_admin\"));\n        const isRootAdmin =\n          userData.length > 0 &&\n          rootEmail &&\n          (userData[0].email || \"\").toLowerCase().trim() === rootEmail;\n\n        // Build new roles array\n        let newRoles = Array.isArray(userData[0]?.roles)\n          ? [...userData[0].roles]\n          : [];\n\n        // Remove volunteer role\n        newRoles = newRoles.filter((r: string) => r !== \"volunteer\");\n\n        // If admin (and not root admin), remove admin roles too (admin must have a manager)\n        if (isAdmin && !isRootAdmin) {\n          newRoles = newRoles.filter(\n            (r: string) => r !== \"admin\" && r !== \"super_admin\",\n          );\n          this.logger.log(\n            `[setManager] ⚠️ Removing admin roles from user ${id} because manager assignment was removed (admin must have a manager)`,\n          );\n        }\n\n        // Update: remove manager, and update roles\n        await this.pool.query(\n          `\n          UPDATE user_profiles \n          SET \n            parent_manager_id = NULL, \n            updated_at = NOW(),\n            roles = $1::text[]\n          WHERE id = $2\n        `,\n          [newRoles, id],\n        );\n\n        // Invalidate caches to ensure fresh data\n        await this.redisCache.delete(`user_profile_${id}`);\n        await this.redisCache.invalidatePattern(\"users_list*\");\n        this.logger.log(\n          `[setManager] Invalidated cache for user ${id} and all user lists`,\n        );\n\n        this.logger.log(\n          `✅ Manager removed: ${id} no longer reports to anyone`,\n        );\n        return { success: true, message: \"שיוך מנהל הוסר בהצלחה\" };\n      }\n\n      // Prevent validation loop (user cannot be their own manager)\n      if (managerId === id) {\n        return { success: false, error: \"User cannot be their own manager\" };\n      }\n\n      // Check if manager exists\n      const { rows: checkManager } = await this.pool.query(\n        \"SELECT id, email, parent_manager_id FROM user_profiles WHERE id = $1\",\n        [managerId],\n      );\n      if (checkManager.length === 0) {\n        return { success: false, error: \"Manager not found\" };\n      }\n\n      const managerEmail = checkManager[0].email;\n      const managerCurrentParent = checkManager[0].parent_manager_id;\n\n      // CRITICAL FIX: If the proposed manager is the root admin (from env),\n      // ensure it has NO parent_manager_id (cannot be subordinate to anyone)\n      if (\n        rootEmail &&\n        (managerEmail || \"\").toLowerCase().trim() === rootEmail &&\n        managerCurrentParent !== null\n      ) {\n        this.logger.log(\n          `[setManager] 🔧 FIXING: Root admin has parent_manager_id=${managerCurrentParent}, removing it...`,\n        );\n        await this.pool.query(\n          `\n          UPDATE user_profiles \n          SET parent_manager_id = NULL, updated_at = NOW()\n          WHERE id = $1\n        `,\n          [managerId],\n        );\n        this.logger.log(\n          `[setManager] ✅ Fixed: Root admin no longer has a parent manager`,\n        );\n        // Invalidate cache\n        await this.redisCache.delete(`user_profile_${managerId}`);\n        await this.redisCache.invalidatePattern(\"users_list*\");\n      }\n\n      // SPECIAL CASE: If assigning to root admin (from env), skip cycle check\n      if (\n        rootEmail &&\n        (managerEmail || \"\").toLowerCase().trim() === rootEmail\n      ) {\n        this.logger.log(\n          `[setManager] ✅ Assigning to root admin - skipping cycle check`,\n        );\n        // Proceed directly to assignment (skip cycle detection)\n      } else {\n        // Full cycle detection using recursive CTE\n        // Check if 'id' (subordinate) appears anywhere in managerId's hierarchy chain\n        // This prevents: user → ... → manager → user (circular)\n\n        // First, get current hierarchy info for debugging\n        const { rows: currentHierarchy } = await this.pool.query(\n          `\n          SELECT id, name, email, parent_manager_id \n          FROM user_profiles \n          WHERE id IN ($1, $2)\n        `,\n          [id, managerId],\n        );\n\n        this.logger.log(`[setManager] 🔍 Current hierarchy state:`, {\n          userId: id,\n          managerId: managerId,\n          users: currentHierarchy.map((u: any) => ({\n            id: u.id,\n            name: u.name,\n            email: u.email,\n            parent_manager_id: u.parent_manager_id,\n          })),\n        });\n\n        // Get the full chain from managerId going up to see what we're checking\n        const { rows: managerChainDebug } = await this.pool.query(\n          `\n          WITH RECURSIVE manager_chain AS (\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100 AND u.parent_manager_id IS NOT NULL\n          )\n          SELECT id, parent_manager_id, depth FROM manager_chain ORDER BY depth\n        `,\n          [managerId],\n        );\n\n        this.logger.log(\n          `[setManager] 🔍 Manager chain (going up from ${managerId}):`,\n          managerChainDebug.map((m: any) => ({\n            id: m.id,\n            parent: m.parent_manager_id,\n            depth: m.depth,\n          })),\n        );\n\n        const { rows: cycleCheck } = await this.pool.query(\n          `\n          WITH RECURSIVE manager_chain AS (\n            -- Base case: start from the proposed manager\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            -- Recursive: go up the chain\n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100 AND u.parent_manager_id IS NOT NULL\n          )\n          SELECT id, depth FROM manager_chain WHERE id = $2 LIMIT 1\n        `,\n          [managerId, id],\n        );\n\n        this.logger.log(\n          `[setManager] 🔄 Checking for hierarchy cycle: Would user ${id} becoming subordinate of ${managerId} create a cycle?`,\n        );\n        this.logger.log(`[setManager] 🔍 Cycle check result:`, cycleCheck);\n\n        if (cycleCheck.length > 0) {\n          // Get user details for better error message\n          const { rows: userDetails } = await this.pool.query(\n            \"SELECT id, name, email FROM user_profiles WHERE id IN ($1, $2)\",\n            [id, managerId],\n          );\n          const userInfo = userDetails.find((u: any) => u.id === id) || {\n            name: null,\n            email: null,\n          };\n          const managerInfo = userDetails.find(\n            (u: any) => u.id === managerId,\n          ) || { name: null, email: null };\n\n          const userName = userInfo.name || userInfo.email || id;\n          const managerName =\n            managerInfo.name || managerInfo.email || managerId;\n\n          this.logger.log(\n            `❌ [setManager] CYCLE DETECTED: Cannot assign ${managerName} as manager of ${userName}`,\n          );\n          this.logger.log(\n            `   Reason: ${userName} is already in the management chain above ${managerName}`,\n          );\n          this.logger.log(\n            `   This would create a circular chain: ${userName} → ... → ${managerName} → ${userName}`,\n          );\n          return {\n            success: false,\n            error: `לא ניתן להגדיר את ${managerName} כמנהל של ${userName} - זה יוצר מחזור בהיררכיה כי ${userName} כבר נמצא בשרשרת הניהול מעל ${managerName}`,\n          };\n        }\n\n        this.logger.log(`[setManager] ✅ No upward cycle found`);\n      }\n\n      // Check reverse direction - if manager is subordinate of user\n      if (\n        !rootEmail ||\n        (managerEmail || \"\").toLowerCase().trim() !== rootEmail\n      ) {\n        const { rows: reverseCheck } = await this.pool.query(\n          `\n          WITH RECURSIVE subordinate_tree AS (\n            -- Base case: direct subordinates of user\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE parent_manager_id = $2\n            \n            UNION ALL\n            \n            -- Recursive: subordinates of subordinates\n            SELECT u.id, u.parent_manager_id, st.depth + 1\n            FROM user_profiles u\n            INNER JOIN subordinate_tree st ON u.parent_manager_id = st.id\n            WHERE st.depth < 100\n          )\n          SELECT 1 FROM subordinate_tree WHERE id = $1 LIMIT 1\n        `,\n          [managerId, id],\n        );\n\n        this.logger.log(\n          `[setManager] 🔄 Checking reverse: Is ${managerId} a subordinate of ${id}?`,\n        );\n\n        if (reverseCheck.length > 0) {\n          // Get user details for better error message\n          const { rows: userDetails } = await this.pool.query(\n            \"SELECT id, name, email FROM user_profiles WHERE id IN ($1, $2)\",\n            [id, managerId],\n          );\n          const userInfo = userDetails.find((u: any) => u.id === id) || {\n            name: null,\n            email: null,\n          };\n          const managerInfo = userDetails.find(\n            (u: any) => u.id === managerId,\n          ) || { name: null, email: null };\n\n          const userName = userInfo.name || userInfo.email || id;\n          const managerName =\n            managerInfo.name || managerInfo.email || managerId;\n\n          this.logger.log(\n            `❌ [setManager] REVERSE CYCLE DETECTED: ${managerName} is currently a subordinate of ${userName}`,\n          );\n          this.logger.log(\n            `   Cannot assign ${managerName} as manager of ${userName} - would create cycle`,\n          );\n          return {\n            success: false,\n            error: `לא ניתן להגדיר את ${managerName} כמנהל של ${userName} - ${managerName} כבר כפוף ל-${userName}`,\n          };\n        }\n\n        this.logger.log(\n          `[setManager] ✅ No reverse cycle found - proceeding with assignment`,\n        );\n      } else {\n        this.logger.log(\n          `[setManager] ✅ Skipping reverse cycle check (root admin cannot be subordinate)`,\n        );\n      }\n\n      this.logger.log(\n        `[setManager] 📝 Before UPDATE: user=${id}, new parent_manager_id=${managerId}`,\n      );\n\n      // CRITICAL CHECK: Admin must have a manager (except root admin)\n      // If user is an admin and we're removing their manager, we should have already removed admin role\n      // But let's also check: if user is an admin and doesn't have a manager, that's invalid\n      const { rows: userCheck } = await this.pool.query(\n        \"SELECT roles, email FROM user_profiles WHERE id = $1\",\n        [id],\n      );\n\n      if (userCheck.length > 0) {\n        const userRoles = Array.isArray(userCheck[0].roles)\n          ? userCheck[0].roles\n          : [];\n        const isAdmin =\n          userRoles.includes(\"admin\") || userRoles.includes(\"super_admin\");\n        const isRootAdmin =\n          rootEmail &&\n          (userCheck[0].email || \"\").toLowerCase().trim() === rootEmail;\n\n        // If user is an admin (and not root admin), they MUST have a manager\n        if (isAdmin && !isRootAdmin && !managerId) {\n          this.logger.log(\n            `[setManager] ❌ BLOCKED: Admin ${id} cannot exist without a manager (except root admin)`,\n          );\n          return {\n            success: false,\n            error:\n              \"מנהל חייב להיות משויך למנהל מעליו (חוץ מהמנהל הראשי). אם ברצונך להסיר את השיוך, המשתמש יהפוך למשתמש רגיל.\",\n          };\n        }\n      }\n\n      // Logic: When a user is assigned a manager, they automatically become a 'volunteer'.\n      // If they're already an admin, they keep admin role (every manager is also a volunteer).\n      // Update to set manager AND ensure 'volunteer' role (keep admin if exists)\n      await this.pool.query(\n        `\n        UPDATE user_profiles \n        SET \n          parent_manager_id = $1, \n          updated_at = NOW(),\n          roles = (\n            SELECT array_agg(DISTINCT role)\n            FROM unnest(roles || ARRAY['volunteer']::text[]) AS role\n            WHERE role IS NOT NULL\n          )\n        WHERE id = $2\n      `,\n        [managerId, id],\n      );\n\n      // Invalidate caches to ensure fresh data\n      await this.redisCache.delete(`user_profile_${id}`);\n      await this.redisCache.delete(`user_profile_${managerId}`);\n      await this.redisCache.invalidatePattern(\"users_list*\");\n      this.logger.log(\n        `[setManager] ♻️ Invalidated cache for users ${id} and ${managerId} and all user lists`,\n      );\n\n      this.logger.log(`✅ Manager set: ${id} now reports to ${managerId}`);\n      this.logger.log(\n        `[setManager] 📊 Updated: parent_manager_id=${managerId}`,\n      );\n\n      return { success: true, message: \"Manager updated successfully\" };\n    } catch (error) {\n      this.logger.error(\"Set manager error:\", error);\n      return { success: false, error: \"Failed to set manager\" };\n    }\n  }\n\n  /**\n   * Manage hierarchy: Add or Remove subordinate\n   * POST /api/users/:id/hierarchy/manage\n   * Body: { action: 'add' | 'remove', managerId: string }\n   */\n  @Post(\":id/hierarchy/manage\")\n  @UseGuards(JwtAuthGuard)\n  async manageHierarchy(\n    @Param(\"id\") subordinateId: string,\n    @Body() body: { action: \"add\" | \"remove\"; managerId: string },\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const { action, managerId } = body;\n      await client.query(\"BEGIN\");\n\n      // CRITICAL: Protect root admin (from env)\n      const rootEmail = this.getRootAdminEmail();\n      const { rows: subordinateCheck } = await client.query(\n        \"SELECT email FROM user_profiles WHERE id = $1\",\n        [subordinateId],\n      );\n\n      if (\n        rootEmail &&\n        subordinateCheck.length > 0 &&\n        (subordinateCheck[0].email || \"\").toLowerCase().trim() === rootEmail\n      ) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[manageHierarchy] ❌ BLOCKED: Attempt to modify root admin`,\n        );\n        return {\n          success: false,\n          error: \"לא ניתן לשנות את המנהל הראשי - הוא המנהל הראשי\",\n        };\n      }\n\n      if (action === \"add\") {\n        // Full cycle detection using recursive CTE\n        // Check if subordinateId appears anywhere in managerId's hierarchy chain (upwards)\n        // This prevents: A → B → C → A cycles at any depth\n        const { rows: cycleCheck } = await client.query(\n          `\n          WITH RECURSIVE manager_chain AS (\n            -- Base case: start from the proposed manager\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            -- Recursive: go up the chain\n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100  -- Prevent infinite loops in case of existing cycles\n          )\n          SELECT 1 FROM manager_chain WHERE id = $2 LIMIT 1\n        `,\n          [managerId, subordinateId],\n        );\n\n        this.logger.log(\n          `[manageHierarchy] 🔄 Checking for hierarchy cycle: Would ${subordinateId} → ${managerId} create a cycle?`,\n        );\n\n        if (cycleCheck.length > 0) {\n          await client.query(\"ROLLBACK\");\n          this.logger.log(\n            `❌ [manageHierarchy] CYCLE DETECTED: ${subordinateId} is already in the management chain ABOVE ${managerId}`,\n          );\n          return {\n            success: false,\n            error:\n              \"Cannot create hierarchy cycle - this would create a circular management chain\",\n          };\n        }\n\n        this.logger.log(`[manageHierarchy] ✅ No upward cycle found`);\n\n        // Also check if subordinate would become manager of someone in their own chain\n        const { rows: reverseCheck } = await client.query(\n          `\n          WITH RECURSIVE subordinate_chain AS (\n            -- Base case: start from the subordinate\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $2\n            \n            UNION ALL\n            \n            -- Recursive: go up the chain\n            SELECT u.id, u.parent_manager_id, sc.depth + 1\n            FROM user_profiles u\n            INNER JOIN subordinate_chain sc ON u.id = sc.parent_manager_id\n            WHERE sc.depth < 100\n          )\n          SELECT 1 FROM subordinate_chain WHERE id = $1 LIMIT 1\n        `,\n          [managerId, subordinateId],\n        );\n\n        this.logger.log(\n          `[manageHierarchy] 🔄 Checking reverse: Is ${managerId} in hierarchy chain of ${subordinateId}?`,\n        );\n\n        if (reverseCheck.length > 0) {\n          await client.query(\"ROLLBACK\");\n          this.logger.log(\n            `❌ [manageHierarchy] REVERSE CYCLE DETECTED: ${managerId} is already in management chain of ${subordinateId}`,\n          );\n          return {\n            success: false,\n            error:\n              \"Cannot assign - this user is already in your management chain\",\n          };\n        }\n\n        this.logger.log(\n          `[manageHierarchy] ✅ No reverse cycle found - proceeding with assignment`,\n        );\n\n        await client.query(\n          `\n          UPDATE user_profiles \n          SET parent_manager_id = $1, updated_at = NOW()\n          WHERE id = $2\n        `,\n          [managerId, subordinateId],\n        );\n\n        await client.query(\"COMMIT\");\n        this.logger.log(\n          `✅ Hierarchy updated: ${subordinateId} now reports to ${managerId}`,\n        );\n        return { success: true, message: \"Subordinate added successfully\" };\n      } else if (action === \"remove\") {\n        // Validate that they are currently managed by this manager\n        const { rows: currentCheck } = await client.query(\n          \"SELECT parent_manager_id, name, email FROM user_profiles WHERE id = $1\",\n          [subordinateId],\n        );\n        if (currentCheck[0]?.parent_manager_id !== managerId) {\n          await client.query(\"ROLLBACK\");\n          return { success: false, error: \"User is not your subordinate\" };\n        }\n\n        const subordinateName =\n          currentCheck[0]?.name || currentCheck[0]?.email || \"Unknown\";\n\n        // 1. Get tasks that will be transferred (for notification and logging)\n        const { rows: tasksToTransfer } = await client.query(\n          `\n          SELECT id, title, status, priority\n          FROM tasks\n          WHERE $1::UUID = ANY(assignees::UUID[]) \n          AND status NOT IN ('done', 'archived')\n        `,\n          [subordinateId],\n        );\n\n        const transferCount = tasksToTransfer.length;\n        this.logger.log(\n          `📋 Found ${transferCount} active tasks to transfer from ${subordinateId} to ${managerId}`,\n        );\n\n        // 2. Remove manager link\n        await client.query(\n          `\n          UPDATE user_profiles \n          SET parent_manager_id = NULL, updated_at = NOW()\n          WHERE id = $1\n        `,\n          [subordinateId],\n        );\n\n        // 3. Transfer active tasks (assignees) from subordinate to manager\n        if (transferCount > 0) {\n          await client.query(\n            `\n            UPDATE tasks\n            SET assignees = array_replace(assignees::UUID[], $1::UUID, $2::UUID)::UUID[],\n                updated_at = NOW()\n            WHERE $1::UUID = ANY(assignees::UUID[]) \n            AND status NOT IN ('done', 'archived')\n          `,\n            [subordinateId, managerId],\n          );\n\n          this.logger.log(\n            `✅ Transferred ${transferCount} tasks from ${subordinateName} to manager ${managerId}`,\n          );\n\n          // Log the transfer details\n          this.logger.log(\n            \"📝 Transferred tasks:\",\n            tasksToTransfer\n              .map((t) => `${t.id.substring(0, 8)}: ${t.title} (${t.priority})`)\n              .join(\", \"),\n          );\n        }\n\n        await client.query(\"COMMIT\");\n\n        // 4. Create notification for manager about transferred tasks (non-blocking)\n        if (transferCount > 0) {\n          try {\n            // Insert notification directly to the database\n            await this.pool.query(\n              `\n              INSERT INTO notifications (user_id, item_id, data, created_at)\n              VALUES ($1, $2, $3, NOW())\n              ON CONFLICT (user_id, item_id) DO NOTHING\n            `,\n              [\n                managerId,\n                randomUUID(),\n                JSON.stringify({\n                  title: \"משימות הועברו אליך\",\n                  body: `${transferCount} משימות הועברו אליך מ${subordinateName} שהוסר מהניהול שלך`,\n                  type: \"system\",\n                  timestamp: new Date().toISOString(),\n                  read: false,\n                  data: {\n                    transferredTaskIds: tasksToTransfer.map((t) => t.id),\n                    fromUser: subordinateId,\n                    fromUserName: subordinateName,\n                    count: transferCount,\n                  },\n                }),\n              ],\n            );\n            this.logger.log(\n              `🔔 Notification sent to manager ${managerId} about ${transferCount} transferred tasks`,\n            );\n          } catch (notifError) {\n            this.logger.warn(\n              \"Failed to create transfer notification (non-fatal):\",\n              notifError,\n            );\n          }\n        }\n\n        return {\n          success: true,\n          message: `Subordinate removed and ${transferCount} tasks transferred`,\n          data: { transferredTasks: transferCount },\n        };\n      }\n\n      await client.query(\"ROLLBACK\");\n      return { success: false, error: \"Invalid action\" };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Manage hierarchy error:\", error);\n      return { success: false, error: \"Failed to manage hierarchy\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Promote a user to admin role with hierarchy validation\n   * POST /api/users/:id/promote-admin\n   * Body: { requestingAdminId: string }\n   *\n   * Rules:\n   * 1. The requesting admin must be an admin\n   * 2. The target user must NOT already be an admin under someone else\n   * 3. The target user must NOT be a manager above the requesting admin\n   * 4. The target user will be set as subordinate of the requesting admin\n   */\n  @Post(\":id/promote-admin\")\n  @UseGuards(JwtAuthGuard)\n  async promoteToAdmin(\n    @Param(\"id\") targetUserId: string,\n    @Body() body: { requestingAdminId: string },\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const { requestingAdminId } = body;\n\n      this.logger.log(\n        `[promoteToAdmin] 📝 Request: targetUserId=${targetUserId}, requestingAdminId=${requestingAdminId}`,\n      );\n\n      if (!requestingAdminId) {\n        return { success: false, error: \"requestingAdminId is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // 1. Verify requesting user exists and is an admin\n      const { rows: requestingUser } = await client.query(\n        `SELECT id, email, roles FROM user_profiles WHERE id = $1`,\n        [requestingAdminId],\n      );\n\n      this.logger.log(`[promoteToAdmin] 🔍 Requesting user lookup:`, {\n        requestingAdminId,\n        found: requestingUser.length > 0,\n        user: requestingUser[0] || null,\n      });\n\n      if (requestingUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[promoteToAdmin] ❌ Requesting user not found: ${requestingAdminId}`,\n        );\n        return { success: false, error: \"Requesting user not found\" };\n      }\n\n      const isSuperAdmin = (requestingUser[0].roles || []).includes(\n        \"super_admin\",\n      );\n      const isAdmin =\n        (requestingUser[0].roles || []).includes(\"admin\") || isSuperAdmin;\n\n      this.logger.log(`[promoteToAdmin] 🔐 Authorization check:`, {\n        email: requestingUser[0].email,\n        roles: requestingUser[0].roles,\n        isSuperAdmin,\n        isAdmin,\n      });\n\n      if (!isAdmin) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[promoteToAdmin] ❌ Authorization denied - not an admin`,\n        );\n        return {\n          success: false,\n          error: \"אין לך הרשאה לבצע פעולה זו - נדרשות הרשאות מנהל\",\n        };\n      }\n\n      // 2. Get target user info\n      const { rows: targetUser } = await client.query(\n        `SELECT id, name, email, roles, parent_manager_id FROM user_profiles WHERE id = $1`,\n        [targetUserId],\n      );\n\n      if (targetUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // CRITICAL: Protect root admin (from env)\n      const rootEmail = this.getRootAdminEmail();\n      if (\n        rootEmail &&\n        (targetUser[0].email || \"\").toLowerCase().trim() === rootEmail\n      ) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[promoteToAdmin] ❌ BLOCKED: Attempt to modify root admin`,\n        );\n        return {\n          success: false,\n          error: \"לא ניתן לשנות הרשאות למנהל הראשי - הוא המנהל הראשי\",\n        };\n      }\n\n      const targetIsAlreadyAdmin =\n        (targetUser[0].roles || []).includes(\"admin\") ||\n        (targetUser[0].roles || []).includes(\"super_admin\");\n\n      // 3. Check if target is already an admin under someone else\n      if (targetIsAlreadyAdmin && targetUser[0].parent_manager_id) {\n        if (targetUser[0].parent_manager_id !== requestingAdminId) {\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: \"משתמש זה כבר מנהל תחת מישהו אחר - לא ניתן להעביר\",\n          };\n        }\n        // Already an admin under requesting admin - nothing to do\n        await client.query(\"ROLLBACK\");\n        return { success: true, message: \"משתמש זה כבר מנהל תחתיך\" };\n      }\n\n      // 4. Check if target is in the management chain above the requesting admin\n      // (Cannot promote your own manager or their managers)\n      if (!isSuperAdmin) {\n        const { rows: chainCheck } = await client.query(\n          `\n          WITH RECURSIVE manager_chain AS (\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100\n          )\n          SELECT 1 FROM manager_chain WHERE id = $2 LIMIT 1\n        `,\n          [requestingAdminId, targetUserId],\n        );\n\n        if (chainCheck.length > 0) {\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: \"לא ניתן להפוך את המנהל שלך או מנהלים מעליו למנהל תחתיך\",\n          };\n        }\n      }\n\n      // 5. All checks passed - promote the user to admin\n      // Add 'admin' role (and 'volunteer' if not exists - every manager is also a volunteer)\n      const currentRoles = Array.isArray(targetUser[0].roles)\n        ? targetUser[0].roles\n        : [];\n      // Ensure unique roles and add admin + volunteer\n      const uniqueRoles = new Set(currentRoles);\n      uniqueRoles.add(\"admin\");\n      uniqueRoles.add(\"volunteer\"); // Every manager is also a volunteer\n      const newRoles = Array.from(uniqueRoles);\n\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET roles = $1::text[], parent_manager_id = $2, updated_at = NOW()\n        WHERE id = $3\n      `,\n        [newRoles, requestingAdminId, targetUserId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Invalidate caches to ensure fresh data on next request\n      await this.redisCache.delete(`user_profile_${targetUserId}`);\n      await this.redisCache.delete(`user_profile_${requestingAdminId}`);\n      await this.redisCache.invalidatePattern(\"users_list*\");\n      this.logger.log(\n        `[promoteToAdmin] ♻️ Invalidated cache for users ${targetUserId} and ${requestingAdminId}`,\n      );\n\n      this.logger.log(\n        `✅ User ${targetUserId} promoted to admin under ${requestingAdminId}`,\n      );\n      this.logger.log(\n        `[promoteToAdmin] 📊 Updated: roles=${JSON.stringify(newRoles)}, parent_manager_id=${requestingAdminId}`,\n      );\n\n      return {\n        success: true,\n        message: `${targetUser[0].name || targetUser[0].email} הפך למנהל תחתיך`,\n      };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Promote to admin error:\", error);\n      return { success: false, error: \"Failed to promote user to admin\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Demote an admin to regular user or volunteer (remove admin role)\n   * POST /api/users/:id/demote-admin\n   * Body: { requestingAdminId: string, convertToVolunteer?: boolean }\n   *\n   * Rules:\n   * 1. The requesting admin must be an admin\n   * 2. Can only demote admins that are YOUR subordinates\n   * 3. Super admin can demote anyone except themselves\n   * 4. If convertToVolunteer is true, user becomes volunteer under requesting admin\n   */\n  @Post(\":id/demote-admin\")\n  @UseGuards(JwtAuthGuard)\n  async demoteAdmin(\n    @Param(\"id\") targetUserId: string,\n    @Body() body: { requestingAdminId: string; convertToVolunteer?: boolean },\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const { requestingAdminId, convertToVolunteer = false } = body;\n\n      this.logger.log(\n        `[demoteAdmin] 📝 Request: targetUserId=${targetUserId}, requestingAdminId=${requestingAdminId}, convertToVolunteer=${convertToVolunteer}`,\n      );\n\n      if (!requestingAdminId) {\n        return { success: false, error: \"requestingAdminId is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // 1. Verify requesting user exists and is an admin\n      const { rows: requestingUser } = await client.query(\n        `SELECT id, email, roles FROM user_profiles WHERE id = $1`,\n        [requestingAdminId],\n      );\n\n      this.logger.log(`[demoteAdmin] 🔍 Requesting user lookup:`, {\n        requestingAdminId,\n        found: requestingUser.length > 0,\n        user: requestingUser[0] || null,\n      });\n\n      if (requestingUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[demoteAdmin] ❌ Requesting user not found: ${requestingAdminId}`,\n        );\n        return { success: false, error: \"Requesting user not found\" };\n      }\n\n      const isSuperAdmin = (requestingUser[0].roles || []).includes(\n        \"super_admin\",\n      );\n      const isAdmin =\n        (requestingUser[0].roles || []).includes(\"admin\") || isSuperAdmin;\n\n      this.logger.log(`[demoteAdmin] 🔐 Authorization check:`, {\n        email: requestingUser[0].email,\n        roles: requestingUser[0].roles,\n        isSuperAdmin,\n        isAdmin,\n      });\n\n      if (!isAdmin) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(`[demoteAdmin] ❌ Authorization denied - not an admin`);\n        return {\n          success: false,\n          error: \"אין לך הרשאה לבצע פעולה זו - נדרשות הרשאות מנהל\",\n        };\n      }\n\n      // 2. Get target user info\n      const { rows: targetUser } = await client.query(\n        `SELECT id, name, email, roles, parent_manager_id FROM user_profiles WHERE id = $1`,\n        [targetUserId],\n      );\n\n      if (targetUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // CRITICAL: Protect root admin (from env)\n      const rootEmail = this.getRootAdminEmail();\n      if (\n        rootEmail &&\n        (targetUser[0].email || \"\").toLowerCase().trim() === rootEmail\n      ) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[demoteAdmin] ❌ BLOCKED: Attempt to modify root admin`,\n        );\n        return {\n          success: false,\n          error: \"לא ניתן לשנות הרשאות למנהל הראשי - הוא המנהל הראשי\",\n        };\n      }\n\n      // 3. Check authorization - can only demote your own subordinates\n      if (!isSuperAdmin) {\n        // Check if target is a direct subordinate OR in the subordinate tree\n        const { rows: subordinateCheck } = await client.query(\n          `\n          WITH RECURSIVE subordinates AS (\n            SELECT id, 1 as depth FROM user_profiles WHERE parent_manager_id = $1\n            UNION ALL\n            SELECT u.id, s.depth + 1\n            FROM user_profiles u\n            INNER JOIN subordinates s ON u.parent_manager_id = s.id\n            WHERE s.depth < 100\n          )\n          SELECT 1 FROM subordinates WHERE id = $2 LIMIT 1\n        `,\n          [requestingAdminId, targetUserId],\n        );\n\n        if (subordinateCheck.length === 0) {\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: \"ניתן להסיר הרשאות מנהל רק ממנהלים שתחתיך\",\n          };\n        }\n      }\n\n      // 4. Remove admin role and handle conversion\n      const currentRoles = Array.isArray(targetUser[0].roles)\n        ? targetUser[0].roles\n        : [];\n      const hasParentManager = !!targetUser[0].parent_manager_id;\n\n      // Remove admin and super_admin roles\n      let newRoles = currentRoles.filter(\n        (r: string) => r !== \"admin\" && r !== \"super_admin\",\n      );\n\n      let newParentManagerId: string | null = null;\n\n      if (convertToVolunteer) {\n        // Convert to volunteer: set parent_manager_id to requesting admin and add volunteer role\n        newParentManagerId = requestingAdminId;\n        if (!newRoles.includes(\"volunteer\")) {\n          newRoles.push(\"volunteer\");\n        }\n        this.logger.log(\n          `[demoteAdmin] 🔄 Converting to volunteer under ${requestingAdminId}`,\n        );\n      } else {\n        // Regular demotion: if no parent_manager_id, remove volunteer role (becomes regular user)\n        // If has parent_manager_id, keep it and keep volunteer role (they're still a volunteer)\n        if (!hasParentManager) {\n          newRoles = newRoles.filter((r: string) => r !== \"volunteer\");\n          newParentManagerId = null;\n        } else {\n          // Keep existing parent_manager_id and volunteer role\n          newParentManagerId = targetUser[0].parent_manager_id;\n          if (!newRoles.includes(\"volunteer\")) {\n            newRoles.push(\"volunteer\");\n          }\n        }\n      }\n\n      this.logger.log(\n        `[demoteAdmin] 📝 Before UPDATE: target=${targetUserId}, hasParent=${hasParentManager}, convertToVolunteer=${convertToVolunteer}, currentRoles=${JSON.stringify(currentRoles)}, newRoles=${JSON.stringify(newRoles)}, newParentManagerId=${newParentManagerId}`,\n      );\n\n      // Update: remove admin roles, set parent_manager_id, and update volunteer role\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET roles = $1::text[], \n            parent_manager_id = $2,\n            updated_at = NOW()\n        WHERE id = $3\n      `,\n        [newRoles, newParentManagerId, targetUserId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Invalidate caches to ensure fresh data on next request\n      await this.redisCache.delete(`user_profile_${targetUserId}`);\n      await this.redisCache.delete(`user_profile_${requestingAdminId}`);\n      await this.redisCache.invalidatePattern(\"users_list*\");\n      this.logger.log(\n        `[demoteAdmin] ♻️ Invalidated cache for users ${targetUserId} and ${requestingAdminId}`,\n      );\n\n      this.logger.log(\n        `✅ User ${targetUserId} demoted from admin by ${requestingAdminId}`,\n      );\n      this.logger.log(\n        `[demoteAdmin] 📊 Updated: roles=${JSON.stringify(newRoles)}, parent_manager_id=${newParentManagerId}`,\n      );\n\n      const message = convertToVolunteer\n        ? `הרשאות מנהל הוסרו מ-${targetUser[0].name || targetUser[0].email} והוא הפך למתנדב`\n        : `הרשאות מנהל הוסרו מ-${targetUser[0].name || targetUser[0].email}`;\n\n      return {\n        success: true,\n        message,\n      };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Demote admin error:\", error);\n      return { success: false, error: \"Failed to demote admin\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Promote a user to volunteer role\n   * POST /api/users/:id/promote-volunteer\n   * Body: { requestingAdminId: string }\n   *\n   * Rules:\n   * 1. The requesting admin must be a manager (hierarchy_level >= 1)\n   * 2. The target user must NOT already be a volunteer under someone else\n   * 3. The target user will be set as subordinate of the requesting admin\n   * 4. Adds 'volunteer' role (keeps 'admin' if exists)\n   */\n  @Post(\":id/promote-volunteer\")\n  @UseGuards(JwtAuthGuard)\n  async promoteToVolunteer(\n    @Param(\"id\") targetUserId: string,\n    @Body() body: { requestingAdminId: string },\n  ) {\n    const client = await this.pool.connect();\n    try {\n      const { requestingAdminId } = body;\n\n      this.logger.log(\n        `[promoteToVolunteer] 📝 Request: targetUserId=${targetUserId}, requestingAdminId=${requestingAdminId}`,\n      );\n\n      if (!requestingAdminId) {\n        return { success: false, error: \"requestingAdminId is required\" };\n      }\n\n      await client.query(\"BEGIN\");\n\n      // 1. Verify requesting user exists and is a manager\n      let requestingUser: any[];\n      try {\n        const result = await client.query(\n          `SELECT id, email, roles, hierarchy_level FROM user_profiles WHERE id = $1`,\n          [requestingAdminId],\n        );\n        requestingUser = result.rows;\n      } catch (error: any) {\n        // Fallback: if hierarchy_level column doesn't exist yet\n        if (error.message && error.message.includes(\"hierarchy_level\")) {\n          const result = await client.query(\n            `SELECT id, email, roles FROM user_profiles WHERE id = $1`,\n            [requestingAdminId],\n          );\n          requestingUser = result.rows.map((row: any) => ({\n            ...row,\n            hierarchy_level: null,\n          }));\n        } else {\n          throw error;\n        }\n      }\n\n      if (requestingUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"Requesting user not found\" };\n      }\n\n      // SEC-003.1: Use RBAC roles instead of hardcoded emails\n      const isSuperAdmin = (requestingUser[0].roles || []).includes(\n        \"super_admin\",\n      );\n      const isAdmin =\n        (requestingUser[0].roles || []).includes(\"admin\") || isSuperAdmin;\n      const hierarchyLevel = requestingUser[0].hierarchy_level;\n\n      // Only managers (hierarchy_level >= 1) can promote to volunteer\n      // If hierarchy_level is null (migration not run), allow if isAdmin\n      if (!isAdmin || (hierarchyLevel === null && !isSuperAdmin && !isAdmin)) {\n        await client.query(\"ROLLBACK\");\n        return {\n          success: false,\n          error: \"אין לך הרשאה לבצע פעולה זו - נדרשות הרשאות מנהל\",\n        };\n      }\n\n      // 2. Get target user info\n      let targetUser: any[];\n      try {\n        const result = await client.query(\n          `SELECT id, name, email, roles, parent_manager_id, hierarchy_level FROM user_profiles WHERE id = $1`,\n          [targetUserId],\n        );\n        targetUser = result.rows;\n      } catch (error: any) {\n        // Fallback: if hierarchy_level column doesn't exist yet\n        if (error.message && error.message.includes(\"hierarchy_level\")) {\n          const result = await client.query(\n            `SELECT id, name, email, roles, parent_manager_id FROM user_profiles WHERE id = $1`,\n            [targetUserId],\n          );\n          targetUser = result.rows.map((row: any) => ({\n            ...row,\n            hierarchy_level: null,\n          }));\n        } else {\n          throw error;\n        }\n      }\n\n      if (targetUser.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      // CRITICAL: Protect root admin — use env var, not hardcoded email\n      const rootEmail = this.getRootAdminEmail();\n      if (rootEmail && targetUser[0].email === rootEmail) {\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\n          `[promoteToVolunteer] ❌ BLOCKED: Attempt to modify root admin (${rootEmail})`,\n        );\n        return {\n          success: false,\n          error: \"לא ניתן לשנות הרשאות למנהל הראשי - הוא המנהל הראשי\",\n        };\n      }\n\n      // SEC-003.1: Use RBAC roles instead of hardcoded emails\n\n      // 3. Check if target is already a volunteer under someone else\n      const targetIsVolunteer = (targetUser[0].roles || []).includes(\n        \"volunteer\",\n      );\n      if (\n        targetIsVolunteer &&\n        targetUser[0].parent_manager_id &&\n        targetUser[0].parent_manager_id !== requestingAdminId\n      ) {\n        await client.query(\"ROLLBACK\");\n        return {\n          success: false,\n          error: \"משתמש זה כבר מתנדב תחת מישהו אחר - לא ניתן להעביר\",\n        };\n      }\n\n      // 4. Check for cycles (same as promoteToAdmin)\n      if (!isSuperAdmin) {\n        const { rows: chainCheck } = await client.query(\n          `\n          WITH RECURSIVE manager_chain AS (\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100\n          )\n          SELECT 1 FROM manager_chain WHERE id = $2 LIMIT 1\n        `,\n          [requestingAdminId, targetUserId],\n        );\n\n        if (chainCheck.length > 0) {\n          await client.query(\"ROLLBACK\");\n          return {\n            success: false,\n            error: \"לא ניתן להפוך את המנהל שלך או מנהלים מעליו למתנדב תחתיך\",\n          };\n        }\n      }\n\n      // 5. All checks passed - promote to volunteer\n      const currentRoles = Array.isArray(targetUser[0].roles)\n        ? targetUser[0].roles\n        : [];\n      const uniqueRoles = new Set(currentRoles);\n      uniqueRoles.add(\"volunteer\");\n      const newRoles = Array.from(uniqueRoles);\n\n      // Set parent_manager_id and add volunteer role\n      // hierarchy_level will be calculated automatically by trigger\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET roles = $1::text[], parent_manager_id = $2, updated_at = NOW()\n        WHERE id = $3\n      `,\n        [newRoles, requestingAdminId, targetUserId],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Invalidate caches\n      await this.redisCache.delete(`user_profile_${targetUserId}`);\n      await this.redisCache.delete(`user_profile_${requestingAdminId}`);\n      await this.redisCache.invalidatePattern(\"users_list*\");\n      this.logger.log(\n        `[promoteToVolunteer] ♻️ Invalidated cache for users ${targetUserId} and ${requestingAdminId}`,\n      );\n\n      this.logger.log(\n        `✅ User ${targetUserId} promoted to volunteer under ${requestingAdminId}`,\n      );\n      this.logger.log(\n        `[promoteToVolunteer] 📊 Updated: roles=${JSON.stringify(newRoles)}, parent_manager_id=${requestingAdminId}`,\n      );\n\n      return {\n        success: true,\n        message: `${targetUser[0].name || targetUser[0].email} הפך למתנדב תחתיך`,\n      };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Promote to volunteer error:\", error);\n      return { success: false, error: \"Failed to promote user to volunteer\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get users eligible for admin promotion by a specific admin\n   * GET /api/users/eligible-for-promotion/:adminId\n   * Returns users that can be promoted by this admin\n   */\n  @Get(\"eligible-for-promotion/:adminId\")\n  async getEligibleForPromotion(@Param(\"adminId\") adminId: string) {\n    try {\n      // Get admin info\n      const { rows: adminRows } = await this.pool.query(\n        `SELECT id, email, roles FROM user_profiles WHERE id = $1`,\n        [adminId],\n      );\n\n      if (adminRows.length === 0) {\n        return { success: false, error: \"Admin not found\" };\n      }\n\n      // SEC-003.1: Use RBAC roles instead of hardcoded emails\n      const isSuperAdmin = (adminRows[0].roles || []).includes(\"super_admin\");\n\n      // Get all users who are NOT:\n      // 1. The requesting admin themselves\n      // 2. Already admins under someone else (unless super admin)\n      // 3. In the management chain above the requesting admin\n      // 4. Super admin\n\n      let query: string;\n      let params: any[];\n\n      if (isSuperAdmin) {\n        // Super admin can promote anyone who isn't already an admin OR is an orphan admin\n        query = `\n          SELECT id, name, email, avatar_url, roles, parent_manager_id\n          FROM user_profiles\n          WHERE id != $1\n          AND email NOT IN ('navesarussi@gmail.com', 'karmacommunity2.0@gmail.com')\n          AND (\n            -- Not an admin yet\n            NOT ('admin' = ANY(roles) OR 'super_admin' = ANY(roles))\n            -- OR is an admin without a parent (orphan admin - can be reassigned)\n            OR (('admin' = ANY(roles) OR 'super_admin' = ANY(roles)) AND parent_manager_id IS NULL)\n          )\n          ORDER BY name\n        `;\n        params = [adminId];\n      } else {\n        // Regular admins can only promote users who:\n        // - Are not admins yet\n        // - Are not in their management chain above them\n        query = `\n          WITH RECURSIVE manager_chain AS (\n            -- Get all managers above requesting admin\n            SELECT id, parent_manager_id, 1 as depth\n            FROM user_profiles\n            WHERE id = $1\n            \n            UNION ALL\n            \n            SELECT u.id, u.parent_manager_id, mc.depth + 1\n            FROM user_profiles u\n            INNER JOIN manager_chain mc ON u.id = mc.parent_manager_id\n            WHERE mc.depth < 100\n          )\n          SELECT u.id, u.name, u.email, u.avatar_url, u.roles, u.parent_manager_id\n          FROM user_profiles u\n          WHERE u.id != $1\n          AND u.email NOT IN ('navesarussi@gmail.com', 'karmacommunity2.0@gmail.com')\n          -- Not already an admin under someone else\n          AND NOT (\n            ('admin' = ANY(u.roles) OR 'super_admin' = ANY(u.roles))\n            AND u.parent_manager_id IS NOT NULL\n            AND u.parent_manager_id != $1\n          )\n          -- Not in management chain above\n          AND u.id NOT IN (SELECT id FROM manager_chain)\n          ORDER BY u.name\n        `;\n        params = [adminId];\n      }\n\n      const { rows } = await this.pool.query(query, params);\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Get eligible for promotion error:\", error);\n      return { success: false, error: \"Failed to get eligible users\" };\n    }\n  }\n\n  /**\n   * Get full admin hierarchy tree starting from super admin\n   * GET /api/users/hierarchy/tree\n   * Returns a nested tree structure of all managers\n   * NOTE: This route MUST be defined BEFORE :id/hierarchy to avoid route conflict\n   */\n  @Get(\"hierarchy/tree\")\n  async getFullHierarchyTree() {\n    try {\n      // Ensure columns exist before querying\n      await this.ensureSalarySeniorityColumns();\n\n      // First, get the ROOT admin (karmacommunity2.0@gmail.com) - the KING\n      const { rows: rootAdminRows } = await this.pool.query(`\n        SELECT id, name, email, avatar_url, roles\n        FROM user_profiles\n        WHERE email = 'karmacommunity2.0@gmail.com'\n        LIMIT 1\n      `);\n\n      if (rootAdminRows.length === 0) {\n        return {\n          success: false,\n          error: \"Root admin (karmacommunity2.0@gmail.com) not found\",\n        };\n      }\n\n      // Try query with salary/seniority fields, fallback if columns don't exist\n      let allUsers: any[];\n      try {\n        const result = await this.pool.query(`\n          WITH RECURSIVE hierarchy AS (\n            -- Base case: ROOT admin (karmacommunity2.0@gmail.com) - the KING\n            SELECT \n              id, name, email, avatar_url, \n              NULL::UUID as parent_manager_id,  -- CRITICAL: Root admin ALWAYS has NULL\n              roles, salary, seniority_start_date,\n              0 as level,\n              ARRAY[id] as path\n            FROM user_profiles\n            WHERE email = 'karmacommunity2.0@gmail.com'\n            \n            UNION ALL\n            \n            -- Recursive: all subordinates\n            SELECT \n              u.id, u.name, u.email, u.avatar_url, u.parent_manager_id, u.roles, u.salary, u.seniority_start_date,\n              h.level + 1,\n              h.path || u.id\n            FROM user_profiles u\n            INNER JOIN hierarchy h ON u.parent_manager_id = h.id\n            WHERE h.level < 10  -- Max depth to prevent infinite loops\n              AND u.email != 'karmacommunity2.0@gmail.com'  -- Prevent root admin from appearing twice\n          )\n          SELECT \n            id::text as id, \n            COALESCE(name, 'ללא שם') as name, \n            email, \n            avatar_url, \n            parent_manager_id::text as parent_manager_id, \n            roles,\n            level,\n            COALESCE(salary, 0) as salary,\n            COALESCE(seniority_start_date::text, CURRENT_DATE::text) as seniority_start_date,\n            CASE WHEN email = 'karmacommunity2.0@gmail.com' THEN true \n                 WHEN email = 'navesarussi@gmail.com' THEN true \n                 ELSE false END as is_super_admin\n          FROM hierarchy\n          ORDER BY level, name\n        `);\n        allUsers = result.rows;\n      } catch (error: any) {\n        // If columns don't exist, use query without them\n        if (error.message && error.message.includes(\"salary\")) {\n          this.logger.warn(\n            \"Salary/seniority columns not found, using fallback query\",\n          );\n          const result = await this.pool.query(`\n            WITH RECURSIVE hierarchy AS (\n              -- Base case: ROOT admin (karmacommunity2.0@gmail.com) - the KING\n              SELECT \n                id, name, email, avatar_url, \n                NULL::UUID as parent_manager_id,  -- CRITICAL: Root admin ALWAYS has NULL\n                roles,\n                0::DECIMAL(10,2) as salary,\n                CURRENT_DATE::DATE as seniority_start_date,\n                0 as level,\n                ARRAY[id] as path\n              FROM user_profiles\n              WHERE email = 'karmacommunity2.0@gmail.com'\n              \n              UNION ALL\n              \n              -- Recursive: all subordinates\n              SELECT \n                u.id, u.name, u.email, u.avatar_url, u.parent_manager_id, u.roles,\n                0::DECIMAL(10,2) as salary,\n                CURRENT_DATE::DATE as seniority_start_date,\n                h.level + 1,\n                h.path || u.id\n              FROM user_profiles u\n              INNER JOIN hierarchy h ON u.parent_manager_id = h.id\n              WHERE h.level < 10  -- Max depth to prevent infinite loops\n                AND u.email != 'karmacommunity2.0@gmail.com'  -- Prevent root admin from appearing twice\n            )\n            SELECT \n              id::text as id, \n              COALESCE(name, 'ללא שם') as name, \n              email, \n              avatar_url, \n              parent_manager_id::text as parent_manager_id, \n              roles,\n              level,\n              0 as salary,\n              CURRENT_DATE::text as seniority_start_date,\n              CASE WHEN email = 'karmacommunity2.0@gmail.com' THEN true \n                   WHEN email = 'navesarussi@gmail.com' THEN true \n                   ELSE false END as is_super_admin\n            FROM hierarchy\n            ORDER BY level, name\n          `);\n          allUsers = result.rows;\n        } else {\n          throw error;\n        }\n      }\n\n      // Build nested tree structure with cycle detection\n      // We use a Set to track visited IDs in the current branch\n      const buildTree = (\n        parentId: string | null,\n        level: number,\n        visitedIds: Set<string> = new Set(),\n      ): any[] => {\n        // Safety break for deep recursion\n        if (level > 20) return [];\n\n        return (\n          allUsers\n            .filter((user) => {\n              if (level === 0) {\n                // Root level: only the ROOT admin (karmacommunity2.0@gmail.com) - the KING\n                return user.email === \"karmacommunity2.0@gmail.com\";\n              }\n              return user.parent_manager_id === parentId;\n            })\n            // Filter out users we've already visited in this branch to prevent cycles\n            .filter((user) => !visitedIds.has(user.id))\n            .map((user) => {\n              // Create a new set for the next level including current user\n              const nextVisitedIds = new Set(visitedIds);\n              nextVisitedIds.add(user.id);\n\n              const userRoles = Array.isArray(user.roles) ? user.roles : [];\n              return {\n                id: user.id,\n                name: user.name,\n                email: user.email,\n                avatar_url: user.avatar_url,\n                level: user.level,\n                isSuperAdmin: user.is_super_admin,\n                isAdmin:\n                  userRoles.includes(\"admin\") ||\n                  userRoles.includes(\"super_admin\"),\n                isVolunteer:\n                  userRoles.includes(\"volunteer\") &&\n                  !(\n                    userRoles.includes(\"admin\") ||\n                    userRoles.includes(\"super_admin\")\n                  ),\n                salary: user.salary || 0,\n                seniority_start_date:\n                  user.seniority_start_date ||\n                  new Date().toISOString().split(\"T\")[0],\n                children: buildTree(user.id, level + 1, nextVisitedIds),\n              };\n            })\n        );\n      };\n\n      const tree = buildTree(null, 0);\n\n      this.logger.log(`🌳 Built hierarchy tree with ${allUsers.length} users`);\n\n      return {\n        success: true,\n        data: tree,\n        totalCount: allUsers.length,\n      };\n    } catch (error) {\n      this.logger.error(\"Get full hierarchy tree error:\", error);\n      return { success: false, error: \"Failed to get hierarchy tree\" };\n    }\n  }\n\n  /**\n   * Get direct subordinates and their sub-tree (hierarchy)\n   * GET /api/users/:id/hierarchy\n   */\n  @Get(\":id/hierarchy\")\n  async getUserHierarchy(@Param(\"id\") id: string) {\n    try {\n      // Recursive CTE to get full hierarchy\n      const { rows } = await this.pool.query(\n        `\n        WITH RECURSIVE subordinates AS (\n          -- Base case: direct subordinates\n          SELECT id, name, email, avatar_url, parent_manager_id, 1 as level\n          FROM user_profiles\n          WHERE parent_manager_id = $1\n          \n          UNION ALL\n          \n          -- Recursive member: subordinates of subordinates\n          SELECT u.id, u.name, u.email, u.avatar_url, u.parent_manager_id, s.level + 1\n          FROM user_profiles u\n          INNER JOIN subordinates s ON u.parent_manager_id = s.id\n        )\n        SELECT * FROM subordinates ORDER BY level, name\n      `,\n        [id],\n      );\n\n      return { success: true, data: rows };\n    } catch (error) {\n      this.logger.error(\"Get hierarchy error:\", error);\n      return { success: false, error: \"Failed to get hierarchy\" };\n    }\n  }\n  // ================================================================\n  // End Phase 2+ Admin Hierarchy & RBAC block\n  // ================================================================\n\n  @Post(\"register\")\n  async registerUser(@Body() userData: any) {\n    // TODO: Replace 'any' with proper DTO interface\n    // TODO: Add comprehensive input validation (email format, password strength)\n    // TODO: Add rate limiting to prevent spam registrations\n    // TODO: Add email verification flow before account activation\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      const normalizedEmail = userData.email.toLowerCase().trim();\n\n      // Check if user already exists in user_profiles table\n      const { rows: existingUsers } = await client.query(\n        `SELECT id FROM user_profiles WHERE LOWER(email) = LOWER($1) LIMIT 1`,\n        [normalizedEmail],\n      );\n\n      if (existingUsers.length > 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User already exists\" };\n      }\n\n      // Hash password if provided\n      let passwordHash = null;\n      if (userData.password) {\n        passwordHash = await argon2.hash(userData.password);\n      }\n\n      const PRE_APPROVED_ADMINS = [\n        \"mahalalel100@gmail.com\",\n        \"matan7491@gmail.com\",\n        \"ichai1306@gmail.com\",\n        \"lianbh2004@gmail.com\",\n        \"navesarussi@gmail.com\",\n        \"karmacommunity2.0@gmail.com\",\n      ];\n\n      const shouldBeAdmin = PRE_APPROVED_ADMINS.includes(normalizedEmail);\n      const initialRoles = shouldBeAdmin ? [\"user\", \"admin\"] : [\"user\"];\n\n      const nowIso = new Date().toISOString();\n      // Insert user into user_profiles table with UUID\n      // Include firebase_uid if provided (for Firebase authentication)\n      const { rows: newUser } = await client.query(\n        `\n        INSERT INTO user_profiles (\n          email, name, phone, avatar_url, bio, password_hash,\n          karma_points, join_date, is_active, last_active,\n          city, country, interests, roles, email_verified, settings, firebase_uid\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::text[], $14::text[], $15, $16::jsonb, $17)\n        RETURNING id\n      `,\n        [\n          normalizedEmail,\n          userData.name || normalizedEmail.split(\"@\")[0],\n          userData.phone || \"+9720000000\",\n          userData.avatar_url ||\n            `https://ui-avatars.com/api/?name=${encodeURIComponent(userData.name || \"User\")}&background=random`,\n          userData.bio || \"משתמש חדש בקארמה קומיוניטי\",\n          passwordHash,\n          0, // karma_points\n          nowIso, // join_date\n          true, // is_active\n          nowIso, // last_active\n          userData.city || \"ישראל\", // city\n          userData.country || \"Israel\", // country\n          userData.interests || [], // interests\n          initialRoles, // roles\n          false, // email_verified\n          JSON.stringify(\n            userData.settings || {\n              language: \"he\",\n              dark_mode: false,\n              notifications_enabled: true,\n              privacy: \"public\",\n            },\n          ), // settings\n          userData.firebase_uid || userData.id || null, // firebase_uid - use id if it's a Firebase UID\n        ],\n      );\n\n      const userId = newUser[0].id;\n\n      await client.query(\"COMMIT\");\n\n      // Clear statistics cache when new user is registered\n      // This ensures totalUsers and other user-related stats are refreshed immediately\n      await this.redisCache.clearStatsCaches();\n\n      // Fetch the created user to return full data\n      const { rows: createdUser } = await client.query(\n        `SELECT id, email, name, phone, avatar_url, bio, city, country, interests, roles, settings, created_at, parent_manager_id\n         FROM user_profiles WHERE id = $1`,\n        [userId],\n      );\n\n      // Return user data in the expected format\n      const user = {\n        id: createdUser[0].id,\n        email: createdUser[0].email,\n        name: createdUser[0].name,\n        phone: createdUser[0].phone,\n        avatar_url: createdUser[0].avatar_url,\n        bio: createdUser[0].bio || \"\",\n        karma_points: 0,\n        join_date: createdUser[0].created_at,\n        is_active: true,\n        last_active: nowIso,\n        city: createdUser[0].city || \"\",\n        country: createdUser[0].country || \"Israel\",\n        interests: createdUser[0].interests || [],\n        roles: createdUser[0].roles || [\"user\"],\n        posts_count: 0,\n        followers_count: 0,\n        following_count: 0,\n        total_donations_amount: 0,\n        total_volunteer_hours: 0,\n        email_verified: false,\n        parent_manager_id: createdUser[0].parent_manager_id || null,\n        settings: createdUser[0].settings || {},\n      };\n\n      return { success: true, data: user };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Register user error:\", error);\n      return { success: false, error: \"Failed to register user\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Post(\"login\")\n  async loginUser(@Body() loginData: any) {\n    try {\n      const normalizedEmail = loginData.email.toLowerCase().trim();\n\n      // Use user_profiles table\n      const { rows } = await this.pool.query(\n        `SELECT id, email, name, phone, avatar_url, bio, password_hash, \n                karma_points, join_date, is_active, last_active, parent_manager_id,\n                city, country, interests, roles, settings, created_at\n         FROM user_profiles WHERE LOWER(email) = LOWER($1) LIMIT 1`,\n        [normalizedEmail],\n      );\n\n      if (rows.length === 0) {\n        return { success: false, error: \"User not found\" };\n      }\n\n      const user = rows[0];\n\n      // Auto-grant admin role for pre-approved emails (Self-healing)\n      const PRE_APPROVED_ADMINS = [\n        \"mahalalel100@gmail.com\",\n        \"matan7491@gmail.com\",\n        \"ichai1306@gmail.com\",\n        \"lianbh2004@gmail.com\",\n        \"navesarussi@gmail.com\",\n        \"karmacommunity2.0@gmail.com\",\n      ];\n\n      const shouldBeAdmin = PRE_APPROVED_ADMINS.includes(normalizedEmail);\n      const currentRoles: string[] = user.roles || [];\n\n      if (shouldBeAdmin && !currentRoles.includes(\"admin\")) {\n        await this.pool.query(\n          `UPDATE user_profiles SET roles = array_append(roles, 'admin') WHERE id = $1`,\n          [user.id],\n        );\n        user.roles = [...currentRoles, \"admin\"];\n      }\n\n      // Verify password if provided\n      if (loginData.password && user.password_hash) {\n        const isValid = await argon2.verify(\n          user.password_hash,\n          loginData.password,\n        );\n        if (!isValid) {\n          return { success: false, error: \"Invalid password\" };\n        }\n      }\n\n      // Update last active\n      await this.pool.query(\n        `UPDATE user_profiles SET last_active = NOW(), updated_at = NOW() WHERE id = $1`,\n        [user.id],\n      );\n\n      // Return user data in the expected format\n      const userResponse = {\n        id: user.id,\n        email: user.email,\n        name: user.name,\n        phone: user.phone,\n        avatar_url: user.avatar_url,\n        bio: user.bio || \"\",\n        karma_points: user.karma_points || 0,\n        join_date: user.join_date || user.created_at,\n        is_active: user.is_active !== false,\n        last_active: new Date().toISOString(),\n        city: user.city || \"\",\n        country: user.country || \"Israel\",\n        interests: user.interests || [],\n        roles: user.roles || [\"user\"],\n        posts_count: 0, // TODO: Calculate from actual data\n        followers_count: 0, // TODO: Calculate from actual data\n        following_count: 0, // TODO: Calculate from actual data\n        total_donations_amount: 0,\n        total_volunteer_hours: 0,\n        email_verified: user.email_verified || false,\n        parent_manager_id: user.parent_manager_id || null,\n        settings: user.settings || {},\n      };\n\n      return { success: true, data: userResponse };\n    } catch (error) {\n      this.logger.error(\"Login user error:\", error);\n      return { success: false, error: \"Login failed\" };\n    }\n  }\n\n  @Get(\":id\")\n  async getUserById(@Param(\"id\") id: string) {\n    try {\n      this.logger.log(`[UsersController] getUserById called with id: ${id}`);\n\n      // Normalize email to lowercase for consistent lookup\n      // This matches the normalization used in auth.controller.ts\n      const normalizedId = id.includes(\"@\")\n        ? String(id).trim().toLowerCase()\n        : id;\n\n      this.logger.log(`[UsersController] Normalized id: ${normalizedId}`);\n\n      const cacheKey = `user_profile_${normalizedId}`;\n\n      // Try to get from cache, but handle Redis errors gracefully\n      let cached = null;\n      try {\n        cached = await this.redisCache.get(cacheKey);\n        if (cached) {\n          this.logger.log(`[UsersController] Cache hit for ${normalizedId}`);\n          return { success: true, data: cached };\n        }\n        this.logger.log(`[UsersController] Cache miss for ${normalizedId}`);\n      } catch (cacheError) {\n        this.logger.warn(\n          `[UsersController] Redis cache error (non-fatal):`,\n          cacheError,\n        );\n        // Continue without cache - don't fail the request\n      }\n\n      // Use user_profiles table - support UUID, email, firebase_uid, or google_id lookups\n      this.logger.log(\n        `[UsersController] Querying database for ${normalizedId}`,\n      );\n\n      // Try query with google_id first, if it fails (column doesn't exist), try without it\n      let rows: any[];\n      try {\n        const result = await this.pool.query(\n          `\n          SELECT \n            id,\n            email,\n            COALESCE(name, 'ללא שם') as name,\n            phone,\n            COALESCE(avatar_url, '') as avatar_url,\n            COALESCE(bio, '') as bio,\n            -- CRITICAL: Root admin ALWAYS has parent_manager_id = NULL\n            CASE \n              WHEN email = 'karmacommunity2.0@gmail.com' THEN NULL\n              ELSE parent_manager_id\n            END as parent_manager_id,\n            COALESCE(karma_points, 0) as karma_points,\n            COALESCE(join_date, created_at) as join_date,\n            COALESCE(is_active, true) as is_active,\n            COALESCE(last_active, updated_at) as last_active,\n            COALESCE(city, '') as city,\n            COALESCE(country, 'Israel') as country,\n            COALESCE(interests, ARRAY[]::TEXT[]) as interests,\n            COALESCE(roles, ARRAY['user']::TEXT[]) as roles,\n            COALESCE(posts_count, 0) as posts_count,\n            COALESCE(followers_count, 0) as followers_count,\n            COALESCE(following_count, 0) as following_count,\n            0 as total_donations_amount,\n            0 as total_volunteer_hours,\n            COALESCE(email_verified, false) as email_verified,\n            COALESCE(settings, '{}'::jsonb) as settings\n          FROM user_profiles \n          WHERE id::text = $1 \n             OR LOWER(email) = LOWER($1)\n             OR firebase_uid = $1\n             OR google_id = $1\n          LIMIT 1\n        `,\n          [normalizedId],\n        );\n        rows = result.rows;\n        this.logger.log(\n          `[UsersController] Database query returned ${rows.length} rows`,\n        );\n      } catch (error: any) {\n        // If google_id column doesn't exist, try without it\n        if (error.message && error.message.includes(\"google_id\")) {\n          this.logger.log(\n            `[UsersController] Retrying query without google_id column`,\n          );\n          const result = await this.pool.query(\n            `\n            SELECT \n              id,\n              email,\n              COALESCE(name, 'ללא שם') as name,\n              phone,\n              COALESCE(avatar_url, '') as avatar_url,\n              COALESCE(bio, '') as bio,\n              -- CRITICAL: Root admin ALWAYS has parent_manager_id = NULL\n              CASE \n                WHEN email = 'karmacommunity2.0@gmail.com' THEN NULL\n                ELSE parent_manager_id\n              END as parent_manager_id,\n              COALESCE(karma_points, 0) as karma_points,\n              COALESCE(join_date, created_at) as join_date,\n              COALESCE(is_active, true) as is_active,\n              COALESCE(last_active, updated_at) as last_active,\n              COALESCE(city, '') as city,\n              COALESCE(country, 'Israel') as country,\n              COALESCE(interests, ARRAY[]::TEXT[]) as interests,\n              COALESCE(roles, ARRAY['user']::TEXT[]) as roles,\n              COALESCE(posts_count, 0) as posts_count,\n              COALESCE(followers_count, 0) as followers_count,\n              COALESCE(following_count, 0) as following_count,\n              0 as total_donations_amount,\n              0 as total_volunteer_hours,\n              COALESCE(email_verified, false) as email_verified,\n              COALESCE(settings, '{}'::jsonb) as settings\n            FROM user_profiles \n            WHERE id::text = $1 \n               OR LOWER(email) = LOWER($1)\n               OR firebase_uid = $1\n            LIMIT 1\n          `,\n            [normalizedId],\n          );\n          rows = result.rows;\n          this.logger.log(\n            `[UsersController] Retry query returned ${rows.length} rows`,\n          );\n        } else {\n          throw error;\n        }\n      }\n\n      if (rows.length === 0) {\n        this.logger.log(`[UsersController] User not found for ${normalizedId}`);\n        return { success: false, error: \"User not found\" };\n      }\n\n      const user = rows[0];\n      this.logger.log(\n        `[UsersController] User found: ${user.email} (${user.id})`,\n      );\n\n      // Try to cache the result, but don't fail if Redis is down\n      try {\n        await this.redisCache.set(cacheKey, user, this.CACHE_TTL);\n        this.logger.log(`[UsersController] User cached successfully`);\n      } catch (cacheError) {\n        this.logger.warn(\n          `[UsersController] Failed to cache user (non-fatal):`,\n          cacheError,\n        );\n        // Continue - caching failure shouldn't fail the request\n      }\n\n      return { success: true, data: user };\n    } catch (error: any) {\n      this.logger.error(\n        `[UsersController] getUserById error for id ${id}:`,\n        error,\n      );\n      this.logger.error(`[UsersController] Error stack:`, error?.stack);\n      return {\n        success: false,\n        error: \"Failed to get user\",\n        details: error?.message || \"Unknown error\",\n      };\n    }\n  }\n\n  @Put(\":id\")\n  @UseGuards(JwtAuthGuard)\n  async updateUser(@Param(\"id\") id: string, @Body() updateData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Get existing user data from user_profiles\n      const { rows: existingRows } = await client.query(\n        `\n        SELECT id, email, name, phone, avatar_url, bio, password_hash,\n               city, country, interests, settings, roles, created_at\n        FROM user_profiles \n        WHERE id::text = $1 OR LOWER(email) = LOWER($1) OR firebase_uid = $1 OR google_id = $1\n        LIMIT 1\n      `,\n        [id],\n      );\n\n      if (existingRows.length === 0) {\n        await client.query(\"ROLLBACK\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      const existingUser = existingRows[0];\n      const userId = existingUser.id;\n\n      // CRITICAL: Protect root admin - karmacommunity2.0@gmail.com is the KING\n      if (existingUser.email === \"karmacommunity2.0@gmail.com\") {\n        // Allow updates to name, avatar, etc. but block changes to roles, parent_manager_id, hierarchy_level\n        if (\n          updateData.roles !== undefined ||\n          updateData.parent_manager_id !== undefined ||\n          updateData.hierarchy_level !== undefined\n        ) {\n          await client.query(\"ROLLBACK\");\n          this.logger.log(\n            `[updateUser] ❌ BLOCKED: Attempt to modify root admin roles/hierarchy (karmacommunity2.0@gmail.com)`,\n          );\n          return {\n            success: false,\n            error:\n              \"לא ניתן לשנות הרשאות או היררכיה למנהל הראשי - הוא המנהל הראשי\",\n          };\n        }\n      }\n\n      // Build update query dynamically\n      const updateFields: string[] = [];\n      const updateValues: any[] = [];\n      let paramCount = 1;\n\n      if (updateData.password) {\n        const passwordHash = await argon2.hash(updateData.password);\n        updateFields.push(`password_hash = $${paramCount++}`);\n        updateValues.push(passwordHash);\n      }\n      if (updateData.name !== undefined) {\n        updateFields.push(`name = $${paramCount++}`);\n        updateValues.push(updateData.name);\n      }\n      if (updateData.phone !== undefined) {\n        updateFields.push(`phone = $${paramCount++}`);\n        updateValues.push(updateData.phone);\n      }\n      if (updateData.avatar_url !== undefined) {\n        updateFields.push(`avatar_url = $${paramCount++}`);\n        updateValues.push(updateData.avatar_url);\n      }\n      if (updateData.bio !== undefined) {\n        updateFields.push(`bio = $${paramCount++}`);\n        updateValues.push(updateData.bio);\n      }\n      if (updateData.city !== undefined) {\n        updateFields.push(`city = $${paramCount++}`);\n        updateValues.push(updateData.city);\n      }\n      if (updateData.country !== undefined) {\n        updateFields.push(`country = $${paramCount++}`);\n        updateValues.push(updateData.country);\n      }\n      if (updateData.interests !== undefined) {\n        updateFields.push(`interests = $${paramCount++}`);\n        updateValues.push(updateData.interests);\n      }\n      if (updateData.settings !== undefined) {\n        updateFields.push(`settings = $${paramCount++}::jsonb`);\n        updateValues.push(\n          JSON.stringify({ ...existingUser.settings, ...updateData.settings }),\n        );\n      }\n      if (updateData.firebase_uid !== undefined) {\n        updateFields.push(`firebase_uid = $${paramCount++}`);\n        updateValues.push(updateData.firebase_uid);\n      }\n      if (updateData.roles !== undefined) {\n        // SEC-003.1: Use ROOT_ADMIN_EMAIL env var instead of hardcoded emails\n        const rootAdminEmail = this.getRootAdminEmail();\n        const superAdminEmails = rootAdminEmail ? [rootAdminEmail] : [];\n        if (\n          superAdminEmails.includes(existingUser.email?.toLowerCase() || \"\")\n        ) {\n          // Instead of throwing error, we just ignore the roles update for this user to be safe but not break other updates\n          this.logger.warn(\n            `Attempted to modify roles of Super Admin (${existingUser.email}) - Ignoring role update.`,\n          );\n        } else {\n          updateFields.push(`roles = $${paramCount++}::text[]`);\n          updateValues.push(updateData.roles);\n        }\n      }\n\n      // Always update last_active and updated_at\n      updateFields.push(`last_active = NOW()`, `updated_at = NOW()`);\n\n      if (updateFields.length > 2) {\n        // More than just last_active and updated_at\n        updateValues.push(userId);\n        await client.query(\n          `\n          UPDATE user_profiles \n          SET ${updateFields.join(\", \")}\n          WHERE id = $${paramCount}\n        `,\n          updateValues,\n        );\n      } else {\n        // Only update last_active\n        await client.query(\n          `\n          UPDATE user_profiles \n          SET last_active = NOW(), updated_at = NOW()\n          WHERE id = $1\n        `,\n          [userId],\n        );\n      }\n\n      await client.query(\"COMMIT\");\n\n      // Fetch updated user\n      const { rows: updatedRows } = await client.query(\n        `\n        SELECT id, email, name, phone, avatar_url, bio, karma_points, join_date,\n               is_active, last_active, city, country, interests, roles, \n               posts_count, followers_count, following_count, email_verified, settings, created_at\n        FROM user_profiles WHERE id = $1\n      `,\n        [userId],\n      );\n\n      // Clear cache to ensure fresh data after update\n      await this.redisCache.delete(`user_profile_${id}`);\n      await this.redisCache.delete(`user_profile_${userId}`);\n      await this.redisCache.invalidatePattern(\"users_list*\");\n\n      const updatedUser = updatedRows[0];\n\n      // Return user data in the expected format\n      const user = {\n        id: updatedUser.id,\n        email: updatedUser.email,\n        name: updatedUser.name,\n        phone: updatedUser.phone,\n        avatar_url: updatedUser.avatar_url,\n        bio: updatedUser.bio || \"\",\n        karma_points: updatedUser.karma_points || 0,\n        join_date: updatedUser.join_date || updatedUser.created_at,\n        is_active: updatedUser.is_active !== false,\n        last_active: updatedUser.last_active,\n        city: updatedUser.city || \"\",\n        country: updatedUser.country || \"Israel\",\n        interests: updatedUser.interests || [],\n        roles: updatedUser.roles || [\"user\"],\n        posts_count: updatedUser.posts_count || 0,\n        followers_count: updatedUser.followers_count || 0,\n        following_count: updatedUser.following_count || 0,\n        total_donations_amount: 0,\n        total_volunteer_hours: 0,\n        email_verified: updatedUser.email_verified || false,\n        settings: updatedUser.settings || {},\n      };\n\n      return { success: true, data: user };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Update user error:\", error);\n      return { success: false, error: \"Failed to update user\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Get()\n  async getUsers(\n    @Query(\"city\") city?: string,\n    @Query(\"search\") search?: string,\n    @Query(\"limit\") limit?: string,\n    @Query(\"offset\") offset?: string,\n    @Query(\"forceRefresh\") forceRefresh?: string,\n  ) {\n    // TODO: Implement proper cache key structure and versioning\n    // TODO: Add cache invalidation strategy when users are updated\n    // TODO: Implement cache warming for frequently accessed data\n    const cacheKey = `users_list_${city || \"all\"}_${search || \"\"}_${limit || \"50\"}_${offset || \"0\"}`;\n\n    // Skip cache if forceRefresh is requested\n    const shouldForceRefresh = forceRefresh === \"true\" || forceRefresh === \"1\";\n\n    if (!shouldForceRefresh) {\n      const cached = await this.redisCache.get(cacheKey);\n      if (cached) {\n        this.logger.log(\n          `[getUsers] 📦 Returning cached data for key: ${cacheKey}`,\n        );\n        return { success: true, data: cached };\n      }\n    } else {\n      this.logger.log(\n        `[getUsers] 🔄 Force refresh requested, bypassing cache for key: ${cacheKey}`,\n      );\n    }\n\n    // Unified query: Get all users from both user_profiles and users (legacy) tables\n    // טבלה מאוחדת: כל המשתמשים מ-user_profiles ו-users (legacy)\n    const params: any[] = [];\n    let paramCount = 0;\n\n    // Build WHERE conditions for filtering\n    let whereConditions = \"\";\n\n    if (city) {\n      paramCount++;\n      whereConditions += ` AND u.city ILIKE $${paramCount}`;\n      params.push(`%${city}%`);\n    }\n\n    if (search) {\n      paramCount++;\n      whereConditions += ` AND (u.name ILIKE $${paramCount} OR u.bio ILIKE $${paramCount} OR u.email ILIKE $${paramCount})`;\n      params.push(`%${search}%`);\n    }\n\n    // Build pagination\n    let limitClause = \"\";\n    let offsetClause = \"\";\n\n    if (limit) {\n      paramCount++;\n      limitClause = `LIMIT $${paramCount}`;\n      params.push(parseInt(limit));\n    } else {\n      limitClause = `LIMIT 50`;\n    }\n\n    if (offset) {\n      paramCount++;\n      offsetClause = `OFFSET $${paramCount}`;\n      params.push(parseInt(offset));\n    }\n\n    // Main query: Get users from user_profiles only (legacy users table no longer used)\n    // Includes manager details (name, email, avatar) via subquery\n    // Includes hierarchy_level for hierarchy management (if column exists)\n    // CRITICAL: Root admin (karmacommunity2.0@gmail.com) ALWAYS has parent_manager_id = NULL\n    let query: string;\n    let rows: any[] = [];\n    try {\n      // Try query with hierarchy_level (if migration ran)\n      query = `\n        SELECT \n          u.id::text as id,\n          COALESCE(u.name, 'ללא שם') as name,\n          COALESCE(u.avatar_url, '') as avatar_url,\n          COALESCE(u.city, '') as city,\n          COALESCE(u.karma_points, 0) as karma_points,\n          COALESCE(u.last_active, u.updated_at) as last_active,\n          COALESCE(u.total_donations_amount, 0) as total_donations_amount,\n          COALESCE(u.total_volunteer_hours, 0) as total_volunteer_hours,\n          COALESCE(u.join_date, u.created_at) as join_date,\n          COALESCE(u.bio, '') as bio,\n          COALESCE(u.roles, ARRAY['user']::text[]) as roles,\n          u.email,\n          u.is_active,\n          u.created_at,\n          -- CRITICAL: Root admin ALWAYS has parent_manager_id = NULL (enforced)\n          CASE \n            WHEN u.email = 'karmacommunity2.0@gmail.com' THEN NULL::text\n            ELSE u.parent_manager_id::text\n          END as parent_manager_id,\n          u.hierarchy_level,\n          -- Only show manager_details if NOT root admin and has parent_manager_id\n          CASE \n            WHEN u.email = 'karmacommunity2.0@gmail.com' THEN NULL\n            ELSE (SELECT json_build_object(\n              'id', m.id::text,\n              'name', COALESCE(m.name, 'ללא שם'),\n              'email', m.email,\n              'avatar_url', COALESCE(m.avatar_url, '')\n            )::jsonb FROM user_profiles m WHERE m.id = u.parent_manager_id)\n          END::jsonb as manager_details\n        FROM user_profiles u\n        WHERE u.email IS NOT NULL AND u.email <> ''\n          ${whereConditions}\n        ORDER BY u.karma_points DESC, u.last_active DESC, u.join_date DESC\n        ${limitClause}\n        ${offsetClause}\n      `;\n      const result = await this.pool.query(query, params);\n      rows = result.rows;\n    } catch (error: any) {\n      // Fallback: if hierarchy_level column doesn't exist yet (migration not run)\n      // OR if there's a type conversion error (jsonb/json)\n      if (\n        error.message &&\n        (error.message.includes(\"hierarchy_level\") ||\n          error.message.includes(\"could not convert type jsonb\"))\n      ) {\n        this.logger.warn(\"[getUsers] Using fallback query:\", error.message);\n        query = `\n          SELECT \n            u.id::text as id,\n            COALESCE(u.name, 'ללא שם') as name,\n            COALESCE(u.avatar_url, '') as avatar_url,\n            COALESCE(u.city, '') as city,\n            COALESCE(u.karma_points, 0) as karma_points,\n            COALESCE(u.last_active, u.updated_at) as last_active,\n            COALESCE(u.total_donations_amount, 0) as total_donations_amount,\n            COALESCE(u.total_volunteer_hours, 0) as total_volunteer_hours,\n            COALESCE(u.join_date, u.created_at) as join_date,\n            COALESCE(u.bio, '') as bio,\n            COALESCE(u.roles, ARRAY['user']::text[]) as roles,\n            u.email,\n            u.is_active,\n            u.created_at,\n            -- CRITICAL: Root admin ALWAYS has parent_manager_id = NULL (enforced)\n            CASE \n              WHEN u.email = 'karmacommunity2.0@gmail.com' THEN NULL::text\n              ELSE u.parent_manager_id::text\n            END as parent_manager_id,\n            NULL::INTEGER as hierarchy_level,  -- Not available yet\n            -- Only show manager_details if NOT root admin and has parent_manager_id\n            CASE \n              WHEN u.email = 'karmacommunity2.0@gmail.com' THEN NULL\n              ELSE (SELECT json_build_object(\n                'id', m.id::text,\n                'name', COALESCE(m.name, 'ללא שם'),\n                'email', m.email,\n                'avatar_url', COALESCE(m.avatar_url, '')\n              )::jsonb FROM user_profiles m WHERE m.id = u.parent_manager_id)\n            END::jsonb as manager_details\n          FROM user_profiles u\n          WHERE u.email IS NOT NULL AND u.email <> ''\n            ${whereConditions}\n          ORDER BY u.karma_points DESC, u.last_active DESC, u.join_date DESC\n          ${limitClause}\n          ${offsetClause}\n        `;\n        const result = await this.pool.query(query, params);\n        rows = result.rows;\n      } else {\n        throw error;\n      }\n    }\n\n    // Log for debugging\n    this.logger.log(\n      `[UsersController] getUsers returned ${rows.length} users from unified table`,\n    );\n\n    // Cache for 20 minutes - user lists are relatively static\n    await this.redisCache.set(cacheKey, rows, 20 * 60);\n    return { success: true, data: rows };\n  }\n\n  // ================================================================\n  // Phase 2+ Analytics Methods (kept active — non-breaking for MVP)\n  // ================================================================\n\n  @Get(\":id/activities\")\n  async getUserActivities(\n    @Param(\"id\") userId: string,\n    @Query(\"limit\") limit?: string,\n  ) {\n    const cacheKey = `user_activities_${userId}_${limit || \"50\"}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(\n      `\n      SELECT activity_type, activity_data, created_at\n      FROM user_activities \n      WHERE user_id = $1\n      ORDER BY created_at DESC\n      LIMIT $2\n    `,\n      [userId, parseInt(limit || \"50\")],\n    );\n\n    await this.redisCache.set(cacheKey, rows, 5 * 60);\n    return { success: true, data: rows };\n  }\n\n  /**\n   * Get user statistics with partial caching optimization\n   */\n  @Get(\":id/stats\")\n  async getUserStats(@Param(\"id\") userId: string) {\n    const cacheKey = `user_stats_${userId}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    // Try to get individual cached stats using batch get for better performance\n    const donationStatsKey = `user_stats_donations_${userId}`;\n    const rideStatsKey = `user_stats_rides_${userId}`;\n    const bookingStatsKey = `user_stats_bookings_${userId}`;\n\n    const cachedStats = await this.redisCache.getMultiple([\n      donationStatsKey,\n      rideStatsKey,\n      bookingStatsKey,\n    ]);\n\n    let donationStats: any;\n    let rideStats: any;\n    let bookingStats: any;\n\n    // Get donation stats (from cache or DB)\n    if (cachedStats.get(donationStatsKey)) {\n      donationStats = { rows: [cachedStats.get(donationStatsKey)] };\n    } else {\n      const result = await this.pool.query(\n        `\n        SELECT \n          COUNT(*) as total_donations,\n          SUM(CASE WHEN type = 'money' THEN amount ELSE 0 END) as total_money_donated,\n          COUNT(CASE WHEN type = 'time' THEN 1 END) as volunteer_activities,\n          COUNT(CASE WHEN type = 'trump' THEN 1 END) as rides_offered\n        FROM donations\n        WHERE donor_id = $1\n      `,\n        [userId],\n      );\n      donationStats = result;\n      await this.redisCache.set(\n        donationStatsKey,\n        result.rows[0],\n        this.CACHE_TTL,\n      );\n    }\n\n    // Get ride stats (from cache or DB)\n    if (cachedStats.get(rideStatsKey)) {\n      rideStats = { rows: [cachedStats.get(rideStatsKey)] };\n    } else {\n      const result = await this.pool.query(\n        `\n        SELECT \n          COUNT(*) as rides_created,\n          SUM(available_seats) as total_seats_offered,\n          COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_rides\n        FROM rides\n        WHERE driver_id = $1\n      `,\n        [userId],\n      );\n      rideStats = result;\n      await this.redisCache.set(rideStatsKey, result.rows[0], this.CACHE_TTL);\n    }\n\n    // Get booking stats (from cache or DB)\n    if (cachedStats.get(bookingStatsKey)) {\n      bookingStats = { rows: [cachedStats.get(bookingStatsKey)] };\n    } else {\n      const result = await this.pool.query(\n        `\n        SELECT \n          COUNT(*) as rides_booked,\n          COUNT(CASE WHEN status = 'approved' THEN 1 END) as approved_bookings\n        FROM ride_bookings\n        WHERE passenger_id = $1\n      `,\n        [userId],\n      );\n      bookingStats = result;\n      await this.redisCache.set(\n        bookingStatsKey,\n        result.rows[0],\n        this.CACHE_TTL,\n      );\n    }\n\n    const stats = {\n      donations: donationStats.rows[0],\n      rides: rideStats.rows[0],\n      bookings: bookingStats.rows[0],\n    };\n\n    // Cache the combined result\n    await this.redisCache.set(cacheKey, stats, this.CACHE_TTL);\n    return { success: true, data: stats };\n  }\n  // End Phase 2+ Analytics block (getUserActivities, getUserStats)\n\n  @Post(\":id/follow\")\n  @UseGuards(JwtAuthGuard)\n  async followUser(@Param(\"id\") userId: string, @Body() followData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Insert follow relationship\n      await client.query(\n        `\n        INSERT INTO user_follows (follower_id, following_id)\n        VALUES ($1, $2)\n        ON CONFLICT (follower_id, following_id) DO NOTHING\n      `,\n        [followData.follower_id, userId],\n      );\n\n      // Update follower counts\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET followers_count = (\n          SELECT COUNT(*) FROM user_follows WHERE following_id = user_profiles.id\n        )\n        WHERE id = $1\n      `,\n        [userId],\n      );\n\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET following_count = (\n          SELECT COUNT(*) FROM user_follows WHERE follower_id = user_profiles.id\n        )\n        WHERE id = $1\n      `,\n        [followData.follower_id],\n      );\n\n      // Track activity\n      await client.query(\n        `\n        INSERT INTO user_activities (user_id, activity_type, activity_data)\n        VALUES ($1, $2, $3)\n      `,\n        [\n          followData.follower_id,\n          \"user_followed\",\n          JSON.stringify({ followed_user_id: userId }),\n        ],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear relevant caches\n      await this.redisCache.delete(`user_profile_${userId}`);\n      await this.redisCache.delete(`user_profile_${followData.follower_id}`);\n\n      return { success: true, message: \"User followed successfully\" };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Follow user error:\", error);\n      return { success: false, error: \"Failed to follow user\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  @Delete(\":id/follow\")\n  @UseGuards(JwtAuthGuard)\n  async unfollowUser(@Param(\"id\") userId: string, @Body() unfollowData: any) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Remove follow relationship\n      await client.query(\n        `\n        DELETE FROM user_follows \n        WHERE follower_id = $1 AND following_id = $2\n      `,\n        [unfollowData.follower_id, userId],\n      );\n\n      // Update follower counts\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET followers_count = (\n          SELECT COUNT(*) FROM user_follows WHERE following_id = user_profiles.id\n        )\n        WHERE id = $1\n      `,\n        [userId],\n      );\n\n      await client.query(\n        `\n        UPDATE user_profiles \n        SET following_count = (\n          SELECT COUNT(*) FROM user_follows WHERE follower_id = user_profiles.id\n        )\n        WHERE id = $1\n      `,\n        [unfollowData.follower_id],\n      );\n\n      await client.query(\"COMMIT\");\n\n      // Clear relevant caches\n      await this.redisCache.delete(`user_profile_${userId}`);\n      await this.redisCache.delete(`user_profile_${unfollowData.follower_id}`);\n\n      return { success: true, message: \"User unfollowed successfully\" };\n    } catch (error) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"Unfollow user error:\", error);\n      return { success: false, error: \"Failed to unfollow user\" };\n    } finally {\n      client.release();\n    }\n  }\n\n  // Phase 2+ Analytics: getUsersSummary (Disabled for MVP — DO NOT DELETE)\n  // @Get('stats/summary')\n  // async getUsersSummary() { ... }\n  @Get(\"stats/summary\")\n  async getUsersSummary() {\n    const cacheKey = \"users_summary_stats\";\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      return { success: true, data: cached };\n    }\n\n    const { rows } = await this.pool.query(`\n    SELECT \n      COUNT(DISTINCT LOWER(email)) as total_users,\n      COUNT(CASE WHEN is_active = true THEN 1 END) as active_users,\n      COUNT(CASE WHEN last_active >= NOW() - INTERVAL '7 days' THEN 1 END) as weekly_active_users,\n      COUNT(CASE WHEN last_active >= NOW() - INTERVAL '30 days' THEN 1 END) as monthly_active_users,\n      COUNT(CASE WHEN join_date >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as new_users_this_month,\n      AVG(karma_points) as avg_karma_points,\n      SUM(total_donations_amount) as total_platform_donations\n    FROM user_profiles\n    WHERE email IS NOT NULL AND email <> ''\n  `);\n\n    const stats = rows[0];\n    await this.redisCache.set(cacheKey, stats, this.CACHE_TTL);\n\n    return { success: true, data: stats };\n  }\n\n  /**\n   * Resolve user ID from firebase_uid, google_id, or email to UUID\n   * This endpoint is used by the client to get the database UUID when they have Firebase UID or Google ID\n   * It performs SMART LINKING: if a user exists by email but lacks the external ID, it updates the record.\n   */\n  @Post(\"resolve-id\")\n  async resolveUserId(\n    @Body() body: { firebase_uid?: string; google_id?: string; email?: string },\n  ) {\n    const { firebase_uid, google_id, email } = body;\n\n    // Use a clearer logging for debugging\n    this.logger.log(\"🔍 ResolveUserId called with:\", {\n      firebase_uid,\n      google_id,\n      email,\n    });\n\n    if (!firebase_uid && !google_id && !email) {\n      return {\n        success: false,\n        error: \"Must provide firebase_uid, google_id, or email\",\n      };\n    }\n\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // 1. Try to find user by ANY of the identifiers\n      // Priorities: Database UUID (not passed here), Firebase UID, Google ID, Email\n      let query = `\n        SELECT id, email, name, avatar_url, roles, settings, created_at, last_active, firebase_uid, google_id\n        FROM user_profiles \n        WHERE false \n      `;\n      const params: any[] = [];\n      let paramCount = 1;\n\n      if (firebase_uid) {\n        query += ` OR firebase_uid = $${paramCount++}`;\n        params.push(firebase_uid);\n      }\n      if (google_id) {\n        // Only if google_id column exists (handled by try/catch in query execution if column missing, but we assume it exists from init)\n        query += ` OR google_id = $${paramCount++}`;\n        params.push(google_id);\n      }\n      if (email) {\n        query += ` OR LOWER(email) = LOWER($${paramCount++})`;\n        params.push(email);\n      }\n\n      query += ` LIMIT 1`;\n\n      let rows: any[] = [];\n      try {\n        const result = await client.query(query, params);\n        rows = result.rows;\n      } catch (err: any) {\n        // Fallback if google_id column doesn't exist yet\n        if (err.message?.includes(\"google_id\")) {\n          this.logger.warn(\n            \"⚠️ Google ID column missing in resolve-id, retrying without it\",\n          );\n          // Retry without google_id logic\n          let fallbackQuery = `SELECT id, email, name, avatar_url, roles, settings, created_at, last_active, firebase_uid FROM user_profiles WHERE false`;\n          const fallbackParams: any[] = [];\n          let fbCount = 1;\n          if (firebase_uid) {\n            fallbackQuery += ` OR firebase_uid = $${fbCount++}`;\n            fallbackParams.push(firebase_uid);\n          }\n          if (email) {\n            fallbackQuery += ` OR LOWER(email) = LOWER($${fbCount++})`;\n            fallbackParams.push(email);\n          }\n\n          const fallbackResult = await client.query(\n            fallbackQuery,\n            fallbackParams,\n          );\n          rows = fallbackResult.rows;\n        } else {\n          throw err;\n        }\n      }\n\n      if (rows.length === 0) {\n        this.logger.log(\"❌ User not found for resolution:\", {\n          firebase_uid,\n          google_id,\n          email,\n        });\n        // User not found - if we have firebase_uid, try to create user from Firebase\n        if (firebase_uid) {\n          try {\n            // Try to get user info from Firebase Admin SDK\n            // Note: This requires Firebase Admin SDK to be initialized\n            // If not available, we'll just return error\n            if (admin.apps.length > 0) {\n              try {\n                const firebaseUser = await admin.auth().getUser(firebase_uid);\n                if (firebaseUser.email) {\n                  // Create user in user_profiles\n                  const normalizedEmail = firebaseUser.email\n                    .toLowerCase()\n                    .trim();\n                  const googleProvider = firebaseUser.providerData?.find(\n                    (p: any) => p.providerId === \"google.com\",\n                  );\n                  const googleId = googleProvider?.uid || null;\n\n                  const creationTime = firebaseUser.metadata.creationTime\n                    ? new Date(firebaseUser.metadata.creationTime)\n                    : new Date();\n                  const lastSignInTime = firebaseUser.metadata.lastSignInTime\n                    ? new Date(firebaseUser.metadata.lastSignInTime)\n                    : creationTime;\n\n                  try {\n                    const { rows: newUser } = await client.query(\n                      `INSERT INTO user_profiles (\n                        firebase_uid, google_id, email, name, avatar_url, bio,\n                        karma_points, join_date, is_active, last_active,\n                        city, country, interests, roles, email_verified, settings\n                      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::text[], $14::text[], $15, $16::jsonb)\n                      RETURNING id, email, name, avatar_url, roles, settings, created_at, last_active`,\n                      [\n                        firebaseUser.uid,\n                        googleId,\n                        normalizedEmail,\n                        firebaseUser.displayName ||\n                          normalizedEmail.split(\"@\")[0] ||\n                          \"User\",\n                        firebaseUser.photoURL ||\n                          \"https://i.pravatar.cc/150?img=1\",\n                        \"משתמש חדש בקארמה קומיוניטי\",\n                        0,\n                        creationTime,\n                        true,\n                        lastSignInTime,\n                        \"ישראל\",\n                        \"Israel\",\n                        [],\n                        [\"user\"],\n                        firebaseUser.emailVerified || false,\n                        JSON.stringify({\n                          language: \"he\",\n                          dark_mode: false,\n                          notifications_enabled: true,\n                          privacy: \"public\",\n                        }),\n                      ],\n                    );\n                    await client.query(\"COMMIT\");\n                    this.logger.log(\n                      `✨ Auto-created user from Firebase: ${normalizedEmail} (${firebaseUser.uid})`,\n                    );\n\n                    // Generate JWT tokens for the new user\n                    const tokenPair = await this.jwtService.createTokenPair({\n                      id: newUser[0].id,\n                      email: newUser[0].email,\n                      roles: newUser[0].roles || [\"user\"],\n                    });\n\n                    return {\n                      success: true,\n                      tokens: {\n                        accessToken: tokenPair.accessToken,\n                        refreshToken: tokenPair.refreshToken,\n                        expiresIn: tokenPair.expiresIn,\n                        refreshExpiresIn: tokenPair.refreshExpiresIn,\n                      },\n                      user: {\n                        id: newUser[0].id,\n                        email: newUser[0].email,\n                        name: newUser[0].name,\n                        avatar: newUser[0].avatar_url,\n                        roles: newUser[0].roles || [\"user\"],\n                        settings: newUser[0].settings || {},\n                        createdAt: newUser[0].created_at,\n                        lastActive: newUser[0].last_active,\n                      },\n                    };\n                  } catch (insertError: any) {\n                    // If google_id column doesn't exist, try without it\n                    if (\n                      insertError.message &&\n                      insertError.message.includes(\"google_id\")\n                    ) {\n                      const { rows: newUser } = await client.query(\n                        `INSERT INTO user_profiles (\n                          firebase_uid, email, name, avatar_url, bio,\n                          karma_points, join_date, is_active, last_active,\n                          city, country, interests, roles, email_verified, settings\n                        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb)\n                        RETURNING id, email, name, avatar_url, roles, settings, created_at, last_active`,\n                        [\n                          firebaseUser.uid,\n                          normalizedEmail,\n                          firebaseUser.displayName ||\n                            normalizedEmail.split(\"@\")[0] ||\n                            \"User\",\n                          firebaseUser.photoURL ||\n                            \"https://i.pravatar.cc/150?img=1\",\n                          \"משתמש חדש בקארמה קומיוניטי\",\n                          0,\n                          creationTime,\n                          true,\n                          lastSignInTime,\n                          \"ישראל\",\n                          \"Israel\",\n                          [],\n                          [\"user\"],\n                          firebaseUser.emailVerified || false,\n                          JSON.stringify({\n                            language: \"he\",\n                            dark_mode: false,\n                            notifications_enabled: true,\n                            privacy: \"public\",\n                          }),\n                        ],\n                      );\n                      await client.query(\"COMMIT\");\n                      this.logger.log(\n                        `✨ Auto-created user from Firebase (without google_id): ${normalizedEmail} (${firebaseUser.uid})`,\n                      );\n\n                      // Generate JWT tokens for the new user\n                      const tokenPair = await this.jwtService.createTokenPair({\n                        id: newUser[0].id,\n                        email: newUser[0].email,\n                        roles: newUser[0].roles || [\"user\"],\n                      });\n\n                      return {\n                        success: true,\n                        tokens: {\n                          accessToken: tokenPair.accessToken,\n                          refreshToken: tokenPair.refreshToken,\n                          expiresIn: tokenPair.expiresIn,\n                          refreshExpiresIn: tokenPair.refreshExpiresIn,\n                        },\n                        user: {\n                          id: newUser[0].id,\n                          email: newUser[0].email,\n                          name: newUser[0].name,\n                          avatar: newUser[0].avatar_url,\n                          roles: newUser[0].roles || [\"user\"],\n                          settings: newUser[0].settings || {},\n                          createdAt: newUser[0].created_at,\n                          lastActive: newUser[0].last_active,\n                        },\n                      };\n                    } else {\n                      throw insertError;\n                    }\n                  }\n                }\n              } catch (firebaseError) {\n                this.logger.warn(\n                  \"⚠️ Could not fetch user from Firebase Admin SDK:\",\n                  firebaseError,\n                );\n                // Continue to return error\n              }\n            }\n          } catch {\n            // Firebase Admin SDK not available - that's okay, continue\n            this.logger.warn(\n              \"⚠️ Firebase Admin SDK not available for auto-creation\",\n            );\n          }\n        }\n\n        await client.query(\"ROLLBACK\");\n        this.logger.log(\"❌ User not found for resolution\");\n        return { success: false, error: \"User not found\" };\n      }\n\n      const user = rows[0];\n\n      // Log which identifier was used to find the user\n      let resolvedBy = \"unknown\";\n      if (firebase_uid && user.firebase_uid === firebase_uid) {\n        resolvedBy = \"firebase_uid\";\n      } else if (google_id && user.google_id === google_id) {\n        resolvedBy = \"google_id\";\n      } else if (email && user.email?.toLowerCase() === email.toLowerCase()) {\n        resolvedBy = \"email\";\n      }\n      this.logger.log(`✅ User resolved by ${resolvedBy}:`, {\n        email: user.email,\n        id: user.id,\n      });\n\n      let needsUpdate = false;\n      const updateFields: string[] = [];\n      const updateValues: any[] = [];\n      let upCount = 1;\n\n      // 2. Alert on account linking (found by email, but missing external ID)\n      if (firebase_uid && user.firebase_uid !== firebase_uid) {\n        if (!user.firebase_uid) {\n          this.logger.log(\n            `🔗 Linking User ${user.email} to Firebase UID: ${firebase_uid}`,\n          );\n          updateFields.push(`firebase_uid = $${upCount++}`);\n          updateValues.push(firebase_uid);\n          needsUpdate = true;\n        } else {\n          this.logger.warn(\n            `⚠️ Conflict: User ${user.email} has different Firebase UID (${user.firebase_uid}) than provided (${firebase_uid})`,\n          );\n        }\n      }\n\n      if (google_id && user.google_id !== google_id) {\n        // Check if row has google_id property (it might not if column missing)\n        // We assume if we are here, we want to try updating it.\n        if (!user.google_id) {\n          this.logger.log(\n            `🔗 Linking User ${user.email} to Google ID: ${google_id}`,\n          );\n          updateFields.push(`google_id = $${upCount++}`);\n          updateValues.push(google_id);\n          needsUpdate = true;\n        }\n      }\n\n      if (needsUpdate) {\n        try {\n          // Append ID for WHERE clause\n          updateValues.push(user.id);\n          const updateQuery = `\n            UPDATE user_profiles \n            SET ${updateFields.join(\", \")}, updated_at = NOW()\n            WHERE id = $${upCount}\n          `;\n          await client.query(updateQuery, updateValues);\n          this.logger.log(\"✅ User linked successfully\");\n        } catch (updateErr) {\n          this.logger.error(\"❌ Failed to link user account:\", updateErr);\n          // Non-fatal? Maybe. But safer to rollback if linking fails.\n          // actually, if we fail to link, we should probably still return the user found by email,\n          // but logging the error is important.\n        }\n      }\n\n      await client.query(\"COMMIT\");\n\n      // Clear cache for this user\n      await this.redisCache.delete(`user_profile_${user.id}`);\n      if (user.firebase_uid)\n        await this.redisCache.delete(`user_profile_${user.firebase_uid}`);\n      if (user.email)\n        await this.redisCache.delete(`user_profile_${user.email}`);\n\n      // Generate JWT tokens for authenticated session\n      const tokenPair = await this.jwtService.createTokenPair({\n        id: user.id,\n        email: user.email,\n        roles: user.roles || [\"user\"],\n      });\n\n      return {\n        success: true,\n        tokens: {\n          accessToken: tokenPair.accessToken,\n          refreshToken: tokenPair.refreshToken,\n          expiresIn: tokenPair.expiresIn,\n          refreshExpiresIn: tokenPair.refreshExpiresIn,\n        },\n        user: {\n          id: user.id, // UUID - this is the primary identifier\n          email: user.email,\n          name: user.name,\n          avatar: user.avatar_url,\n          roles: user.roles || [\"user\"],\n          settings: user.settings || {},\n          createdAt: user.created_at,\n          lastActive: user.last_active,\n        },\n      };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      this.logger.error(\"❌ Error in resolveUserId:\", error);\n      return {\n        success: false,\n        error: error.message || \"Failed to resolve user ID\",\n      };\n    } finally {\n      client.release();\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/database/database.init.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":196,"column":35,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":196,"endColumn":38,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[6332,6335],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[6332,6335],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":228,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":228,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7402,7405],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7402,7405],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":307,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":307,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10383,10386],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10383,10386],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":334,"column":53,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":334,"endColumn":56,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11364,11367],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11364,11367],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":954,"column":47,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":954,"endColumn":50,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[34339,34342],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[34339,34342],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1178,"column":45,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1178,"endColumn":48,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[40941,40944],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[40941,40944],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1213,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1213,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[42061,42064],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[42061,42064],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1234,"column":59,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1234,"endColumn":62,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[42677,42680],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[42677,42680],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":1282,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":1282,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[44020,44023],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[44020,44023],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":9,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Initialize database schema/tables on module init; supports modern schema and legacy JSONB compatibility.\n// - Reached from: `AppModule` providers (runs on startup).\n// - Provides: Detects legacy schema, runs `schema.sql` when available, ensures compatibility tables and default data.\n// - Env inputs: `SKIP_FULL_SCHEMA` to skip full schema in dev.\n// - Downstream: Creates core tables (community_stats, user_profiles, donation_categories, donations, user_activities) when needed.\nimport { Inject, Injectable, OnModuleInit } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"./database.module\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\n@Injectable()\nexport class DatabaseInit implements OnModuleInit {\n  constructor(@Inject(PG_POOL) private readonly pool: Pool) {}\n\n  async onModuleInit() {\n    try {\n      const client = await this.pool.connect();\n      try {\n        // 0) Allow forcing full schema via env var (overrides legacy detection and SKIP flags)\n        const forceFullSchemaEnv = process.env.FORCE_FULL_SCHEMA;\n        const forceFullSchema =\n          !!forceFullSchemaEnv && /^(1|true|yes)$/i.test(forceFullSchemaEnv);\n\n        if (forceFullSchema) {\n          console.warn(\n            \"⏭️  FORCE_FULL_SCHEMA detected. Running full schema initialization.\",\n          );\n          try {\n            await this.runSchema(client);\n            await this.initializeDefaultData(client);\n            console.log(\n              \"✅ DatabaseInit - Forced full schema initialized successfully\",\n            );\n          } catch (schemaError: unknown) {\n            const reason =\n              schemaError instanceof Error\n                ? schemaError.message\n                : String(schemaError);\n            console.error(\n              \"❌ Forced full schema initialization failed:\",\n              reason,\n            );\n            throw schemaError;\n          }\n          return;\n        }\n\n        // Run full schema initialization\n        // NOTE: Legacy tables are no longer created - all code should use relational tables\n        if (process.env.SKIP_FULL_SCHEMA === \"1\") {\n          console.warn(\n            \"⏭️  Skipping full schema initialization (SKIP_FULL_SCHEMA=1)\",\n          );\n          await this.ensureBackwardCompatibility(client);\n          await this.initializeDefaultData(client);\n        } else {\n          try {\n            await this.runSchema(client);\n            await this.initializeDefaultData(client);\n            console.log(\n              \"✅ DatabaseInit - Complete schema initialized successfully\",\n            );\n          } catch (schemaError: unknown) {\n            const reason =\n              schemaError instanceof Error\n                ? schemaError.message\n                : String(schemaError);\n            console.error(\"❌ Full schema initialization failed:\", reason);\n            throw schemaError;\n          }\n        }\n      } finally {\n        client.release();\n      }\n    } catch (err) {\n      console.error(\n        \"❌ DatabaseInit failed (Non-fatal, continuing startup)\",\n        err,\n      );\n      // DO NOT throw err; allow app to start so we can debug via logs/health check\n    }\n  }\n\n  // NOTE: Legacy schema detection removed - we no longer support legacy JSONB tables\n  // All code should use the new relational schema (user_profiles, etc.)\n\n  /**\n   * Split SQL statements intelligently, handling quoted strings, dollar quotes, and comments.\n   * Preserves DO $$ ... END$$; blocks as single statements.\n   */\n  private splitSqlStatements(sql: string): string[] {\n    const statements: string[] = [];\n    let currentStatement = \"\";\n    let i = 0;\n    const len = sql.length;\n\n    while (i < len) {\n      const char = sql[i];\n\n      // Handle single quoted strings '...'\n      if (char === \"'\") {\n        currentStatement += char;\n        i++;\n        while (i < len) {\n          currentStatement += sql[i];\n          if (sql[i] === \"'\") {\n            // Check for escaped quote ''\n            if (i + 1 < len && sql[i + 1] === \"'\") {\n              currentStatement += sql[i + 1];\n              i += 2;\n              continue;\n            }\n            i++;\n            break;\n          }\n          i++;\n        }\n        continue;\n      }\n\n      // Handle dollar quoted strings $tag$...$tag$\n      if (char === \"$\") {\n        // Check if it's a dollar quote start\n        const tagMatch = sql.substring(i).match(/^(\\$[a-zA-Z0-9_]*\\$)/);\n        if (tagMatch) {\n          const tag = tagMatch[1];\n          currentStatement += tag;\n          i += tag.length;\n\n          // Find closing tag\n          const closeIndex = sql.indexOf(tag, i);\n          if (closeIndex !== -1) {\n            currentStatement += sql.substring(i, closeIndex + tag.length);\n            i = closeIndex + tag.length;\n          } else {\n            // Unterminated dollar quote - consume rest\n            currentStatement += sql.substring(i);\n            i = len;\n          }\n          continue;\n        }\n      }\n\n      // Handle comments\n      if (char === \"-\" && i + 1 < len && sql[i + 1] === \"-\") {\n        // Line comment --\n        const newlineIndex = sql.indexOf(\"\\n\", i);\n        if (newlineIndex !== -1) {\n          currentStatement += sql.substring(i, newlineIndex + 1);\n          i = newlineIndex + 1;\n        } else {\n          currentStatement += sql.substring(i);\n          i = len;\n        }\n        continue;\n      }\n\n      if (char === \"/\" && i + 1 < len && sql[i + 1] === \"*\") {\n        // Block comment /* ... */\n        const closeIndex = sql.indexOf(\"*/\", i + 2);\n        if (closeIndex !== -1) {\n          currentStatement += sql.substring(i, closeIndex + 2);\n          i = closeIndex + 2;\n        } else {\n          currentStatement += sql.substring(i);\n          i = len;\n        }\n        continue;\n      }\n\n      // Handle semicolon\n      if (char === \";\") {\n        currentStatement += char;\n        if (currentStatement.trim()) {\n          statements.push(currentStatement.trim());\n        }\n        currentStatement = \"\";\n        i++;\n        continue;\n      }\n\n      // Regular character\n      currentStatement += char;\n      i++;\n    }\n\n    if (currentStatement.trim()) {\n      statements.push(currentStatement.trim());\n    }\n\n    return statements;\n  }\n\n  private async runSchema(client: any) {\n    try {\n      // Support both build (dist) and dev (src) paths\n      const candidates = [\n        path.join(__dirname, \"schema.sql\"), // dist/database/schema.sql (build)\n        path.join(process.cwd(), \"dist\", \"database\", \"schema.sql\"),\n        path.join(process.cwd(), \"src\", \"database\", \"schema.sql\"), // dev path\n        path.resolve(__dirname, \"../../src/database/schema.sql\"),\n      ];\n\n      let schemaPath = \"\";\n      for (const p of candidates) {\n        if (fs.existsSync(p)) {\n          schemaPath = p;\n          break;\n        }\n      }\n\n      if (!schemaPath) {\n        throw new Error(\"schema.sql not found in expected locations\");\n      }\n\n      const schemaSql = fs.readFileSync(schemaPath, \"utf8\");\n\n      // Split SQL statements intelligently, handling DO $$ blocks\n      const statements = this.splitSqlStatements(schemaSql);\n\n      for (let i = 0; i < statements.length; i++) {\n        const statement = statements[i];\n        if (statement.trim()) {\n          try {\n            await client.query(statement.trim());\n          } catch (err: any) {\n            console.error(\n              `❌ Failed at statement #${i + 1} of ${statements.length}:`,\n            );\n            console.error(\n              `Statement preview: ${statement.trim().substring(0, 200)}...`,\n            );\n            throw err;\n          }\n        }\n      }\n\n      console.log(`✅ Schema tables created successfully from: ${schemaPath}`);\n\n      // Ensure firebase_uid column exists in user_profiles (for existing databases)\n      // This is now handled in schema.sql, but kept here for backward compatibility\n      await client.query(`\n        ALTER TABLE user_profiles ADD COLUMN IF NOT EXISTS firebase_uid TEXT UNIQUE;\n      `);\n\n      // Ensure google_id column exists in user_profiles (for existing databases)\n      // This is now handled in schema.sql, but kept here for backward compatibility\n      try {\n        // Check if column exists first\n        const columnCheck = await client.query(`\n          SELECT column_name \n          FROM information_schema.columns \n          WHERE table_name = 'user_profiles' AND column_name = 'google_id'\n        `);\n\n        if (columnCheck.rows.length === 0) {\n          console.log(\"📝 google_id column does not exist, creating it...\");\n          await client.query(`\n            ALTER TABLE user_profiles ADD COLUMN google_id TEXT;\n          `);\n          console.log(\"✅ google_id column created\");\n        } else {\n          console.log(\"✅ google_id column already exists\");\n        }\n\n        // Add unique constraint separately if it doesn't exist\n        const constraintCheck = await client.query(`\n          SELECT conname \n          FROM pg_constraint \n          WHERE conname = 'user_profiles_google_id_key'\n        `);\n\n        if (constraintCheck.rows.length === 0) {\n          console.log(\n            \"📝 google_id unique constraint does not exist, creating it...\",\n          );\n          await client.query(`\n            ALTER TABLE user_profiles ADD CONSTRAINT user_profiles_google_id_key UNIQUE (google_id);\n          `);\n          console.log(\"✅ google_id unique constraint created\");\n        } else {\n          console.log(\"✅ google_id unique constraint already exists\");\n        }\n\n        // Create index if it doesn't exist\n        const indexCheck = await client.query(`\n          SELECT indexname \n          FROM pg_indexes \n          WHERE tablename = 'user_profiles' AND indexname = 'idx_user_profiles_google_id'\n        `);\n\n        if (indexCheck.rows.length === 0) {\n          console.log(\"📝 google_id index does not exist, creating it...\");\n          await client.query(`\n            CREATE INDEX idx_user_profiles_google_id ON user_profiles (google_id) WHERE google_id IS NOT NULL;\n          `);\n          console.log(\"✅ google_id index created\");\n        } else {\n          console.log(\"✅ google_id index already exists\");\n        }\n\n        console.log(\n          \"✅ google_id column, constraint, and index ensured in user_profiles\",\n        );\n      } catch (err: any) {\n        console.error(\"❌ Failed to add google_id column:\", err.message);\n        console.error(\"❌ Error stack:\", err.stack);\n        // Don't throw - continue with other operations\n      }\n\n      // Create the firebase_uid index (also in schema.sql)\n      await client.query(`\n        CREATE INDEX IF NOT EXISTS idx_user_profiles_firebase_uid ON user_profiles (firebase_uid) WHERE firebase_uid IS NOT NULL;\n      `);\n\n      // Create the google_id index (also in schema.sql)\n      await client.query(`\n        CREATE INDEX IF NOT EXISTS idx_user_profiles_google_id ON user_profiles (google_id) WHERE google_id IS NOT NULL;\n      `);\n\n      // Run challenges schema\n      await this.runChallengesSchema(client);\n\n      // Run community group challenges schema\n      await this.runCommunityGroupChallengesSchema(client);\n    } catch (err) {\n      console.error(\"❌ Schema creation failed:\", err);\n      throw err;\n    }\n  }\n\n  private async ensureBackwardCompatibility(client: any) {\n    try {\n      // Required extensions for UUIDs and text search\n      await client.query(`CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";`);\n\n      // NOTE: Legacy JSONB tables (users, posts, etc.) are no longer created\n      // All code should use the new relational tables (user_profiles, etc.)\n      // If you need legacy tables, they must be created manually or migrated from existing data\n\n      // Ensure minimal relational tables required by new controllers exist\n      // community_stats is used by StatsController; create it even in legacy mode\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS community_stats (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          stat_type VARCHAR(50) NOT NULL,\n          stat_value BIGINT DEFAULT 0,\n          city VARCHAR(100),\n          date_period DATE,\n          metadata JSONB,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW(),\n          UNIQUE(stat_type, city, date_period)\n        );\n      `);\n      await client.query(`\n        CREATE INDEX IF NOT EXISTS idx_community_stats_type ON community_stats (stat_type, date_period);\n      `);\n      await client.query(`\n        CREATE INDEX IF NOT EXISTS idx_community_stats_city ON community_stats (city, date_period);\n      `);\n\n      // Ensure items table with separate columns (not JSONB)\n      console.log(\"🔧 Ensuring items table with dedicated columns...\");\n      try {\n        await client.query(`\n          CREATE TABLE IF NOT EXISTS items (\n            id TEXT PRIMARY KEY,\n            owner_id UUID NOT NULL, -- REFERENCES user_profiles(id), -- UUID to match user_profiles.id type\n            title VARCHAR(255) NOT NULL,\n            description TEXT,\n            category VARCHAR(50) NOT NULL,\n            condition VARCHAR(20),\n            location JSONB,\n            city VARCHAR(100),\n            address TEXT,\n            coordinates VARCHAR(100),\n            price DECIMAL(10,2) DEFAULT 0,\n            image_base64 TEXT,\n            rating INTEGER DEFAULT 0,\n            tags TEXT,\n            quantity INTEGER DEFAULT 1,\n            status VARCHAR(20) DEFAULT 'available',\n            delivery_method VARCHAR(20) DEFAULT 'pickup',\n            is_deleted BOOLEAN DEFAULT FALSE,\n            deleted_at TIMESTAMPTZ,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          );\n        `);\n\n        // Try to create indexes, skip if column doesn't exist\n        try {\n          await client.query(\n            `CREATE INDEX IF NOT EXISTS idx_items_owner_id ON items(owner_id);`,\n          );\n        } catch {\n          console.log(\"⚠️ Skipping idx_items_owner_id\");\n        }\n\n        try {\n          await client.query(\n            `CREATE INDEX IF NOT EXISTS idx_items_category ON items(category);`,\n          );\n        } catch {\n          console.log(\"⚠️ Skipping idx_items_category\");\n        }\n\n        try {\n          await client.query(\n            `CREATE INDEX IF NOT EXISTS idx_items_status ON items(status);`,\n          );\n        } catch {\n          console.log(\"⚠️ Skipping idx_items_status\");\n        }\n\n        try {\n          await client.query(\n            `CREATE INDEX IF NOT EXISTS idx_items_is_deleted ON items(is_deleted);`,\n          );\n        } catch {\n          console.log(\"⚠️ Skipping idx_items_is_deleted\");\n        }\n\n        try {\n          await client.query(\n            `CREATE INDEX IF NOT EXISTS idx_items_created_at ON items(created_at DESC);`,\n          );\n        } catch {\n          console.log(\"⚠️ Skipping idx_items_created_at\");\n        }\n\n        console.log(\"✅ Items table ensured with dedicated columns\");\n      } catch (error) {\n        console.error(\"❌ Failed to create items table:\", error);\n        // Continue anyway - table might already exist in different format\n      }\n\n      // Ensure location column exists in items\n      try {\n        await client.query(`\n            DO $$ \n            BEGIN\n              IF NOT EXISTS (\n                SELECT 1 FROM information_schema.columns \n                WHERE table_name = 'items' AND column_name = 'location'\n              ) THEN\n                ALTER TABLE items ADD COLUMN location JSONB;\n              END IF;\n            END $$ ;\n          `);\n      } catch (_e) {\n        console.log(\"⚠️ Failed to add location column to items:\", _e);\n      }\n\n      // Minimal user_profiles to satisfy joins and stats\n      // NOTE: id is UUID (standard identifier), firebase_uid is TEXT (for Firebase authentication linking)\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS user_profiles (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          firebase_uid TEXT UNIQUE, -- Firebase UID for authentication linking (optional)\n          email VARCHAR(255) UNIQUE NOT NULL,\n          name VARCHAR(255) NOT NULL,\n          phone VARCHAR(20),\n          avatar_url TEXT,\n          city VARCHAR(100),\n          is_active BOOLEAN DEFAULT true,\n          last_active TIMESTAMPTZ DEFAULT NOW(),\n          join_date TIMESTAMPTZ DEFAULT NOW(),\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n\n      // Add firebase_uid column if it doesn't exist (for existing databases)\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name = 'user_profiles' AND column_name = 'firebase_uid'\n          ) THEN\n            ALTER TABLE user_profiles ADD COLUMN firebase_uid TEXT;\n            CREATE UNIQUE INDEX IF NOT EXISTS user_profiles_firebase_uid_unique ON user_profiles (firebase_uid) WHERE firebase_uid IS NOT NULL;\n          END IF;\n        END $$ ;\n      `);\n\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_user_profiles_email_lower ON user_profiles (LOWER(email));`,\n      );\n      // Only create firebase_uid index if the column exists\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name = 'user_profiles' AND column_name = 'firebase_uid'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_user_profiles_firebase_uid ON user_profiles (firebase_uid) WHERE firebase_uid IS NOT NULL;\n          END IF;\n        END $$ ;\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_user_profiles_city ON user_profiles (city);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_user_profiles_active ON user_profiles (is_active, last_active);`,\n      );\n\n      // Ensure metadata column exists\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name = 'user_profiles' AND column_name = 'metadata'\n          ) THEN\n            ALTER TABLE user_profiles ADD COLUMN metadata JSONB DEFAULT '{}'::jsonb;\n          END IF;\n        END $$ ;\n      `);\n\n      // donation_categories to power categories and analytics\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS donation_categories (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          slug VARCHAR(50) UNIQUE NOT NULL,\n          name_he VARCHAR(100) NOT NULL,\n          name_en VARCHAR(100) NOT NULL,\n          description_he TEXT,\n          description_en TEXT,\n          icon VARCHAR(50),\n          color VARCHAR(7),\n          is_active BOOLEAN DEFAULT true,\n          sort_order INTEGER DEFAULT 0,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n\n      // donations table with essential columns\n      // If legacy JSONB 'donations' exists, replace it with relational schema\n      const donationsLegacy = await client.query(`\n        SELECT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name = 'donations' AND column_name = 'data'\n        ) AS exists;\n      `);\n      if (donationsLegacy?.rows?.[0]?.exists) {\n        console.warn(\n          \"⚠️  Replacing legacy JSONB donations table with relational schema\",\n        );\n        await client.query(\"DROP TABLE IF EXISTS donations CASCADE;\");\n      }\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS donations (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          donor_id UUID,\n          recipient_id UUID,\n          organization_id UUID,\n          category_id UUID,\n          title VARCHAR(255) NOT NULL,\n          description TEXT,\n          amount DECIMAL(10,2),\n          currency VARCHAR(3) DEFAULT 'ILS',\n          type VARCHAR(20) NOT NULL,\n          status VARCHAR(20) DEFAULT 'active',\n          is_recurring BOOLEAN DEFAULT false,\n          location JSONB,\n          images TEXT[],\n          tags TEXT[],\n          metadata JSONB,\n          expires_at TIMESTAMPTZ,\n          completed_at TIMESTAMPTZ,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      // Create indexes conditionally to avoid errors if columns ever differ\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='donor_id'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_donations_donor ON donations (donor_id);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='category_id'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_donations_category ON donations (category_id);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='type'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_donations_type ON donations (type);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='status'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_donations_status ON donations (status);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='created_at'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_donations_created ON donations (created_at);\n          END IF;\n        END $$ ;\n      `);\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='donations' AND column_name='is_recurring'\n          ) THEN\n            ALTER TABLE donations ADD COLUMN is_recurring BOOLEAN DEFAULT false;\n          END IF;\n        END $$ ;\n      `);\n      // location is JSONB – safe\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_donations_location ON donations USING GIN (location);`,\n      );\n\n      // minimal user_activities used by stats\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS user_activities (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          user_id UUID,\n          activity_type VARCHAR(50) NOT NULL,\n          activity_data JSONB,\n          ip_address INET,\n          user_agent TEXT,\n          created_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n\n      // Ensure rides relational schema (replace legacy JSONB rides if exists)\n      const ridesLegacy = await client.query(`\n        SELECT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name = 'rides' AND column_name = 'data'\n        ) AS exists;\n      `);\n      if (ridesLegacy?.rows?.[0]?.exists) {\n        console.warn(\n          \"⚠️  Replacing legacy JSONB rides table with relational schema\",\n        );\n        await client.query(\"DROP TABLE IF EXISTS rides CASCADE;\");\n      }\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS rides (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          driver_id UUID,\n          title VARCHAR(255),\n          from_location JSONB NOT NULL,\n          to_location JSONB NOT NULL,\n          departure_time TIMESTAMPTZ NOT NULL,\n          arrival_time TIMESTAMPTZ,\n          available_seats INTEGER DEFAULT 1,\n          price_per_seat DECIMAL(10,2) DEFAULT 0,\n          description TEXT,\n          requirements TEXT,\n          status VARCHAR(20) DEFAULT 'active',\n          metadata JSONB,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='rides' AND column_name='driver_id'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_rides_driver ON rides (driver_id);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='rides' AND column_name='departure_time'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_rides_departure ON rides (departure_time);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='rides' AND column_name='status'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_rides_status ON rides (status);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='rides' AND column_name='created_at'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_rides_created ON rides (created_at);\n          END IF;\n        END $$ ;\n      `);\n      await client.query(\n        \"CREATE INDEX IF NOT EXISTS idx_rides_from_location ON rides USING GIN (from_location);\",\n      );\n      await client.query(\n        \"CREATE INDEX IF NOT EXISTS idx_rides_to_location ON rides USING GIN (to_location);\",\n      );\n\n      // Minimal chat schema required by ChatController\n      // NOTE: All user ID fields use UUID type to match user_profiles.id\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS chat_conversations (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          title VARCHAR(255),\n          type VARCHAR(20) DEFAULT 'direct',\n          participants UUID[] NOT NULL, -- UUID[] to match user_profiles.id type\n          created_by UUID, -- UUID to match user_profiles.id type\n          last_message_id UUID,\n          last_message_at TIMESTAMPTZ DEFAULT NOW(),\n          metadata JSONB,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_chat_conversations_participants ON chat_conversations USING GIN (participants);`,\n      );\n\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS chat_messages (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          conversation_id UUID NOT NULL,\n          sender_id UUID NOT NULL,\n          content TEXT,\n          message_type VARCHAR(20) DEFAULT 'text',\n          file_url TEXT,\n          file_name VARCHAR(255),\n          file_size INTEGER,\n          file_type VARCHAR(100),\n          metadata JSONB,\n          reply_to_id UUID,\n          is_edited BOOLEAN DEFAULT false,\n          edited_at TIMESTAMPTZ,\n          is_deleted BOOLEAN DEFAULT false,\n          deleted_at TIMESTAMPTZ,\n          created_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_chat_messages_conversation ON chat_messages (conversation_id, created_at);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_chat_messages_sender ON chat_messages (sender_id);`,\n      );\n\n      // Add missing columns to existing chat_messages table if needed\n      await client.query(`\n        DO $$ \n        BEGIN\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='chat_messages' AND column_name='is_deleted'\n          ) THEN\n            ALTER TABLE chat_messages ADD COLUMN is_deleted BOOLEAN DEFAULT false;\n          END IF;\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='chat_messages' AND column_name='deleted_at'\n          ) THEN\n            ALTER TABLE chat_messages ADD COLUMN deleted_at TIMESTAMPTZ;\n          END IF;\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='chat_messages' AND column_name='is_edited'\n          ) THEN\n            ALTER TABLE chat_messages ADD COLUMN is_edited BOOLEAN DEFAULT false;\n          END IF;\n          IF NOT EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='chat_messages' AND column_name='edited_at'\n          ) THEN\n            ALTER TABLE chat_messages ADD COLUMN edited_at TIMESTAMPTZ;\n          END IF;\n        END $$ ;\n      `);\n\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS message_read_receipts (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          message_id UUID NOT NULL,\n          user_id UUID NOT NULL,\n          read_at TIMESTAMPTZ DEFAULT NOW(),\n          UNIQUE(message_id, user_id)\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_message_read_receipts_message ON message_read_receipts (message_id);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_message_read_receipts_user ON message_read_receipts (user_id);`,\n      );\n\n      // ride_bookings table\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS ride_bookings (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          ride_id UUID,\n          passenger_id UUID,\n          seats_requested INTEGER DEFAULT 1,\n          status VARCHAR(20) DEFAULT 'pending',\n          message TEXT,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW(),\n          UNIQUE(ride_id, passenger_id)\n        );\n      `);\n\n      // community_events table - required by StatsController\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS community_events (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          organizer_id UUID,\n          organization_id UUID,\n          title VARCHAR(255) NOT NULL,\n          description TEXT,\n          event_date TIMESTAMPTZ NOT NULL,\n          end_date TIMESTAMPTZ,\n          location JSONB,\n          max_attendees INTEGER,\n          current_attendees INTEGER DEFAULT 0,\n          category VARCHAR(50),\n          tags TEXT[],\n          image_url TEXT,\n          is_virtual BOOLEAN DEFAULT false,\n          meeting_link TEXT,\n          status VARCHAR(20) DEFAULT 'active',\n          metadata JSONB,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_events_date ON community_events (event_date);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_events_organizer ON community_events (organizer_id);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_events_status ON community_events (status);`,\n      );\n\n      // event_attendees table\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS event_attendees (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          event_id UUID,\n          user_id UUID,\n          status VARCHAR(20) DEFAULT 'going',\n          registered_at TIMESTAMPTZ DEFAULT NOW(),\n          UNIQUE(event_id, user_id)\n        );\n      `);\n\n      // community_members table for admin management\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS community_members (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          name VARCHAR(255) NOT NULL,\n          role VARCHAR(255) NOT NULL,\n          description TEXT,\n          contact_info JSONB,\n          status VARCHAR(20) DEFAULT 'active',\n          created_by UUID, -- REFERENCES user_profiles(id), -- UUID to match user_profiles.id type\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_members_name ON community_members (name);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_members_role ON community_members (role);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_members_status ON community_members (status);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_community_members_created_at ON community_members (created_at DESC);`,\n      );\n\n      // Create trigger function if it doesn't exist\n      await client.query(`\n        CREATE OR REPLACE FUNCTION update_updated_at_column()\n        RETURNS TRIGGER AS '\n        BEGIN\n          NEW.updated_at = NOW();\n          RETURN NEW;\n        END;\n        ' language 'plpgsql'\n      `);\n\n      // Create trigger for community_members\n      await client.query(\n        \"DROP TRIGGER IF EXISTS update_community_members_updated_at ON community_members\",\n      );\n      await client.query(`\n        CREATE TRIGGER update_community_members_updated_at \n        BEFORE UPDATE ON community_members \n        FOR EACH ROW \n        EXECUTE FUNCTION update_updated_at_column()\n      `);\n\n      // NOTE: links table has been removed - it contained duplicate user/item data\n      // All user data is now unified in user_profiles table with UUID identifiers\n\n      // Ensure item_requests table exists\n      console.log(\"📦 Ensuring item_requests table...\");\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS item_requests (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          item_id TEXT,\n          requester_id UUID,\n          status VARCHAR(20) DEFAULT 'pending',\n          message TEXT,\n          proposed_time TIMESTAMPTZ,\n          delivery_method VARCHAR(20),\n          meeting_location JSONB,\n          owner_response TEXT,\n          completed_at TIMESTAMPTZ,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_item_requests_item ON item_requests(item_id);`,\n      );\n      await client.query(\n        `CREATE INDEX IF NOT EXISTS idx_item_requests_requester ON item_requests(requester_id);`,\n      );\n\n      console.log(\"✅ Backward compatibility tables ensured\");\n    } catch (err) {\n      console.error(\"❌ Backward compatibility setup failed:\", err);\n      throw err;\n    }\n  }\n\n  private async initializeDefaultData(client: any) {\n    try {\n      // Initialize donation categories\n      const categories = [\n        {\n          slug: \"money\",\n          name_he: \"כסף\",\n          name_en: \"Money\",\n          icon: \"💰\",\n          color: \"#4CAF50\",\n          sort_order: 1,\n        },\n        {\n          slug: \"trump\",\n          name_he: \"טרמפים\",\n          name_en: \"Rides\",\n          icon: \"🚗\",\n          color: \"#2196F3\",\n          sort_order: 2,\n        },\n        {\n          slug: \"knowledge\",\n          name_he: \"ידע\",\n          name_en: \"Knowledge\",\n          icon: \"📚\",\n          color: \"#9C27B0\",\n          sort_order: 3,\n        },\n        {\n          slug: \"time\",\n          name_he: \"זמן\",\n          name_en: \"Time\",\n          icon: \"⏰\",\n          color: \"#FF9800\",\n          sort_order: 4,\n        },\n        {\n          slug: \"food\",\n          name_he: \"אוכל\",\n          name_en: \"Food\",\n          icon: \"🍞\",\n          color: \"#8BC34A\",\n          sort_order: 5,\n        },\n        {\n          slug: \"clothes\",\n          name_he: \"בגדים\",\n          name_en: \"Clothes\",\n          icon: \"👕\",\n          color: \"#03A9F4\",\n          sort_order: 6,\n        },\n        {\n          slug: \"books\",\n          name_he: \"ספרים\",\n          name_en: \"Books\",\n          icon: \"📖\",\n          color: \"#607D8B\",\n          sort_order: 7,\n        },\n        {\n          slug: \"furniture\",\n          name_he: \"רהיטים\",\n          name_en: \"Furniture\",\n          icon: \"🪑\",\n          color: \"#795548\",\n          sort_order: 8,\n        },\n        {\n          slug: \"medical\",\n          name_he: \"רפואה\",\n          name_en: \"Medical\",\n          icon: \"🏥\",\n          color: \"#F44336\",\n          sort_order: 9,\n        },\n        {\n          slug: \"animals\",\n          name_he: \"חיות\",\n          name_en: \"Animals\",\n          icon: \"🐾\",\n          color: \"#4CAF50\",\n          sort_order: 10,\n        },\n        {\n          slug: \"housing\",\n          name_he: \"דיור\",\n          name_en: \"Housing\",\n          icon: \"🏠\",\n          color: \"#FF5722\",\n          sort_order: 11,\n        },\n        {\n          slug: \"support\",\n          name_he: \"תמיכה\",\n          name_en: \"Support\",\n          icon: \"💝\",\n          color: \"#E91E63\",\n          sort_order: 12,\n        },\n        {\n          slug: \"education\",\n          name_he: \"חינוך\",\n          name_en: \"Education\",\n          icon: \"🎓\",\n          color: \"#3F51B5\",\n          sort_order: 13,\n        },\n        {\n          slug: \"environment\",\n          name_he: \"סביבה\",\n          name_en: \"Environment\",\n          icon: \"🌱\",\n          color: \"#4CAF50\",\n          sort_order: 14,\n        },\n        {\n          slug: \"technology\",\n          name_he: \"טכנולוגיה\",\n          name_en: \"Technology\",\n          icon: \"💻\",\n          color: \"#009688\",\n          sort_order: 15,\n        },\n      ];\n\n      for (const category of categories) {\n        await client.query(\n          `\n          INSERT INTO donation_categories (slug, name_he, name_en, icon, color, sort_order)\n          VALUES ($1, $2, $3, $4, $5, $6)\n          ON CONFLICT (slug) DO UPDATE SET\n            name_he = EXCLUDED.name_he,\n            name_en = EXCLUDED.name_en,\n            icon = EXCLUDED.icon,\n            color = EXCLUDED.color,\n            sort_order = EXCLUDED.sort_order,\n            updated_at = NOW()\n        `,\n          [\n            category.slug,\n            category.name_he,\n            category.name_en,\n            category.icon,\n            category.color,\n            category.sort_order,\n          ],\n        );\n      }\n\n      // Initialize global community stats\n      // IMPORTANT: Using ON CONFLICT DO NOTHING to preserve existing data on redeployment\n      // This ensures that stats like site_visits don't reset when the server restarts\n      const defaultStats = [\n        { stat_type: \"site_visits\", stat_value: 0 },\n        { stat_type: \"money_donations\", stat_value: 0 },\n        { stat_type: \"volunteer_hours\", stat_value: 0 },\n        { stat_type: \"rides_completed\", stat_value: 0 },\n        { stat_type: \"events_created\", stat_value: 0 },\n        { stat_type: \"active_members\", stat_value: 0 },\n        { stat_type: \"food_kg\", stat_value: 0 },\n        { stat_type: \"clothing_kg\", stat_value: 0 },\n        { stat_type: \"books_donated\", stat_value: 0 },\n      ];\n\n      for (const stat of defaultStats) {\n        // ON CONFLICT DO NOTHING: If the stat exists for today, don't change it\n        // This preserves accumulated values during server restarts/redeployments\n        const result = await client.query(\n          `\n          INSERT INTO community_stats (stat_type, stat_value, date_period)\n          VALUES ($1, $2, CURRENT_DATE)\n          ON CONFLICT (stat_type, city, date_period) DO NOTHING\n          RETURNING stat_type, stat_value\n        `,\n          [stat.stat_type, stat.stat_value],\n        );\n\n        // If result has rows, it means we created a new stat entry\n        // If no rows, it means the stat already existed and was preserved\n        if (result.rows.length > 0) {\n          console.log(\n            `✨ Created new stat: ${stat.stat_type} = ${stat.stat_value}`,\n          );\n        } else {\n          console.log(`✅ Preserved existing stat: ${stat.stat_type}`);\n        }\n      }\n\n      // Create a test user for API testing\n      await client.query(`\n        INSERT INTO user_profiles (id, email, name, is_active)\n        VALUES ('550e8400-e29b-41d4-a716-446655440000', 'test@example.com', 'Test User', true)\n        ON CONFLICT (id) DO UPDATE SET\n          email = EXCLUDED.email,\n          name = EXCLUDED.name,\n          is_active = EXCLUDED.is_active,\n          updated_at = NOW()\n      `);\n\n      // Ensure root admin (from env) always has super_admin role. No hardcoded emails.\n      const rootAdminEmail = process.env.ROOT_ADMIN_EMAIL?.toLowerCase().trim();\n      if (rootAdminEmail) {\n        await client.query(\n          `UPDATE user_profiles \n           SET roles = ARRAY['super_admin', 'admin', 'user']::TEXT[]\n           WHERE LOWER(TRIM(email)) = $1\n             AND (roles IS NULL OR NOT (roles @> ARRAY['super_admin']::TEXT[]))`,\n          [rootAdminEmail],\n        );\n        console.log(`✅ Root admin role ensured for: ${rootAdminEmail}`);\n      } else {\n        console.warn(\n          \"⚠️ ROOT_ADMIN_EMAIL not set - no root admin bootstrap. Set in .env for initial setup.\",\n        );\n      }\n\n      console.log(\"✅ Default data initialized\");\n    } catch (err) {\n      console.error(\"❌ Default data initialization failed:\", err);\n      // Don't throw here as it's not critical\n    }\n  }\n\n  private async runChallengesSchema(client: any) {\n    try {\n      // Support both build (dist) and dev (src) paths\n      const candidates = [\n        path.join(__dirname, \"challenges-schema.sql\"),\n        path.join(process.cwd(), \"dist\", \"database\", \"challenges-schema.sql\"),\n        path.join(process.cwd(), \"src\", \"database\", \"challenges-schema.sql\"),\n        path.resolve(__dirname, \"../../src/database/challenges-schema.sql\"),\n      ];\n\n      let schemaPath = \"\";\n      for (const p of candidates) {\n        if (fs.existsSync(p)) {\n          schemaPath = p;\n          break;\n        }\n      }\n\n      if (!schemaPath) {\n        console.warn(\n          \"⚠️ challenges-schema.sql not found, skipping challenges tables\",\n        );\n        return;\n      }\n\n      const schemaSql = fs.readFileSync(schemaPath, \"utf8\");\n\n      // Split SQL statements intelligently, handling DO $$ blocks\n      const statements = this.splitSqlStatements(schemaSql);\n\n      for (let i = 0; i < statements.length; i++) {\n        const statement = statements[i];\n        if (statement.trim()) {\n          try {\n            await client.query(statement.trim());\n          } catch (err: any) {\n            console.error(\n              `❌ Failed at CHALLENGES statement #${i + 1} of ${statements.length}:`,\n            );\n            console.error(\n              `Statement preview: ${statement.trim().substring(0, 200)}...`,\n            );\n            throw err;\n          }\n        }\n      }\n\n      console.log(\n        `✅ Challenges schema tables created successfully from: ${schemaPath}`,\n      );\n    } catch (err) {\n      console.error(\"❌ Challenges schema creation failed:\", err);\n      // Don't throw here as it's not critical\n    }\n  }\n\n  private async runCommunityGroupChallengesSchema(client: any) {\n    try {\n      // Support both build (dist) and dev (src) paths\n      const candidates = [\n        path.join(__dirname, \"community-group-challenges-schema.sql\"),\n        path.join(\n          process.cwd(),\n          \"dist\",\n          \"database\",\n          \"community-group-challenges-schema.sql\",\n        ),\n        path.join(\n          process.cwd(),\n          \"src\",\n          \"database\",\n          \"community-group-challenges-schema.sql\",\n        ),\n        path.resolve(\n          __dirname,\n          \"../../src/database/community-group-challenges-schema.sql\",\n        ),\n      ];\n\n      let schemaPath = \"\";\n      for (const p of candidates) {\n        if (fs.existsSync(p)) {\n          schemaPath = p;\n          break;\n        }\n      }\n\n      if (!schemaPath) {\n        console.warn(\n          \"⚠️ community-group-challenges-schema.sql not found, skipping community challenges tables\",\n        );\n        return;\n      }\n\n      const schemaSql = fs.readFileSync(schemaPath, \"utf8\");\n\n      // Split SQL statements intelligently, handling DO $$ blocks\n      const statements = this.splitSqlStatements(schemaSql);\n\n      for (let i = 0; i < statements.length; i++) {\n        const statement = statements[i];\n        if (statement.trim()) {\n          try {\n            await client.query(statement.trim());\n          } catch (err: any) {\n            console.error(\n              `❌ Failed at COMMUNITY CHALLENGES statement #${i + 1} of ${statements.length}:`,\n            );\n            console.error(\n              `Statement preview: ${statement.trim().substring(0, 200)}...`,\n            );\n            throw err;\n          }\n        }\n      }\n\n      // Additional migration: Ensure image_url column exists\n      try {\n        await client.query(`\n          DO $$ \n          BEGIN\n              IF NOT EXISTS (\n                  SELECT 1 FROM information_schema.columns \n                  WHERE table_name = 'community_group_challenges' AND column_name = 'image_url'\n              ) THEN\n                  ALTER TABLE community_group_challenges ADD COLUMN image_url TEXT;\n                  RAISE NOTICE 'Column image_url added to community_group_challenges';\n              END IF;\n          END $$;\n        `);\n        console.log(\n          \"✅ Verified image_url column exists in community_group_challenges\",\n        );\n      } catch (err) {\n        console.error(\"⚠️ Could not verify image_url column:\", err);\n      }\n\n      console.log(\n        `✅ Community Group Challenges schema tables created successfully from: ${schemaPath}`,\n      );\n    } catch (err) {\n      console.error(\n        \"❌ Community Group Challenges schema creation failed:\",\n        err,\n      );\n      // Don't throw here as it's not critical\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/database/database.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/dedicated-items.controller.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/dedicated-items.service.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/dto/dedicated-item.dto.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/dto/item.dto.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/items.controller.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/items.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/items/items.service.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":278,"column":34,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":278,"endColumn":37,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8765,8768],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8765,8768],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":309,"column":51,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":309,"endColumn":54,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9810,9813],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9810,9813],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Generic JSONB CRUD over multiple logical collections (users, posts, donations, rides, etc.) with Redis caching and activity tracking.\n// - Reached from: `ItemsController` endpoints under '/api'.\n// - Provides: create/read/update/delete/list with safe collection mapping; activity counters and cache stats via Redis.\n// - Storage: Postgres tables named after collections with (user_id, item_id, data JSONB) + indexes.\n// - Cache keys: item:{collection}:{userId}:{itemId}, list:{collection}:{userId}, activity:{userId}, daily_activity:{userId}:{YYYY-MM-DD}, popular_collections:*.\nimport { Inject, Injectable } from \"@nestjs/common\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { Pool } from \"pg\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n@Injectable()\nexport class ItemsService {\n  private readonly CACHE_TTL = 5 * 60; // 5 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  private tableFor(collection: string): string {\n    // map collection names to table names; default: use as-is\n    const allowed = new Set([\n      \"users\",\n      \"posts\",\n      \"followers\",\n      \"following\",\n      \"chats\",\n      \"messages\",\n      \"notifications\",\n      \"bookmarks\",\n      \"donations\",\n      \"items\",\n      \"tasks\",\n      \"settings\",\n      \"media\",\n      \"blocked_users\",\n      \"message_reactions\",\n      \"typing_status\",\n      \"read_receipts\",\n      \"voice_messages\",\n      \"conversation_metadata\",\n      \"rides\",\n      // Organizations / NGO onboarding\n      \"organizations\",\n      \"org_applications\",\n      // Links (for groups and organizations)\n      \"links\",\n      // App analytics (e.g., category open counters)\n      \"analytics\",\n      // Stats\n      \"stats\",\n      \"community_stats\",\n      // Challenges\n      \"challenges\",\n      \"deleted_challenges\",\n      \"challenge_reset_logs\",\n      \"challenge_record_breaks\",\n      \"challenge_global_stats\",\n    ]);\n    if (!allowed.has(collection)) {\n      throw new Error(`Unknown collection: ${collection}`);\n    }\n    return collection;\n  }\n\n  async create(\n    collection: string,\n    userId: string,\n    itemId: string,\n    data: Record<string, unknown>,\n  ) {\n    const table = this.tableFor(collection);\n    const client = await this.pool.connect();\n    try {\n      // Add activity tracking (safely)\n      try {\n        await this.trackUserActivity(userId, \"create\", collection, itemId);\n      } catch (err) {\n        console.warn(\"⚠️ Failed to track user activity (non-fatal):\", err);\n      }\n\n      await client.query(\n        `INSERT INTO ${table} (user_id, item_id, data, created_at, updated_at)\n         VALUES ($1, $2, $3, NOW(), NOW())\n         ON CONFLICT (user_id, item_id)\n         DO UPDATE SET data = EXCLUDED.data, updated_at = NOW()`,\n        [userId, itemId, data],\n      );\n\n      // Cache the created item (safely)\n      try {\n        const cacheKey = `item:${collection}:${userId}:${itemId}`;\n        await this.redisCache.set(cacheKey, data, this.CACHE_TTL);\n      } catch (err) {\n        console.warn(\"⚠️ Failed to cache created item (non-fatal):\", err);\n      }\n\n      // Invalidate list cache for this user and collection (safely)\n      try {\n        await this.invalidateListCache(collection, userId);\n      } catch (err) {\n        console.warn(\"⚠️ Failed to invalidate list cache (non-fatal):\", err);\n      }\n\n      // Track popular collections (safely)\n      try {\n        await this.incrementCollectionCounter(collection);\n      } catch (err) {\n        console.warn(\n          \"⚠️ Failed to increment collection counter (non-fatal):\",\n          err,\n        );\n      }\n\n      return { ok: true };\n    } finally {\n      client.release();\n    }\n  }\n\n  async read(collection: string, userId: string, itemId: string) {\n    // Try cache first\n    const cacheKey = `item:${collection}:${userId}:${itemId}`;\n    const cached = await this.redisCache.get(cacheKey);\n\n    if (cached) {\n      // Track cache hit\n      await this.trackUserActivity(userId, \"read_cached\", collection, itemId);\n      return cached;\n    }\n\n    // Cache miss - get from database\n    const table = this.tableFor(collection);\n    const { rows } = await this.pool.query(\n      `SELECT data FROM ${table} WHERE user_id = $1 AND item_id = $2 LIMIT 1`,\n      [userId, itemId],\n    );\n\n    const data = rows[0]?.data ?? null;\n\n    if (data) {\n      // Cache the result\n      await this.redisCache.set(cacheKey, data, this.CACHE_TTL);\n      // Track cache miss\n      await this.trackUserActivity(userId, \"read_db\", collection, itemId);\n    }\n\n    return data;\n  }\n\n  async update(\n    collection: string,\n    userId: string,\n    itemId: string,\n    data: Record<string, unknown>,\n  ) {\n    const table = this.tableFor(collection);\n    const { rowCount } = await this.pool.query(\n      `UPDATE ${table} SET data = jsonb_strip_nulls(data || $1::jsonb), updated_at = NOW()\n       WHERE user_id = $2 AND item_id = $3`,\n      [data, userId, itemId],\n    );\n    return { ok: (rowCount ?? 0) > 0 };\n  }\n\n  async delete(collection: string, userId: string, itemId: string) {\n    const table = this.tableFor(collection);\n    console.log(\n      `🗑️  DELETE Request - table: ${table}, userId: ${userId}, itemId: ${itemId}`,\n    );\n\n    // First check if item exists\n    const checkResult = await this.pool.query(\n      `SELECT * FROM ${table} WHERE user_id = $1 AND item_id = $2`,\n      [userId, itemId],\n    );\n    console.log(`🔍 Item exists check: ${checkResult.rowCount} rows found`);\n\n    const { rowCount } = await this.pool.query(\n      `DELETE FROM ${table} WHERE user_id = $1 AND item_id = $2`,\n      [userId, itemId],\n    );\n    console.log(`✅ DELETE result: ${rowCount} rows deleted`);\n\n    // Invalidate cache\n    await this.invalidateListCache(collection, userId);\n    const cacheKey = `item:${collection}:${userId}:${itemId}`;\n    await this.redisCache.delete(cacheKey);\n\n    return { ok: (rowCount ?? 0) > 0, deleted: rowCount };\n  }\n\n  async list(collection: string, userId: string, q?: string) {\n    const table = this.tableFor(collection);\n    if (q) {\n      const { rows } = await this.pool.query(\n        `SELECT data FROM ${table}\n         WHERE user_id = $1 AND (data::text ILIKE $2)\n         ORDER BY COALESCE((data->>'timestamp')::timestamptz, NOW()) DESC`,\n        [userId, `%${q}%`],\n      );\n      return rows.map((r) => r.data);\n    }\n    const { rows } = await this.pool.query(\n      `SELECT data FROM ${table}\n       WHERE user_id = $1\n       ORDER BY COALESCE((data->>'timestamp')::timestamptz, NOW()) DESC`,\n      [userId],\n    );\n    return rows.map((r) => r.data);\n  }\n\n  // List all items from all users (for public collections like links)\n  async listAll(collection: string, q?: string) {\n    const table = this.tableFor(collection);\n    console.log(\n      `🔍 ItemsService - listAll for ${collection}, table: ${table}, q: ${q || \"none\"}`,\n    );\n\n    if (q) {\n      const { rows } = await this.pool.query(\n        `SELECT data FROM ${table}\n         WHERE (data::text ILIKE $1)\n         ORDER BY COALESCE((data->>'createdAt')::timestamptz, (data->>'timestamp')::timestamptz, NOW()) DESC`,\n        [`%${q}%`],\n      );\n      console.log(\n        `📊 ItemsService - listAll with query found ${rows.length} items`,\n      );\n      return rows.map((r) => r.data);\n    }\n    const { rows } = await this.pool.query(\n      `SELECT data FROM ${table}\n       ORDER BY COALESCE((data->>'createdAt')::timestamptz, (data->>'timestamp')::timestamptz, NOW()) DESC`,\n    );\n    console.log(`📊 ItemsService - listAll found ${rows.length} items`);\n    if (rows.length > 0) {\n      console.log(\n        `📊 ItemsService - First item sample:`,\n        JSON.stringify(rows[0].data, null, 2),\n      );\n    } else {\n      console.log(\n        `⚠️ ItemsService - listAll: No rows found for table ${table}`,\n      );\n      // Debug: Check if table exists and has data\n      const countResult = await this.pool.query(\n        `SELECT COUNT(*) as count FROM ${table}`,\n      );\n      console.log(\n        `📊 ItemsService - Table ${table} has ${countResult.rows[0]?.count || 0} total rows`,\n      );\n    }\n    const result = rows.map((r) => r.data);\n    console.log(`📤 ItemsService - listAll returning ${result.length} items`);\n    return result;\n  }\n\n  // Redis Helper Functions\n\n  private async trackUserActivity(\n    userId: string,\n    action: string,\n    collection: string,\n    itemId: string,\n  ) {\n    const activityKey = `activity:${userId}`;\n    const activity = {\n      action,\n      collection,\n      itemId,\n      timestamp: new Date().toISOString(),\n    };\n\n    // Get recent activities (max 50)\n    const recentActivities =\n      (await this.redisCache.get<any[]>(activityKey)) || [];\n    recentActivities.unshift(activity);\n\n    // Keep only last 50 activities\n    if (recentActivities.length > 50) {\n      recentActivities.splice(50);\n    }\n\n    // Store with 1 hour TTL\n    await this.redisCache.set(activityKey, recentActivities, 60 * 60);\n\n    // Also increment daily activity counter\n    const today = new Date().toISOString().split(\"T\")[0];\n    const dailyKey = `daily_activity:${userId}:${today}`;\n    await this.redisCache.increment(dailyKey);\n  }\n\n  private async invalidateListCache(collection: string, userId: string) {\n    const listCacheKey = `list:${collection}:${userId}`;\n    await this.redisCache.delete(listCacheKey);\n  }\n\n  private async incrementCollectionCounter(collection: string) {\n    const counterKey = `popular_collections:${collection}`;\n    await this.redisCache.increment(counterKey);\n  }\n\n  // Public methods for Redis data access\n\n  async getUserActivity(userId: string) {\n    const activityKey = `activity:${userId}`;\n    const activities = (await this.redisCache.get<any[]>(activityKey)) || [];\n\n    const today = new Date().toISOString().split(\"T\")[0];\n    const dailyKey = `daily_activity:${userId}:${today}`;\n    const dailyCount = (await this.redisCache.get<number>(dailyKey)) || 0;\n\n    return {\n      recentActivities: activities.slice(0, 10), // Last 10 activities\n      totalActivities: activities.length,\n      todayActivities: dailyCount,\n      lastActivity: activities[0]?.timestamp || null,\n    };\n  }\n\n  async getPopularCollections() {\n    const keys = await this.redisCache.getKeys(\"popular_collections:*\");\n    const collections = [];\n\n    for (const key of keys) {\n      const collection = key.replace(\"popular_collections:\", \"\");\n      const count = (await this.redisCache.get<number>(key)) || 0;\n      collections.push({ collection, count });\n    }\n\n    return collections.sort((a, b) => b.count - a.count);\n  }\n\n  async getCacheStats() {\n    const itemKeys = await this.redisCache.getKeys(\"item:*\");\n    const listKeys = await this.redisCache.getKeys(\"list:*\");\n    const activityKeys = await this.redisCache.getKeys(\"activity:*\");\n\n    return {\n      cachedItems: itemKeys.length,\n      cachedLists: listKeys.length,\n      userActivities: activityKeys.length,\n      totalCacheEntries:\n        itemKeys.length + listKeys.length + activityKeys.length,\n    };\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/main-improved.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":97,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":97,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3079,3082],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3079,3082],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":97,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":97,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3089,3092],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3089,3092],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":97,"column":40,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":97,"endColumn":43,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3100,3103],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3100,3103],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: NestJS bootstrap entrypoint to configure and start the HTTP server.\n// - Reached from: Node process start (Railway/Docker), runs `bootstrap()`.\n// - Provides: CORS configuration (origin from env), global ValidationPipe, loads dotenv.\n// - Env inputs: PORT, CORS_ORIGIN and DB/Redis envs used indirectly by modules.\n// - Downstream flow: Creates `AppModule` → loads controllers/modules for API routes.\n\n// SECURITY IMPROVEMENTS ADDED:\n// - Environment validation on startup\n// - Enhanced ValidationPipe configuration\n// - Graceful shutdown handling\n// - Better error handling and logging\n\nimport \"reflect-metadata\";\nimport { NestFactory } from \"@nestjs/core\";\nimport { AppModule } from \"./app.module\";\nimport { ValidationPipe, Logger } from \"@nestjs/common\";\nimport * as dotenv from \"dotenv\";\n\n// Validate required environment variables\nfunction validateEnvironment() {\n  const logger = new Logger(\"Bootstrap\");\n\n  const required = [\n    { key: \"GOOGLE_CLIENT_ID\", fallback: \"EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID\" },\n    { key: \"DATABASE_URL\", fallback: null },\n    { key: \"REDIS_URL\", fallback: null },\n  ];\n\n  const missing = [];\n\n  for (const { key, fallback } of required) {\n    if (!process.env[key]) {\n      if (fallback && process.env[fallback]) {\n        logger.warn(`Using ${fallback} as fallback for ${key}`);\n        process.env[key] = process.env[fallback];\n      } else {\n        missing.push(key);\n      }\n    }\n  }\n\n  if (missing.length > 0) {\n    logger.error(\n      `Missing REQUIRED environment variables: ${missing.join(\", \")}`,\n    );\n    logger.error(\"Set these variables or the server will not work properly\");\n    process.exit(1);\n  }\n\n  logger.log(\"✅ Environment validation passed\");\n}\n\nasync function bootstrap() {\n  const logger = new Logger(\"Bootstrap\");\n\n  try {\n    dotenv.config();\n    validateEnvironment();\n\n    logger.log(\"🚀 Starting Karma Community Server...\");\n\n    const app = await NestFactory.create(AppModule, { cors: false });\n    const port = Number(process.env.PORT || 3001);\n\n    const corsOrigin = process.env.CORS_ORIGIN || \"*\";\n    app.enableCors({\n      origin:\n        corsOrigin === \"*\" ? true : corsOrigin.split(\",\").map((s) => s.trim()),\n      credentials: true,\n      methods: [\"GET\", \"HEAD\", \"PUT\", \"PATCH\", \"POST\", \"DELETE\", \"OPTIONS\"],\n      allowedHeaders: [\n        \"Content-Type\",\n        \"Authorization\",\n        \"X-Requested-With\",\n        \"X-Auth-Token\",\n        \"Origin\",\n        \"Accept\",\n      ],\n      preflightContinue: false,\n      optionsSuccessStatus: 204,\n    });\n\n    logger.log(`🌐 CORS enabled for origins: ${corsOrigin}`);\n\n    // Extra CORS fallback middleware (handles proxies not honoring default CORS)\n    const defaultOrigins = [\n      \"https://karma-community-kc.com\",\n      \"https://www.karma-community-kc.com\",\n      \"http://localhost:19006\",\n      \"http://localhost:3000\",\n      \"http://127.0.0.1:3000\",\n    ];\n    const allowedOrigins = process.env.CORS_ORIGIN\n      ? process.env.CORS_ORIGIN.split(\",\").map((s) => s.trim())\n      : defaultOrigins;\n    app.use((req: any, res: any, next: any) => {\n      const origin = req.headers.origin;\n      if (origin && (allowedOrigins.includes(origin) || corsOrigin === \"*\")) {\n        res.header(\"Access-Control-Allow-Origin\", origin);\n        res.header(\"Vary\", \"Origin\");\n      }\n      res.header(\"Access-Control-Allow-Credentials\", \"true\");\n      res.header(\n        \"Access-Control-Allow-Methods\",\n        \"GET,HEAD,PUT,PATCH,POST,DELETE,OPTIONS\",\n      );\n      res.header(\n        \"Access-Control-Allow-Headers\",\n        \"Content-Type, Authorization, X-Requested-With, X-Auth-Token, Origin, Accept\",\n      );\n      if (req.method === \"OPTIONS\") {\n        return res.sendStatus(204);\n      }\n      next();\n    });\n\n    // Enhanced validation pipe with security settings\n    app.useGlobalPipes(\n      new ValidationPipe({\n        whitelist: true,\n        transform: true,\n        forbidNonWhitelisted: true,\n        disableErrorMessages: process.env.NODE_ENV === \"production\",\n        transformOptions: {\n          enableImplicitConversion: true,\n        },\n      }),\n    );\n\n    await app.listen(port, \"0.0.0.0\");\n\n    logger.log(`🚀 Karma Community Server running on port ${port}`);\n    logger.log(`📍 Environment: ${process.env.NODE_ENV || \"development\"}`);\n    logger.log(`🔒 Google OAuth configured: ${!!process.env.GOOGLE_CLIENT_ID}`);\n  } catch (error) {\n    if (error instanceof Error) {\n      logger.error(\"❌ Failed to start server:\", error.message);\n      if (error.stack && process.env.NODE_ENV === \"development\") {\n        logger.error(error.stack);\n      }\n    } else {\n      logger.error(\"❌ Failed to start server: Unknown error\", error);\n    }\n    process.exit(1);\n  }\n}\n\nbootstrap().catch((error) => {\n  console.error(\"Unhandled bootstrap error:\", error);\n  process.exit(1);\n});\n\n// Graceful shutdown handling\nprocess.on(\"SIGTERM\", () => {\n  const logger = new Logger(\"Shutdown\");\n  logger.log(\"🛑 SIGTERM received, shutting down gracefully\");\n  process.exit(0);\n});\n\nprocess.on(\"SIGINT\", () => {\n  const logger = new Logger(\"Shutdown\");\n  logger.log(\"🛑 SIGINT received, shutting down gracefully\");\n  process.exit(0);\n});\n\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n  const logger = new Logger(\"Error\");\n  logger.error(\"Unhandled Rejection at:\", promise, \"reason:\", reason);\n  process.exit(1);\n});\n\nprocess.on(\"uncaughtException\", (error) => {\n  const logger = new Logger(\"Error\");\n  logger.error(\"Uncaught Exception:\", error.message);\n  if (error.stack) {\n    logger.error(error.stack);\n  }\n  process.exit(1);\n});\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/main.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":363,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":363,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13332,13335],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13332,13335],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":363,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":363,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13342,13345],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13342,13345],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":363,"column":40,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":363,"endColumn":43,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13353,13356],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13353,13356],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":377,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":377,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13875,13878],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13875,13878],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":377,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":377,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13885,13888],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13885,13888],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":377,"column":40,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":377,"endColumn":43,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13896,13899],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13896,13899],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":6,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: NestJS bootstrap entrypoint to configure and start the HTTP server with enhanced security.\n// - Reached from: Node process start (Railway/Docker), runs `bootstrap()`.\n// - Provides: CORS configuration, environment validation, global ValidationPipe, graceful shutdown.\n// - Env inputs: PORT, CORS_ORIGIN, GOOGLE_CLIENT_ID, DATABASE_URL, REDIS_URL, NODE_ENV.\n// - Downstream flow: Creates `AppModule` → loads controllers/modules for API routes.\n// - Security: Environment validation, enhanced error handling, proper logging with NestJS Logger.\n//\n// SECURITY IMPROVEMENTS:\n// ✅ Environment validation on startup - prevents silent failures\n// ✅ Enhanced ValidationPipe configuration with security settings\n// ✅ Graceful shutdown handling (SIGTERM, SIGINT)\n// ✅ Better error handling and structured logging\n// ✅ Production-safe error messages (no stack traces in prod)\n// ✅ Helmet.js security headers (XSS, clickjacking, MITM protection)\n// ✅ Global rate limiting via ThrottlerModule\n//\n// TODO: Add request/response logging middleware for audit trail\n// TODO: Add API documentation setup (Swagger/OpenAPI)\n// TODO: Add metrics collection and monitoring setup (Prometheus)\n// TODO: Configure proper timeouts and request size limits\n// TODO: Add CSRF protection for state-changing operations\n\n// MVP: Reduced startup logging (verbose debug banners commented out)\n// console.log('========================================');\n// console.log('🚀 STARTING KC-MVP-SERVER');\n// console.log('📍 Node version:', process.version);\n// console.log('📍 Platform:', process.platform);\n// console.log('📍 CWD:', process.cwd());\n// console.log('========================================');\n// console.log('[DEBUG-H1-H4] Server startup initiated:', JSON.stringify({...}));\n\nimport \"reflect-metadata\";\nimport { NestFactory } from \"@nestjs/core\";\nimport { AppModule } from \"./app.module\";\nimport { ValidationPipe, Logger } from \"@nestjs/common\";\nimport { NestExpressApplication } from \"@nestjs/platform-express\";\nimport * as dotenv from \"dotenv\";\nimport helmet from \"helmet\";\nimport * as bodyParser from \"body-parser\";\nimport \"./sanity\";\n\n// MVP: Reduced startup logging\n// console.log(\"🔥🔥🔥 PROCESS STARTING: src/main.ts LOADED 🔥🔥🔥\");\n// console.log(`Env PORT: ${process.env.PORT}`);\n// console.log(`Env DATABASE_URL exists: ${!!process.env.DATABASE_URL}`);\n\n/**\n * Validate required environment variables before server startup\n *\n * This function ensures all critical environment variables are set,\n * preventing the server from starting in a misconfigured state.\n *\n * Required variables:\n * - GOOGLE_CLIENT_ID: For Google OAuth authentication\n * - DATABASE_URL: PostgreSQL connection string\n * - REDIS_URL: Redis connection string\n * - JWT_SECRET: Secret key for JWT token signing (minimum 32 characters)\n * - ENVIRONMENT: development or production\n *\n * Also validates environment separation to prevent critical errors like:\n * - Connecting dev server to production database\n * - Using production JWT secret in development\n *\n * If any required variable is missing, the process exits with error code 1.\n */\nfunction validateEnvironment(): void {\n  const logger = new Logger(\"Bootstrap\");\n\n  const required = [\n    { key: \"GOOGLE_CLIENT_ID\", fallback: \"EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID\" },\n    { key: \"DATABASE_URL\", fallback: null },\n    // REDIS_URL is now optional - removed from required list\n    { key: \"JWT_SECRET\", fallback: null, minLength: 32 },\n  ];\n\n  const missing: string[] = [];\n  const invalid: Array<{ key: string; requirement: string; current: number }> =\n    [];\n\n  for (const { key, fallback, minLength } of required) {\n    if (!process.env[key]) {\n      if (fallback && process.env[fallback]) {\n        logger.warn(`Using ${fallback} as fallback for ${key}`);\n        process.env[key] = process.env[fallback];\n      } else {\n        missing.push(key);\n      }\n    }\n\n    // Validate minimum length if specified\n    if (minLength && process.env[key] && process.env[key]!.length < minLength) {\n      invalid.push({\n        key,\n        requirement: `minimum ${minLength} characters`,\n        current: process.env[key]!.length,\n      });\n    }\n  }\n\n  if (missing.length > 0) {\n    // [MVP] Agent debug log removed\n    logger.error(\n      `❌ Missing REQUIRED environment variables: ${missing.join(\", \")}`,\n    );\n    logger.error(\"💡 Set these variables in your .env file or environment\");\n    logger.error(\"⚠️  Server cannot start without proper configuration\");\n    if (missing.includes(\"JWT_SECRET\")) {\n      logger.error(\"💡 For JWT_SECRET, generate a secure random string:\");\n      logger.error(\n        \"   node -e \\\"console.log(require('crypto').randomBytes(32).toString('hex'))\\\"\",\n      );\n    }\n    process.exit(1);\n  }\n\n  if (invalid.length > 0) {\n    logger.error(`❌ Invalid environment variables:`);\n    for (const { key, requirement, current } of invalid) {\n      logger.error(\n        `   ${key}: requires ${requirement}, but has ${current} characters`,\n      );\n    }\n    if (invalid.some((v) => v.key === \"JWT_SECRET\")) {\n      logger.error(\"💡 Generate a secure JWT_SECRET (32+ characters):\");\n      logger.error(\n        \"   node -e \\\"console.log(require('crypto').randomBytes(32).toString('hex'))\\\"\",\n      );\n    }\n    process.exit(1);\n  }\n\n  // ═══════════════════════════════════════════════════════════════\n  // ENVIRONMENT SEPARATION VALIDATION\n  // ═══════════════════════════════════════════════════════════════\n  // Validate that environment configuration matches the database\n  // This prevents critical errors like connecting dev to prod DB\n\n  const environment =\n    process.env.ENVIRONMENT || process.env.NODE_ENV || \"unknown\";\n  const databaseUrl = process.env.DATABASE_URL || \"\";\n  const redisUrl = process.env.REDIS_URL || \"\";\n\n  logger.log(\n    `📍 Environment: ${environment.toUpperCase()} ${environment === \"development\" ? \"🟢\" : environment === \"production\" ? \"🔴\" : \"⚪\"}`,\n  );\n\n  // Check DATABASE_URL matches environment\n  if (environment === \"development\") {\n    // DEV should use password: mmWLXgvXF... or host: postgres-a3d6beef\n    if (databaseUrl.includes(\"RHkhivARk\")) {\n      logger.error(\n        \"🚨 CRITICAL: DATABASE_URL appears to be PRODUCTION but ENVIRONMENT is development!\",\n      );\n      logger.error(\n        \"   This would connect your dev server to the production database!\",\n      );\n      logger.error(\n        \"   Fix: Update DATABASE_URL in Railway to use the development Postgres\",\n      );\n      process.exit(1);\n    } else if (\n      databaseUrl.includes(\"mmWLXgvXF\") ||\n      databaseUrl.includes(\"postgres-a3d6beef\")\n    ) {\n      logger.log(\"✅ Database: Development (verified by connection string)\");\n    } else {\n      logger.warn(\n        \"⚠️  Cannot verify database environment from connection string\",\n      );\n    }\n  } else if (environment === \"production\") {\n    // PROD should use password: RHkhivARk...\n    if (\n      databaseUrl.includes(\"mmWLXgvXF\") ||\n      databaseUrl.includes(\"postgres-a3d6beef\")\n    ) {\n      logger.error(\n        \"🚨 CRITICAL: DATABASE_URL appears to be DEVELOPMENT but ENVIRONMENT is production!\",\n      );\n      logger.error(\n        \"   This would connect your prod server to the development database!\",\n      );\n      logger.error(\n        \"   Fix: Update DATABASE_URL in Railway to use the production Postgres\",\n      );\n      process.exit(1);\n    } else if (databaseUrl.includes(\"RHkhivARk\")) {\n      logger.log(\"✅ Database: Production (verified by connection string)\");\n    } else {\n      logger.warn(\n        \"⚠️  Cannot verify database environment from connection string\",\n      );\n    }\n  } else {\n    logger.warn(\n      `⚠️  ENVIRONMENT not set (currently: ${environment}). Set to 'development' or 'production'`,\n    );\n  }\n\n  // Check if Redis is shared (warning only, not critical)\n  const isSharedRedis = redisUrl.includes(\"deQMolmzgWZsqeAkiEpZPFvejfGjenEm\");\n  if (isSharedRedis) {\n    logger.warn(\"⚠️  Redis appears to be SHARED between environments!\");\n    logger.warn(\n      \"   Recommendation: Create separate Redis instances for dev and prod\",\n    );\n    logger.warn(\"   This prevents cache pollution and session mixing\");\n  }\n\n  if (\n    environment === \"development\" &&\n    redisUrl.includes(\"ggCVffISJOmdiIHAXBSQpsQCPfaFbaOR\")\n  ) {\n    logger.log(\"✅ Redis: Development (separate instance)\");\n  } else if (environment === \"production\" && isSharedRedis) {\n    logger.log(\"✅ Redis: Production\");\n  }\n\n  logger.log(\"✅ Environment validation passed\");\n}\n\n/**\n * Bootstrap the NestJS application\n *\n * This is the main entry point that:\n * 1. Loads environment variables\n * 2. Validates required configuration\n * 3. Creates the NestJS application\n * 4. Configures CORS for cross-origin requests\n * 5. Sets up global validation pipes\n * 6. Starts listening on the configured port\n */\nasync function bootstrap(): Promise<void> {\n  const logger = new Logger(\"Bootstrap\");\n\n  try {\n    // Load environment variables from .env file\n    dotenv.config();\n\n    // Validate critical environment variables\n    validateEnvironment();\n\n    // [MVP] Agent debug log removed\n\n    logger.log(\"🚀 Starting Karma Community Server...\");\n\n    // [MVP] Agent debug log removed\n\n    // Create NestJS application instance with Express adapter\n    const app = await NestFactory.create<NestExpressApplication>(AppModule, {\n      cors: false, // We configure CORS manually for more control\n      logger: [\"error\", \"warn\", \"log\", \"debug\", \"verbose\"],\n      bodyParser: false, // Disable default body parser so we can configure it manually\n    });\n\n    // [MVP] Agent debug log removed\n\n    // Configure body parser with 5MB limit (SEC-002, PERF-003)\n    // Use a separate multipart/upload route for larger files\n    app.use(bodyParser.json({ limit: \"5mb\" }));\n    app.use(bodyParser.urlencoded({ limit: \"5mb\", extended: true }));\n\n    logger.log(\"📦 Body parser configured with 5MB limit\");\n\n    const port = Number(process.env.PORT || 3001);\n\n    // SEC-002.2: Security headers via Helmet.js\n    // Minimal config to avoid Railway's nginx buffer overflow (\"upstream sent too big header\")\n    app.use(\n      helmet({\n        contentSecurityPolicy: false, // CSP can be strict — disabled for now to avoid breaking mobile\n        crossOriginEmbedderPolicy: false, // Disabled to allow cross-origin resources\n        crossOriginOpenerPolicy: false, // Disabled to avoid breaking OAuth popups\n        hsts: { maxAge: 31536000 }, // Strict-Transport-Security: 1 year\n        frameguard: { action: \"deny\" }, // X-Frame-Options: DENY — prevents clickjacking\n        noSniff: true, // X-Content-Type-Options: nosniff\n        xssFilter: true, // X-XSS-Protection: 1; mode=block\n        referrerPolicy: { policy: \"strict-origin-when-cross-origin\" },\n      }),\n    );\n\n    logger.log(\"🛡️  Helmet.js security headers enabled (SEC-002.2)\");\n\n    // Determine environment for CORS configuration\n    const environment =\n      process.env.ENVIRONMENT || process.env.NODE_ENV || \"development\";\n    const isProduction = environment === \"production\";\n\n    // Configure CORS (Cross-Origin Resource Sharing)\n    let corsOrigin = process.env.CORS_ORIGIN;\n\n    // Remove surrounding quotes if present (Railway sometimes includes them)\n    if (corsOrigin && corsOrigin.startsWith('\"') && corsOrigin.endsWith('\"')) {\n      corsOrigin = corsOrigin.slice(1, -1);\n      logger.log(\"🔧 Removed surrounding quotes from CORS_ORIGIN\");\n    }\n\n    if (!corsOrigin) {\n      logger.warn(\n        \"⚠️  WARNING: CORS_ORIGIN not set! Using default origins based on environment.\",\n      );\n    }\n\n    // Default origins based on environment\n    const defaultOrigins = isProduction\n      ? [\"https://karma-community-kc.com\", \"https://www.karma-community-kc.com\"]\n      : [\n          \"https://dev.karma-community-kc.com\",\n          \"http://localhost:19006\",\n          \"http://localhost:3000\",\n          \"http://localhost:8081\",\n          \"http://127.0.0.1:3000\",\n        ];\n\n    const allowedOrigins = corsOrigin\n      ? corsOrigin.split(\",\").map((s) => s.trim())\n      : defaultOrigins;\n\n    // Force include development domains if not in production\n    // This ensures that even if CORS_ORIGIN is set in Railway but missing the dev domain, it still works\n    if (!isProduction) {\n      const devDomains = [\n        \"https://dev.karma-community-kc.com\",\n        \"http://localhost:19006\",\n        \"http://localhost:3000\",\n        \"http://localhost:8081\",\n      ];\n\n      // Add unique domains\n      devDomains.forEach((domain) => {\n        if (!allowedOrigins.includes(domain)) {\n          allowedOrigins.push(domain);\n        }\n      });\n\n      logger.log(\n        `🔧 Forced inclusion of development domains in CORS allowed origins`,\n      );\n    }\n\n    app.enableCors({\n      origin: allowedOrigins,\n      credentials: true,\n      methods: [\"GET\", \"HEAD\", \"PUT\", \"PATCH\", \"POST\", \"DELETE\", \"OPTIONS\"],\n      allowedHeaders: [\n        \"Content-Type\",\n        \"Authorization\",\n        \"X-Requested-With\",\n        \"X-Auth-Token\",\n        \"Origin\",\n        \"Accept\",\n      ],\n      preflightContinue: false,\n      optionsSuccessStatus: 204,\n      exposedHeaders: [\n        \"Cross-Origin-Opener-Policy\",\n        \"Cross-Origin-Embedder-Policy\",\n      ],\n    });\n\n    // Add Cross-Origin-Opener-Policy header for Google OAuth\n    app.use((req: any, res: any, next: any) => {\n      res.setHeader(\"Cross-Origin-Opener-Policy\", \"same-origin-allow-popups\");\n      res.setHeader(\"Cross-Origin-Embedder-Policy\", \"unsafe-none\");\n      next();\n    });\n\n    logger.log(\n      `🌐 CORS enabled for ${isProduction ? \"PRODUCTION\" : \"DEVELOPMENT\"} environment`,\n    );\n    logger.log(`🌐 Allowed origins: ${allowedOrigins.join(\", \")}`);\n\n    // Extra CORS fallback middleware for proxy compatibility\n    // Some proxies don't properly forward CORS headers, so we add them manually\n\n    app.use((req: any, res: any, next: any) => {\n      const origin = req.headers.origin;\n\n      // Only set CORS headers if origin is in allowed list\n      if (origin && allowedOrigins.includes(origin)) {\n        res.header(\"Access-Control-Allow-Origin\", origin);\n        res.header(\"Vary\", \"Origin\");\n        res.header(\"Access-Control-Allow-Credentials\", \"true\");\n        res.header(\n          \"Access-Control-Allow-Methods\",\n          \"GET,HEAD,PUT,PATCH,POST,DELETE,OPTIONS\",\n        );\n        res.header(\n          \"Access-Control-Allow-Headers\",\n          \"Content-Type, Authorization, X-Requested-With, X-Auth-Token, Origin, Accept\",\n        );\n\n        // Handle preflight requests\n        if (req.method === \"OPTIONS\") {\n          return res.sendStatus(204);\n        }\n      } else if (origin && !isProduction) {\n        // In development, log blocked origins for debugging\n        logger.warn(\n          `🚫 Blocked CORS request from origin: ${origin} (not in allowed list)`,\n        );\n      } else if (origin && isProduction) {\n        // In production, silently block unauthorized origins (security)\n        // Don't set any CORS headers, browser will block the request\n      }\n\n      next();\n    });\n\n    // Configure global validation pipe with security settings\n    // This automatically validates all incoming requests against DTOs\n    app.useGlobalPipes(\n      new ValidationPipe({\n        whitelist: true, // Strip properties that don't have decorators\n        transform: true, // Automatically transform payloads to DTO instances\n        forbidNonWhitelisted: true, // Throw error if non-whitelisted properties exist\n        disableErrorMessages: isProduction, // Hide detailed errors in production\n        transformOptions: {\n          enableImplicitConversion: true, // Convert string numbers to actual numbers\n        },\n      }),\n    );\n\n    // Start the HTTP server\n    await app.listen(port, \"0.0.0.0\");\n\n    // H5/PERF-003.1: Set server timeout to 30s to prevent hung connections\n    const httpServer = app.getHttpServer();\n    httpServer.setTimeout(30000);\n\n    // Log successful startup with configuration summary\n    const isDevelopment = environment === \"development\";\n    logger.log(\"═══════════════════════════════════════════════════\");\n    logger.log(\"🚀 Karma Community Server started successfully!\");\n    logger.log(\"═══════════════════════════════════════════════════\");\n    logger.log(`📍 Port: ${port}`);\n    logger.log(\n      `📍 Environment: ${environment.toUpperCase()} ${isProduction ? \"🔴 PRODUCTION\" : isDevelopment ? \"🟢 DEVELOPMENT\" : \"🟡 OTHER\"}`,\n    );\n    logger.log(\n      `🔒 Google OAuth: ${process.env.GOOGLE_CLIENT_ID ? \"✅ Configured\" : \"❌ Not configured\"}`,\n    );\n\n    // Show database connection details (masked for security)\n    const dbUrl = process.env.DATABASE_URL;\n    if (dbUrl) {\n      try {\n        const dbUrlObj = new URL(dbUrl);\n        const dbName = dbUrlObj.pathname.replace(\"/\", \"\") || \"unknown\";\n        const dbHost = dbUrlObj.hostname || \"unknown\";\n        logger.log(`💾 Database: ✅ Connected to ${dbName}@${dbHost}`);\n      } catch {\n        logger.log(`💾 Database: ✅ Connected (URL configured)`);\n      }\n    } else {\n      logger.log(`💾 Database: ❌ Not connected - DATABASE_URL missing!`);\n    }\n\n    // Show Redis connection details (masked for security)\n    const redisUrl = process.env.REDIS_URL;\n    if (redisUrl) {\n      try {\n        const redisUrlObj = new URL(redisUrl);\n        const redisHost = redisUrlObj.hostname || \"unknown\";\n        logger.log(`⚡ Redis: ✅ Connected to ${redisHost}`);\n      } catch {\n        logger.log(`⚡ Redis: ✅ Connected (URL configured)`);\n      }\n    } else {\n      logger.log(`⚡ Redis: ❌ Not connected - REDIS_URL missing!`);\n    }\n\n    // Warn if running in production without proper environment flag\n    if (\n      isProduction &&\n      !process.env.ENVIRONMENT &&\n      process.env.NODE_ENV !== \"production\"\n    ) {\n      logger.warn(\n        '⚠️  WARNING: Running in production mode but ENVIRONMENT is not explicitly set to \"production\"',\n      );\n    }\n\n    // [MVP] Agent debug log removed\n\n    logger.log(\"═══════════════════════════════════════════════════\");\n  } catch (error) {\n    // [MVP] Agent debug log removed\n\n    // Handle startup errors gracefully\n    if (error instanceof Error) {\n      logger.error(\"❌ Failed to start server:\", error.message);\n      // Use environment variable if available, otherwise default to development\n      const errorEnv =\n        process.env.ENVIRONMENT || process.env.NODE_ENV || \"development\";\n      const isProduction = errorEnv === \"production\";\n      if (error.stack && !isProduction) {\n        logger.error(\"Stack trace:\", error.stack);\n      }\n    } else {\n      logger.error(\"❌ Failed to start server: Unknown error\", error);\n    }\n    process.exit(1);\n  }\n}\n\n// Start the application\nbootstrap().catch((error) => {\n  console.error(\"❌ Unhandled bootstrap error:\", error);\n  console.error(\"Stack:\", error?.stack);\n  process.exit(1);\n});\n\n// ═══════════════════════════════════════════════════════════════\n// GRACEFUL SHUTDOWN HANDLERS\n// ═══════════════════════════════════════════════════════════════\n\n/**\n * Handle SIGTERM signal (sent by process managers like PM2, Docker, Kubernetes)\n * Allows the application to clean up resources before exiting\n */\nprocess.on(\"SIGTERM\", () => {\n  const logger = new Logger(\"Shutdown\");\n  logger.log(\"🛑 SIGTERM signal received, shutting down gracefully...\");\n  logger.log(\"👋 Closing database connections and cleaning up resources\");\n  process.exit(0);\n});\n\n/**\n * Handle SIGINT signal (Ctrl+C in terminal)\n * Allows developers to stop the server cleanly during development\n */\nprocess.on(\"SIGINT\", () => {\n  const logger = new Logger(\"Shutdown\");\n  logger.log(\"🛑 SIGINT signal received (Ctrl+C), shutting down gracefully...\");\n  logger.log(\"👋 Goodbye!\");\n  process.exit(0);\n});\n\n/**\n * Handle unhandled promise rejections\n * These are programming errors that should be caught and fixed\n */\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n  const logger = new Logger(\"Error\");\n  logger.error(\"❌ Unhandled Promise Rejection detected!\");\n  logger.error(\"Promise:\", promise);\n  logger.error(\"Reason:\", reason);\n  logger.error(\"⚠️  This is a programming error that should be fixed\");\n  process.exit(1);\n});\n\n/**\n * Handle uncaught exceptions\n * These are critical errors that should crash the application\n */\nprocess.on(\"uncaughtException\", (error) => {\n  const logger = new Logger(\"Error\");\n  logger.error(\"❌ Uncaught Exception detected!\");\n  logger.error(\"Error:\", error.message);\n  if (error.stack) {\n    logger.error(\"Stack trace:\", error.stack);\n  }\n  logger.error(\"⚠️  Application will exit due to critical error\");\n  process.exit(1);\n});\n\nimport \"./sanity\";\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/minimal-server.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/redis/redis-cache.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/redis/redis-cache.service.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":23,"column":33,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":23,"endColumn":36,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[760,763],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[760,763],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":31,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":31,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1021,1024],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1021,1024],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":37,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":37,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1217,1220],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1217,1220],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":46,"column":17,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":46,"endColumn":20,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1375,1378],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1375,1378],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":71,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":71,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1935,1938],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1935,1938],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":97,"column":43,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":97,"endColumn":46,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2573,2576],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2573,2576],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":112,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":112,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2993,2996],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2993,2996],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":124,"column":28,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":124,"endColumn":31,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3208,3211],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3208,3211],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":155,"column":42,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":155,"endColumn":45,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4093,4096],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4093,4096],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":172,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":172,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4568,4571],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4568,4571],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":187,"column":25,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":187,"endColumn":28,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5156,5159],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5156,5159],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":11,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: High-level Redis helper service for set/get/delete/exists/keys and counters.\n// - Reached from: Injected into controllers/services for caching and stats.\n// - Provides: JSON serialization, TTL, increment, info dump for debugging.\nimport { Injectable, Inject } from \"@nestjs/common\";\nimport Redis from \"ioredis\";\nimport { REDIS } from \"./redis.module\";\n\n@Injectable()\nexport class RedisCacheService {\n  constructor(@Inject(REDIS) private readonly redis: Redis | null) {}\n\n  /**\n   * Check if Redis is available\n   */\n  private isRedisAvailable(): boolean {\n    return this.redis !== null && this.redis.status === \"ready\";\n  }\n\n  /**\n   * Store data in Redis with optional TTL (Time To Live)\n   */\n  async set(key: string, value: any, ttlSeconds?: number): Promise<void> {\n    if (!this.isRedisAvailable()) return;\n\n    const serializedValue = JSON.stringify(value);\n\n    if (ttlSeconds) {\n      try {\n        await this.redis!.setex(key, ttlSeconds, serializedValue);\n      } catch (error: any) {\n        console.warn(`[RedisCache] Failed to setex key ${key}:`, error.message);\n      }\n    } else {\n      try {\n        await this.redis!.set(key, serializedValue);\n      } catch (error: any) {\n        console.warn(`[RedisCache] Failed to set key ${key}:`, error.message);\n      }\n    }\n  }\n\n  /**\n   * Get data from Redis\n   */\n  async get<T = any>(key: string): Promise<T | null> {\n    if (!this.isRedisAvailable()) return null;\n\n    const value = await this.redis!.get(key);\n\n    if (!value) {\n      return null;\n    }\n\n    try {\n      return JSON.parse(value);\n    } catch {\n      // If parsing fails, return the raw string\n      return value as T;\n    }\n  }\n\n  /**\n   * Delete a key from Redis\n   */\n  async delete(key: string): Promise<boolean> {\n    if (!this.isRedisAvailable()) return false;\n    try {\n      const result = await this.redis!.del(key);\n      return result > 0;\n    } catch (error: any) {\n      console.warn(`[RedisCache] Failed to delete key ${key}:`, error.message);\n      return false;\n    }\n  }\n\n  /**\n   * Check if key exists\n   */\n  async exists(key: string): Promise<boolean> {\n    if (!this.isRedisAvailable()) return false;\n    const result = await this.redis!.exists(key);\n    return result === 1;\n  }\n\n  /**\n   * Get all keys matching a pattern\n   */\n  async getKeys(pattern: string = \"*\"): Promise<string[]> {\n    if (!this.isRedisAvailable()) return [];\n    return await this.redis!.keys(pattern);\n  }\n\n  /**\n   * Set with expiration (alias for set with TTL)\n   */\n  async setWithExpiry(key: string, value: any, seconds: number): Promise<void> {\n    return this.set(key, value, seconds);\n  }\n\n  /**\n   * Increment a numeric value\n   */\n  async increment(key: string, amount: number = 1): Promise<number> {\n    if (!this.isRedisAvailable()) return 0;\n    try {\n      if (amount === 1) {\n        return await this.redis!.incr(key);\n      } else {\n        return await this.redis!.incrby(key, amount);\n      }\n    } catch (error: any) {\n      console.warn(\n        `[RedisCache] Failed to increment key ${key}:`,\n        error.message,\n      );\n      return 0;\n    }\n  }\n\n  /**\n   * Get Redis info for debugging\n   */\n  async getInfo(): Promise<any> {\n    if (!this.isRedisAvailable()) {\n      return {\n        connected: false,\n        keyCount: 0,\n        info: \"Redis not configured\",\n      };\n    }\n\n    const info = await this.redis!.info();\n    const keyCount = await this.redis!.dbsize();\n\n    return {\n      connected: this.redis!.status === \"ready\",\n      keyCount,\n      info: info.split(\"\\r\\n\").slice(0, 10).join(\"\\n\"), // First 10 lines\n    };\n  }\n\n  /**\n   * Set multiple keys at once using Redis pipeline for better performance\n   * This is more efficient than calling set() multiple times as it batches operations\n   *\n   * @param entries Array of key-value pairs with optional TTL\n   * @example\n   * await redisCache.setMultiple([\n   *   { key: 'user:1', value: userData, ttl: 600 },\n   *   { key: 'user:2', value: userData2, ttl: 600 }\n   * ]);\n   */\n  async setMultiple(\n    entries: Array<{ key: string; value: any; ttl?: number }>,\n  ): Promise<void> {\n    if (!this.isRedisAvailable() || entries.length === 0) return;\n\n    const pipeline = this.redis!.pipeline();\n\n    for (const entry of entries) {\n      const serializedValue = JSON.stringify(entry.value);\n      if (entry.ttl) {\n        pipeline.setex(entry.key, entry.ttl, serializedValue);\n      } else {\n        pipeline.set(entry.key, serializedValue);\n      }\n    }\n\n    try {\n      await pipeline.exec();\n    } catch (error: any) {\n      console.warn(`[RedisCache] Failed to setMultiple:`, error.message);\n    }\n  }\n\n  /**\n   * Get multiple keys at once using Redis pipeline for better performance\n   * Returns a Map where keys are the cache keys and values are the cached data (or null if not found)\n   *\n   * @param keys Array of cache keys to retrieve\n   * @returns Map of key -> value pairs (null if key doesn't exist)\n   * @example\n   * const results = await redisCache.getMultiple(['user:1', 'user:2', 'user:3']);\n   * const user1 = results.get('user:1'); // User data or null\n   */\n  async getMultiple<T = any>(keys: string[]): Promise<Map<string, T | null>> {\n    if (!this.isRedisAvailable() || keys.length === 0) return new Map();\n\n    const pipeline = this.redis!.pipeline();\n    keys.forEach((key) => pipeline.get(key));\n\n    const results = await pipeline.exec();\n    const map = new Map<string, T | null>();\n\n    if (results) {\n      for (let i = 0; i < keys.length; i++) {\n        const result = results[i];\n        const key = keys[i];\n\n        if (result && result[1] !== null) {\n          try {\n            map.set(key, JSON.parse(result[1] as string));\n          } catch {\n            // If parsing fails, return the raw string\n            map.set(key, result[1] as T);\n          }\n        } else {\n          map.set(key, null);\n        }\n      }\n    }\n\n    return map;\n  }\n\n  /**\n   * Invalidate all keys matching a pattern efficiently using Redis pipeline\n   * This is more efficient than manually getting keys and deleting them one by one\n   *\n   * @param pattern Redis key pattern (supports wildcards like 'user:*', 'stats_*')\n   * @returns Number of keys deleted\n   * @example\n   * const deletedCount = await redisCache.invalidatePattern('user_stats_*');\n   */\n  async invalidatePattern(pattern: string): Promise<number> {\n    if (!this.isRedisAvailable()) return 0;\n\n    try {\n      const keys = await this.getKeys(pattern);\n      if (keys.length === 0) return 0;\n\n      // Use pipeline for better performance\n      const pipeline = this.redis!.pipeline();\n      keys.forEach((key) => pipeline.del(key));\n      await pipeline.exec();\n\n      return keys.length;\n    } catch (error) {\n      // Log error but don't throw - cache clearing should not fail the operation\n      console.warn(`Failed to invalidate cache pattern ${pattern}:`, error);\n      return 0;\n    }\n  }\n\n  /**\n   * Clear all statistics-related caches\n   * This is used when user data changes (new user registered, etc.)\n   * to ensure statistics are refreshed immediately\n   */\n  async clearStatsCaches(): Promise<void> {\n    const patterns = [\n      \"community_stats_*\",\n      \"community_trends_*\",\n      \"city_stats_*\",\n      \"dashboard_stats\",\n      \"real_time_stats\",\n      \"category_analytics\",\n      \"user_analytics\",\n      \"community_stats_version_*\",\n    ];\n\n    for (const pattern of patterns) {\n      await this.invalidatePattern(pattern);\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/redis/redis.module.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":140,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":140,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4800,4803],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4800,4803],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Provide a global Redis client via DI token `REDIS` using ioredis with Railway-friendly config.\n// - Reached from: Imported by `AppModule` and `RedisCacheModule`.\n// - Env inputs: `REDIS_URL`/`REDIS_PUBLIC_URL`/Upstash vars or host/port + TLS flags.\n// - Provides: Connection with logging hooks; masks secrets in logs.\n// src/redis/redis.module.ts\nimport { Global, Module } from \"@nestjs/common\";\nimport Redis from \"ioredis\";\n\nexport const REDIS = \"REDIS\";\n\n@Global()\n@Module({\n  providers: [\n    {\n      provide: REDIS,\n      useFactory: () => {\n        // Check if Redis is configured - if not, return null (optional Redis)\n        const redisUrl =\n          process.env.REDIS_URL ||\n          process.env.REDIS_PUBLIC_URL ||\n          process.env.UPSTASH_REDIS_URL;\n        const internalHost =\n          process.env.REDIS_HOST ||\n          process.env.REDISHOST ||\n          process.env.UPSTASH_REDIS_HOST;\n        const internalPort =\n          process.env.REDIS_PORT ||\n          process.env.REDISPORT ||\n          process.env.UPSTASH_REDIS_PORT;\n\n        // If no Redis configuration is provided, return null (Redis is optional)\n        if (!redisUrl && (!internalHost || !internalPort)) {\n          // eslint-disable-next-line no-console\n          console.warn(\n            \"[redis] ⚠️  No Redis configuration found - running without Redis cache\",\n          );\n          // eslint-disable-next-line no-console\n          console.warn(\n            \"[redis] 💡 To enable Redis, set REDIS_URL environment variable\",\n          );\n          return null;\n        }\n\n        // Railway Redis may expose rediss:// or REDIS_TLS=true\n        const tlsEnabledEnv =\n          String(\n            process.env.REDIS_TLS || process.env.REDIS_SSL || \"\",\n          ).toLowerCase() === \"true\";\n\n        const commonOptions = {\n          username:\n            process.env.REDIS_USERNAME ||\n            process.env.REDISUSER ||\n            process.env.UPSTASH_REDIS_USERNAME ||\n            undefined,\n          password:\n            process.env.REDIS_PASSWORD ||\n            process.env.REDISPASSWORD ||\n            process.env.UPSTASH_REDIS_PASSWORD ||\n            undefined,\n          connectTimeout: 15000,\n          maxRetriesPerRequest: 3,\n          enableReadyCheck: true,\n          retryStrategy: (times: number) => Math.min(times * 200, 2000),\n          reconnectOnError: (err: Error) =>\n            /READONLY|ETIMEDOUT|ECONNRESET/i.test(err.message),\n          family: 4,\n          // Disable offline queue to prevent memory issues\n          enableOfflineQueue: false,\n          // Limit retry attempts to prevent infinite loops\n          lazyConnect: false,\n        } as const;\n\n        // ALWAYS prefer a single connection URL when available (most reliable)\n        if (redisUrl) {\n          let enableTls = tlsEnabledEnv;\n          try {\n            const parsed = new URL(redisUrl);\n            const isRediss = parsed.protocol === \"rediss:\";\n            if (isRediss) enableTls = true;\n          } catch {\n            // ignore parse errors – fall back to env flag only\n          }\n\n          const client = new Redis(redisUrl, {\n            tls: enableTls ? {} : undefined,\n            ...commonOptions,\n          });\n          attachRedisLogging(client, maskRedisUrl(redisUrl));\n          return client;\n        }\n\n        // Fallback to host/port configuration\n        const client = new Redis({\n          host: internalHost!,\n          port: Number(internalPort),\n          tls: tlsEnabledEnv ? {} : undefined,\n          ...commonOptions,\n        });\n        attachRedisLogging(client, `redis://${internalHost}:${internalPort}`);\n        return client;\n      },\n    },\n  ],\n  exports: [REDIS],\n})\nexport class RedisModule {}\n\nfunction maskRedisUrl(url: string): string {\n  try {\n    const u = new URL(url);\n    if (u.password) u.password = \"*\".repeat(3);\n    return u.toString();\n  } catch {\n    return url.replace(/:(?:[^@/]+)@/, \":***@\");\n  }\n}\n\nfunction attachRedisLogging(client: Redis, target: string) {\n  // eslint-disable-next-line no-console\n  console.log(`[redis] connecting to ${target}`);\n  client.on(\"connect\", () => {\n    // eslint-disable-next-line no-console\n    console.log(\"[redis] socket connected\");\n  });\n  client.on(\"ready\", async () => {\n    // eslint-disable-next-line no-console\n    console.log(\"[redis] ready\");\n\n    // Attempt to fix MISCONF error for dev environments\n    try {\n      // eslint-disable-next-line no-console\n      console.log(\n        \"[redis] attempting to disable stop-writes-on-bgsave-error...\",\n      );\n      await client.config(\"SET\", \"stop-writes-on-bgsave-error\", \"no\");\n      // eslint-disable-next-line no-console\n      console.log(\"[redis] successfully disabled stop-writes-on-bgsave-error\");\n    } catch (err: any) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        \"[redis] failed to disable stop-writes-on-bgsave-error (might be restricted):\",\n        err.message,\n      );\n    }\n  });\n  client.on(\"end\", () => {\n    // eslint-disable-next-line no-console\n    console.log(\"[redis] connection ended\");\n  });\n  client.on(\"error\", (err) => {\n    // eslint-disable-next-line no-console\n    console.error(\"[redis] error\", err.message);\n  });\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/sanity.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/add-google-id-column.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":80,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":80,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2528,2531],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2528,2531],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Script to add google_id column to user_profiles table\n * Run with: npm run add:google-id or ts-node -r tsconfig-paths/register src/scripts/add-google-id-column.ts\n */\n\nimport { Pool } from \"pg\";\nimport * as dotenv from \"dotenv\";\n\ndotenv.config();\n\nasync function addGoogleIdColumn() {\n  const connectionString = process.env.DATABASE_URL;\n  if (!connectionString) {\n    throw new Error(\"DATABASE_URL environment variable is required\");\n  }\n  const pool = new Pool({ connectionString });\n\n  const client = await pool.connect();\n\n  try {\n    await client.query(\"BEGIN\");\n\n    console.log(\"📝 Checking if google_id column exists...\");\n\n    // Check if column exists\n    const columnCheck = await client.query(`\n      SELECT column_name \n      FROM information_schema.columns \n      WHERE table_name = 'user_profiles' AND column_name = 'google_id'\n    `);\n\n    if (columnCheck.rows.length === 0) {\n      console.log(\"📝 google_id column does not exist, creating it...\");\n      await client.query(`\n        ALTER TABLE user_profiles ADD COLUMN google_id TEXT;\n      `);\n      console.log(\"✅ google_id column created\");\n    } else {\n      console.log(\"✅ google_id column already exists\");\n    }\n\n    // Check if unique constraint exists\n    const constraintCheck = await client.query(`\n      SELECT conname \n      FROM pg_constraint \n      WHERE conname = 'user_profiles_google_id_key'\n    `);\n\n    if (constraintCheck.rows.length === 0) {\n      console.log(\n        \"📝 google_id unique constraint does not exist, creating it...\",\n      );\n      await client.query(`\n        ALTER TABLE user_profiles ADD CONSTRAINT user_profiles_google_id_key UNIQUE (google_id);\n      `);\n      console.log(\"✅ google_id unique constraint created\");\n    } else {\n      console.log(\"✅ google_id unique constraint already exists\");\n    }\n\n    // Check if index exists\n    const indexCheck = await client.query(`\n      SELECT indexname \n      FROM pg_indexes \n      WHERE tablename = 'user_profiles' AND indexname = 'idx_user_profiles_google_id'\n    `);\n\n    if (indexCheck.rows.length === 0) {\n      console.log(\"📝 google_id index does not exist, creating it...\");\n      await client.query(`\n        CREATE INDEX idx_user_profiles_google_id ON user_profiles (google_id) WHERE google_id IS NOT NULL;\n      `);\n      console.log(\"✅ google_id index created\");\n    } else {\n      console.log(\"✅ google_id index already exists\");\n    }\n\n    await client.query(\"COMMIT\");\n    console.log(\"✅ All operations completed successfully\");\n  } catch (error: any) {\n    await client.query(\"ROLLBACK\");\n    console.error(\"❌ Error:\", error.message);\n    throw error;\n  } finally {\n    client.release();\n    await pool.end();\n  }\n}\n\naddGoogleIdColumn()\n  .then(() => {\n    console.log(\"✅ Script completed successfully\");\n    process.exit(0);\n  })\n  .catch((error) => {\n    console.error(\"❌ Script failed:\", error);\n    process.exit(1);\n  });\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/add-image-url-column.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/anonymize-data.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":30,"column":39,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":30,"endColumn":42,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[914,917],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[914,917],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import * as fs from \"fs\";\nimport * as path from \"path\";\n\n/**\n * Script to anonymize sensitive data exported from production\n * Masks emails and phone numbers to protect user privacy in dev environment\n */\nfunction anonymizeData() {\n  const exportDir = path.join(process.cwd(), \"data-export\");\n  const anonymizedDir = path.join(process.cwd(), \"data-export-anonymized\");\n\n  if (!fs.existsSync(exportDir)) {\n    console.error(\"❌ Export directory not found. Run export-data.ts first.\");\n    return;\n  }\n\n  if (!fs.existsSync(anonymizedDir)) {\n    fs.mkdirSync(anonymizedDir);\n  }\n\n  const files = fs.readdirSync(exportDir).filter((f) => f.endsWith(\".json\"));\n\n  for (const file of files) {\n    console.log(`Anonymizing ${file}...`);\n    const data = JSON.parse(\n      fs.readFileSync(path.join(exportDir, file), \"utf8\"),\n    );\n\n    // Logic to identify and mask sensitive fields\n    const anonymized = data.map((row: any) => {\n      const newRow = { ...row };\n\n      // Mask common sensitive fields\n      if (newRow.email) {\n        newRow.email = `user_${Math.random().toString(36).substring(7)}@dev.test`;\n      }\n\n      if (newRow.phone) {\n        newRow.phone = \"0500000000\";\n      }\n\n      if (newRow.phoneNumber) {\n        newRow.phoneNumber = \"0500000000\";\n      }\n\n      // If it's the users table, maybe reset some other fields\n      if (file === \"users.json\" || file === \"Users.json\") {\n        // Keep display names for testing, but mask real identity if needed\n        // newRow.displayName = `Dev User ${row.id.substring(0,4)}`;\n      }\n\n      return newRow;\n    });\n\n    fs.writeFileSync(\n      path.join(anonymizedDir, file),\n      JSON.stringify(anonymized, null, 2),\n    );\n  }\n\n  console.log(`✅ Anonymization completed! Data saved to ${anonymizedDir}`);\n}\n\nanonymizeData();\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/check-environment.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/debug-db.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/export-data.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/fix-super-admins.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":57,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":57,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1685,1688],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1685,1688],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Pool } from \"pg\";\nimport * as dotenv from \"dotenv\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\n// Load environment\nconst envFiles = [\".env.production\", \".env.development\", \".env\"];\nfor (const file of envFiles) {\n  const envPath = path.resolve(process.cwd(), file);\n  if (fs.existsSync(envPath)) {\n    dotenv.config({ path: envPath });\n    break;\n  }\n}\n\nasync function fixSuperAdmins() {\n  const connectionString = process.env.DATABASE_URL;\n  if (!connectionString) {\n    throw new Error(\"DATABASE_URL environment variable is required\");\n  }\n  const pool = new Pool({ connectionString });\n  const client = await pool.connect();\n\n  try {\n    await client.query(\"BEGIN\");\n\n    console.log(\"🔧 Fixing super admins hierarchy levels...\\n\");\n\n    // Get root admin ID\n    const rootAdmin = await client.query(`\n      SELECT id FROM user_profiles WHERE email = 'karmacommunity2.0@gmail.com'\n    `);\n\n    if (rootAdmin.rows.length === 0) {\n      console.log(\"❌ Root admin not found\");\n      await client.query(\"ROLLBACK\");\n      process.exit(1);\n    }\n\n    const rootAdminId = rootAdmin.rows[0].id;\n    console.log(\"✅ Root admin ID:\", rootAdminId);\n\n    // Update super admins\n    const result = await client.query(\n      `\n      UPDATE user_profiles \n      SET hierarchy_level = 1,\n          parent_manager_id = $1\n      WHERE email IN ('navesarussi@gmail.com', 'mahalalel100@gmail.com')\n        AND (parent_manager_id IS DISTINCT FROM $1 OR hierarchy_level IS DISTINCT FROM 1)\n      RETURNING email, hierarchy_level, parent_manager_id\n    `,\n      [rootAdminId],\n    );\n\n    console.log(`\\n✅ Updated ${result.rows.length} super admin(s):`);\n    result.rows.forEach((r: any) => {\n      console.log(\n        `   - ${r.email}: level=${r.hierarchy_level}, parent=${r.parent_manager_id}`,\n      );\n    });\n\n    await client.query(\"COMMIT\");\n    console.log(\"\\n✅ Fix completed successfully!\");\n  } catch (error) {\n    await client.query(\"ROLLBACK\");\n    console.error(\"❌ Fix failed:\", error);\n    process.exit(1);\n  } finally {\n    client.release();\n    await pool.end();\n  }\n}\n\nfixSuperAdmins().catch((err) => {\n  console.error(\"❌ Fatal error:\", err);\n  process.exit(1);\n});\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/import-data.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":105,"column":31,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":105,"endColumn":34,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3140,3143],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3140,3143],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Client } from \"pg\";\nimport * as dotenv from \"dotenv\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\ndotenv.config();\n\nasync function importData() {\n  const connectionString = process.env.DATABASE_URL;\n  if (!connectionString) {\n    console.error(\n      \"❌ DATABASE_URL missing (Set this to your DEV database URL)\",\n    );\n    process.exit(1);\n  }\n\n  const anonymizedDir = path.join(process.cwd(), \"data-export-anonymized\");\n  if (!fs.existsSync(anonymizedDir)) {\n    console.error(\"❌ Anonymized data not found. Run anonymize-data.ts first.\");\n    process.exit(1);\n  }\n\n  const client = new Client({ connectionString });\n\n  try {\n    await client.connect();\n    console.log(\"✅ Connected to target database for import\");\n\n    const files = fs\n      .readdirSync(anonymizedDir)\n      .filter((f) => f.endsWith(\".json\"));\n\n    // Sort files to handle foreign key dependencies (rough order)\n    // You might need to adjust this depending on your schema\n    const order = [\n      \"users\",\n      \"organizations\",\n      \"categories\",\n      \"posts\",\n      \"chats\",\n      \"items\",\n    ];\n    files.sort((a, b) => {\n      const nameA = a.replace(\".json\", \"\").toLowerCase();\n      const nameB = b.replace(\".json\", \"\").toLowerCase();\n      const indexA = order.findIndex((o) => nameA.includes(o));\n      const indexB = order.findIndex((o) => nameB.includes(o));\n      return (indexA === -1 ? 99 : indexA) - (indexB === -1 ? 99 : indexB);\n    });\n\n    for (const file of files) {\n      const tableName = file.replace(\".json\", \"\");\n      console.log(`Importing table: ${tableName}...`);\n\n      const rows = JSON.parse(\n        fs.readFileSync(path.join(anonymizedDir, file), \"utf8\"),\n      );\n      if (rows.length === 0) {\n        console.log(`   Table ${tableName} is empty, skipping.`);\n        continue;\n      }\n\n      // Check if table exists\n      const tableCheck = await client.query(\n        `\n                SELECT EXISTS (\n                    SELECT FROM information_schema.tables \n                    WHERE table_schema = 'public' \n                    AND table_name = $1\n                )\n            `,\n        [tableName],\n      );\n\n      if (!tableCheck.rows[0].exists) {\n        console.log(\n          `   ⚠️  Table ${tableName} does not exist in target database, skipping.`,\n        );\n        continue;\n      }\n\n      // Clean existing data in THIS table only (be careful!)\n      console.log(`   Cleaning table ${tableName}...`);\n      await client.query(`TRUNCATE TABLE \"${tableName}\" CASCADE`);\n\n      // Insert rows\n      const columns = Object.keys(rows[0]);\n      const columnNames = columns.map((c) => `\"${c}\"`).join(\", \");\n\n      let successCount = 0;\n      let errorCount = 0;\n\n      for (let i = 0; i < rows.length; i++) {\n        try {\n          const placeholders = columns\n            .map((_, idx) => `$${idx + 1}`)\n            .join(\", \");\n          const values = columns.map((c) => rows[i][c]);\n\n          await client.query(\n            `INSERT INTO \"${tableName}\" (${columnNames}) VALUES (${placeholders})`,\n            values,\n          );\n          successCount++;\n        } catch (insertError: any) {\n          errorCount++;\n          // Skip rows with data type mismatches (e.g., UUID vs TEXT)\n          if (errorCount <= 3) {\n            console.log(`   ⚠️  Row ${i + 1} skipped: ${insertError.message}`);\n          }\n        }\n      }\n\n      if (errorCount > 3) {\n        console.log(`   ⚠️  ... and ${errorCount - 3} more rows skipped`);\n      }\n      console.log(\n        `   Successfully imported ${successCount} rows into ${tableName}` +\n          (errorCount > 0\n            ? ` (${errorCount} rows skipped due to data type mismatches)`\n            : \"\"),\n      );\n    }\n\n    console.log(\"✅ Import completed successfully!\");\n  } catch (err) {\n    console.error(\"❌ Import failed:\", err);\n  } finally {\n    await client.end();\n  }\n}\n\nimportData();\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/init-db.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":152,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":152,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5280,5283],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5280,5283],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: One-off/dev script to ensure minimal DB schema and indexes exist for local E2E runs.\n// - Reached from: Client script `scripts/run-local-e2e.sh` before starting server.\n// - Provides: Creates `community_stats`, `donation_categories`, relational `donations`, plus a set of JSONB tables for generic items and messaging.\n// - Also: Ensures rides + ride_bookings tables; seeds default categories; prints success on completion.\nimport { Pool } from \"pg\";\nimport * as dotenv from \"dotenv\";\n\ndotenv.config();\n\nasync function run() {\n  const pool = new Pool({\n    host: process.env.POSTGRES_HOST || \"localhost\",\n    port: Number(process.env.POSTGRES_PORT || 5432),\n    user: process.env.POSTGRES_USER || \"kc\",\n    password: process.env.POSTGRES_PASSWORD || \"kc_password\",\n    database: process.env.POSTGRES_DB || \"kc_db\",\n  });\n\n  const client = await pool.connect();\n  try {\n    await client.query('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";');\n    // Minimal relational tables to satisfy new controllers when skipping full schema\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS community_stats (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        stat_type VARCHAR(50) NOT NULL,\n        stat_value BIGINT DEFAULT 0,\n        city VARCHAR(100),\n        date_period DATE,\n        metadata JSONB,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW(),\n        UNIQUE(stat_type, city, date_period)\n      );\n    `);\n    await client.query(\n      \"CREATE INDEX IF NOT EXISTS idx_community_stats_type ON community_stats (stat_type, date_period);\",\n    );\n    await client.query(\n      \"CREATE INDEX IF NOT EXISTS idx_community_stats_city ON community_stats (city, date_period);\",\n    );\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS donation_categories (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        slug VARCHAR(50) UNIQUE NOT NULL,\n        name_he VARCHAR(100) NOT NULL,\n        name_en VARCHAR(100) NOT NULL,\n        description_he TEXT,\n        description_en TEXT,\n        icon VARCHAR(50),\n        color VARCHAR(7),\n        is_active BOOLEAN DEFAULT true,\n        sort_order INTEGER DEFAULT 0,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS donations (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        donor_id UUID,\n        recipient_id UUID,\n        organization_id UUID,\n        category_id UUID,\n        title VARCHAR(255) NOT NULL,\n        description TEXT,\n        amount DECIMAL(10,2),\n        currency VARCHAR(3) DEFAULT 'ILS',\n        type VARCHAR(20) NOT NULL,\n        status VARCHAR(20) DEFAULT 'active',\n        location JSONB,\n        images TEXT[],\n        tags TEXT[],\n        metadata JSONB,\n        expires_at TIMESTAMPTZ,\n        completed_at TIMESTAMPTZ,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n\n    const baseTable = (name: string) => `\n      CREATE TABLE IF NOT EXISTS ${name} (\n        user_id TEXT NOT NULL,\n        item_id TEXT NOT NULL,\n        data JSONB NOT NULL DEFAULT '{}'::jsonb,\n        created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n        updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n        PRIMARY KEY (user_id, item_id)\n      );\n      CREATE INDEX IF NOT EXISTS ${name}_user_idx ON ${name}(user_id);\n      CREATE INDEX IF NOT EXISTS ${name}_item_idx ON ${name}(item_id);\n      CREATE INDEX IF NOT EXISTS ${name}_data_gin ON ${name} USING GIN (data);\n    `;\n\n    const tables = [\n      \"users\",\n      // 'posts' - handled separately as relational table (not JSONB)\n      \"followers\",\n      \"following\",\n      \"chats\",\n      \"messages\",\n      \"notifications\",\n      \"bookmarks\",\n      \"settings\",\n      \"media\",\n      \"blocked_users\",\n      \"message_reactions\",\n      \"typing_status\",\n      \"read_receipts\",\n      \"voice_messages\",\n      \"conversation_metadata\",\n      // Organizations / NGO onboarding\n      \"organizations\",\n      \"org_applications\",\n      // Links (for groups and organizations)\n      \"links\",\n      \"analytics\",\n    ];\n\n    for (const t of tables) {\n      // eslint-disable-next-line no-console\n      console.log(`Ensuring table: ${t}`);\n\n      try {\n        // 1. Create Table\n        await client.query(`\n          CREATE TABLE IF NOT EXISTS ${t} (\n            user_id TEXT NOT NULL,\n            item_id TEXT NOT NULL,\n            data JSONB NOT NULL DEFAULT '{}'::jsonb,\n            created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n            updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n            PRIMARY KEY (user_id, item_id)\n          );\n        `);\n\n        // 2. Create Indexes (Individually)\n        // Check if index exists is tricky in one-liner, but IF NOT EXISTS handles it.\n        // However, we catch errors individually.\n\n        await client.query(\n          `CREATE INDEX IF NOT EXISTS ${t}_user_idx ON ${t}(user_id);`,\n        );\n        await client.query(\n          `CREATE INDEX IF NOT EXISTS ${t}_item_idx ON ${t}(item_id);`,\n        );\n        await client.query(\n          `CREATE INDEX IF NOT EXISTS ${t}_data_gin ON ${t} USING GIN (data);`,\n        );\n      } catch (err: any) {\n        console.error(`❌ Error initializing table '${t}':`, err.message);\n        if (err.code === \"42501\") {\n          // Permission denied - try to grant myself? No.\n          // Check ownership?\n          const res = await client.query(\n            `\n               SELECT tableowner FROM pg_tables WHERE tablename = $1\n            `,\n            [t],\n          );\n          console.log(\n            `Owner of ${t}:`,\n            res.rows[0]?.tableowner || \"Unknown (table might not exist)\",\n          );\n        }\n        throw err;\n      }\n    }\n\n    // Check if tasks table exists in new schema format (with 'title' column)\n    // If it does, skip creating the legacy JSONB version\n    const newTasks = await client.query(`\n      SELECT EXISTS (\n        SELECT 1 FROM information_schema.columns \n        WHERE table_name = 'tasks' AND column_name = 'title'\n      ) AS exists;\n    `);\n\n    if (!newTasks?.rows?.[0]?.exists) {\n      // Create legacy JSONB tasks table only if new schema doesn't exist\n      // eslint-disable-next-line no-console\n      console.log(\"Ensuring table: tasks (legacy JSONB format)\");\n      await client.query(baseTable(\"tasks\"));\n    } else {\n      // eslint-disable-next-line no-console\n      console.log(\n        \"✅ Tasks table exists in new schema format - skipping legacy creation\",\n      );\n    }\n\n    // Index for email lookup in users table\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS users_email_lower_idx ON users ((lower(data->>'email')))`,\n    );\n\n    // If a legacy JSONB donations table exists (with 'data' column) — replace it with relational schema for APIs\n    const legacyDonations = await client.query(`\n      SELECT EXISTS (\n        SELECT 1 FROM information_schema.columns \n        WHERE table_name = 'donations' AND column_name = 'data'\n      ) AS exists;\n    `);\n    if (legacyDonations?.rows?.[0]?.exists) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        \"⚠️  Replacing legacy JSONB donations table with relational schema\",\n      );\n      await client.query(\"DROP TABLE IF EXISTS donations CASCADE;\");\n    }\n    // Ensure relational donations table exists (id/donor_id/...)\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS donations (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        donor_id UUID,\n        recipient_id UUID,\n        organization_id UUID,\n        category_id UUID,\n        title VARCHAR(255) NOT NULL,\n        description TEXT,\n        amount DECIMAL(10,2),\n        currency VARCHAR(3) DEFAULT 'ILS',\n        type VARCHAR(20) NOT NULL,\n        status VARCHAR(20) DEFAULT 'active',\n        location JSONB,\n        images TEXT[],\n        tags TEXT[],\n        metadata JSONB,\n        expires_at TIMESTAMPTZ,\n        completed_at TIMESTAMPTZ,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    // Create indexes only if columns exist (safe on re-run)\n    await client.query(`\n      DO $$\n      BEGIN\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='donations' AND column_name='donor_id'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_donations_donor ON donations (donor_id);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='donations' AND column_name='category_id'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_donations_category ON donations (category_id);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='donations' AND column_name='type'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_donations_type ON donations (type);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='donations' AND column_name='status'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_donations_status ON donations (status);\n        END IF;\n      END$$;\n    `);\n\n    // Ensure rides relational schema (replace legacy JSONB rides if exists)\n    const legacyRides = await client.query(`\n      SELECT EXISTS (\n        SELECT 1 FROM information_schema.columns \n        WHERE table_name = 'rides' AND column_name = 'data'\n      ) AS exists;\n    `);\n    if (legacyRides?.rows?.[0]?.exists) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        \"⚠️  Replacing legacy JSONB rides table with relational schema\",\n      );\n      await client.query(\"DROP TABLE IF EXISTS rides CASCADE;\");\n    }\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS rides (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        driver_id UUID,\n        title VARCHAR(255),\n        from_location JSONB NOT NULL,\n        to_location JSONB NOT NULL,\n        departure_time TIMESTAMPTZ NOT NULL,\n        arrival_time TIMESTAMPTZ,\n        available_seats INTEGER DEFAULT 1,\n        price_per_seat DECIMAL(10,2) DEFAULT 0,\n        description TEXT,\n        requirements TEXT,\n        status VARCHAR(20) DEFAULT 'active',\n        metadata JSONB,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(`\n      DO $$\n      BEGIN\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='rides' AND column_name='driver_id'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_rides_driver ON rides (driver_id);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='rides' AND column_name='departure_time'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_rides_departure ON rides (departure_time);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='rides' AND column_name='status'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_rides_status ON rides (status);\n        END IF;\n      END$$;\n    `);\n    await client.query(`\n      DO $$\n      BEGIN\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns\n          WHERE table_name='rides' AND column_name='from_location'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_rides_from_location ON rides USING GIN (from_location);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns\n          WHERE table_name='rides' AND column_name='to_location'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_rides_to_location ON rides USING GIN (to_location);\n        END IF;\n      END$$;\n    `);\n\n    // Ensure ride_bookings table\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS ride_bookings (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        ride_id UUID,\n        passenger_id UUID,\n        seats_requested INTEGER DEFAULT 1,\n        status VARCHAR(20) DEFAULT 'pending',\n        message TEXT,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW(),\n        UNIQUE(ride_id, passenger_id)\n      );\n    `);\n\n    // Ensure community_events table - required by StatsController\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS community_events (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        organizer_id UUID,\n        organization_id UUID,\n        title VARCHAR(255) NOT NULL,\n        description TEXT,\n        event_date TIMESTAMPTZ NOT NULL,\n        end_date TIMESTAMPTZ,\n        location JSONB,\n        max_attendees INTEGER,\n        current_attendees INTEGER DEFAULT 0,\n        category VARCHAR(50),\n        tags TEXT[],\n        image_url TEXT,\n        is_virtual BOOLEAN DEFAULT false,\n        meeting_link TEXT,\n        status VARCHAR(20) DEFAULT 'active',\n        metadata JSONB,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(\n      \"CREATE INDEX IF NOT EXISTS idx_community_events_date ON community_events (event_date);\",\n    );\n    await client.query(\n      \"CREATE INDEX IF NOT EXISTS idx_community_events_organizer ON community_events (organizer_id);\",\n    );\n    await client.query(\n      \"CREATE INDEX IF NOT EXISTS idx_community_events_status ON community_events (status);\",\n    );\n\n    // Ensure event_attendees table\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS event_attendees (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        event_id UUID,\n        user_id UUID,\n        status VARCHAR(20) DEFAULT 'going',\n        registered_at TIMESTAMPTZ DEFAULT NOW(),\n        UNIQUE(event_id, user_id)\n      );\n    `);\n\n    // Ensure chat_messages table with required columns for StatsController\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS chat_messages (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        conversation_id UUID,\n        sender_id UUID,\n        content TEXT,\n        message_type VARCHAR(20) DEFAULT 'text',\n        file_url TEXT,\n        file_name VARCHAR(255),\n        file_size INTEGER,\n        file_type VARCHAR(100),\n        metadata JSONB,\n        reply_to_id UUID,\n        is_edited BOOLEAN DEFAULT false,\n        edited_at TIMESTAMPTZ,\n        is_deleted BOOLEAN DEFAULT false,\n        deleted_at TIMESTAMPTZ,\n        created_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_chat_messages_conversation ON chat_messages (conversation_id, created_at);`,\n    );\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_chat_messages_sender ON chat_messages (sender_id);`,\n    );\n\n    // Add missing columns to existing chat_messages table if needed\n    await client.query(`\n      DO $$\n      BEGIN\n        IF NOT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='chat_messages' AND column_name='is_deleted'\n        ) THEN\n          ALTER TABLE chat_messages ADD COLUMN is_deleted BOOLEAN DEFAULT false;\n        END IF;\n        IF NOT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='chat_messages' AND column_name='deleted_at'\n        ) THEN\n          ALTER TABLE chat_messages ADD COLUMN deleted_at TIMESTAMPTZ;\n        END IF;\n        IF NOT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='chat_messages' AND column_name='is_edited'\n        ) THEN\n          ALTER TABLE chat_messages ADD COLUMN is_edited BOOLEAN DEFAULT false;\n        END IF;\n        IF NOT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='chat_messages' AND column_name='edited_at'\n        ) THEN\n          ALTER TABLE chat_messages ADD COLUMN edited_at TIMESTAMPTZ;\n        END IF;\n      END$$;\n    `);\n\n    // Ensure chat_conversations table\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS chat_conversations (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        title VARCHAR(255),\n        type VARCHAR(20) DEFAULT 'direct',\n        participants UUID[] NOT NULL DEFAULT ARRAY[]::UUID[],\n        created_by UUID,\n        last_message_id UUID,\n        last_message_at TIMESTAMPTZ DEFAULT NOW(),\n        metadata JSONB,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_chat_conversations_participants ON chat_conversations USING GIN (participants);`,\n    );\n\n    // Ensure user_profiles table - required by StatsController\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS user_profiles (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        user_id TEXT UNIQUE,\n        email VARCHAR(255),\n        name VARCHAR(255),\n        phone VARCHAR(50),\n        city VARCHAR(100),\n        address TEXT,\n        profile_image TEXT,\n        bio TEXT,\n        date_of_birth DATE,\n        gender VARCHAR(20),\n        join_date TIMESTAMPTZ DEFAULT NOW(),\n        is_active BOOLEAN DEFAULT true,\n        is_verified BOOLEAN DEFAULT false,\n        last_active TIMESTAMPTZ DEFAULT NOW(),\n        karma_points INTEGER DEFAULT 0,\n        total_donations INTEGER DEFAULT 0,\n        total_received INTEGER DEFAULT 0,\n        is_recurring BOOLEAN DEFAULT false,\n        notification_preferences JSONB DEFAULT '{}'::jsonb,\n        privacy_settings JSONB DEFAULT '{}'::jsonb,\n        metadata JSONB DEFAULT '{}'::jsonb,\n        created_at TIMESTAMPTZ DEFAULT NOW(),\n        updated_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    // Create indexes only if columns exist (safe on re-run)\n    await client.query(`\n      DO $$\n      BEGIN\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='user_profiles' AND column_name='user_id'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_user_profiles_user_id ON user_profiles (user_id);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='user_profiles' AND column_name='email'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_user_profiles_email ON user_profiles (LOWER(email));\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='user_profiles' AND column_name='city'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_user_profiles_city ON user_profiles (city);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='user_profiles' AND column_name='is_active'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_user_profiles_is_active ON user_profiles (is_active);\n        END IF;\n        IF EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name='user_profiles' AND column_name='last_active'\n        ) THEN\n          CREATE INDEX IF NOT EXISTS idx_user_profiles_last_active ON user_profiles (last_active);\n        END IF;\n      END$$;\n    `);\n\n    // Ensure posts table - relational table (not JSONB)\n    // Check if posts table exists and what schema it has\n    const postsTableExists = await client.query(`\n      SELECT EXISTS (\n        SELECT 1 FROM information_schema.tables \n        WHERE table_name = 'posts'\n      ) AS exists;\n    `);\n\n    if (postsTableExists?.rows?.[0]?.exists) {\n      // Check if it's legacy JSONB format (has 'user_id' and 'item_id' columns instead of 'author_id')\n      const legacyPostsCheck = await client.query(`\n        SELECT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name = 'posts' AND column_name = 'user_id'\n        ) AS exists;\n      `);\n      const hasAuthorId = await client.query(`\n        SELECT EXISTS (\n          SELECT 1 FROM information_schema.columns \n          WHERE table_name = 'posts' AND column_name = 'author_id'\n        ) AS exists;\n      `);\n\n      if (\n        legacyPostsCheck?.rows?.[0]?.exists &&\n        !hasAuthorId?.rows?.[0]?.exists\n      ) {\n        // eslint-disable-next-line no-console\n        console.warn(\n          \"⚠️  Replacing legacy JSONB posts table with relational schema\",\n        );\n        await client.query(\"DROP TABLE IF EXISTS posts CASCADE;\");\n      }\n    }\n\n    // Check if posts table exists with correct structure (author_id column)\n    const postsCheck = await client.query(`\n      SELECT EXISTS (\n        SELECT 1 FROM information_schema.columns \n        WHERE table_name = 'posts' AND column_name = 'author_id'\n      ) AS exists;\n    `);\n    if (!postsCheck?.rows?.[0]?.exists) {\n      // eslint-disable-next-line no-console\n      console.log(\"Ensuring table: posts (relational schema)\");\n      // Create task_id without foreign key constraint first (tasks table might not exist yet)\n      await client.query(`\n        CREATE TABLE IF NOT EXISTS posts (\n          id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n          author_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,\n          task_id UUID,\n          title VARCHAR(255) NOT NULL,\n          description TEXT,\n          images TEXT[],\n          likes INTEGER DEFAULT 0,\n          comments INTEGER DEFAULT 0,\n          post_type VARCHAR(50) DEFAULT 'task_completion',\n          metadata JSONB DEFAULT '{}'::jsonb,\n          created_at TIMESTAMPTZ DEFAULT NOW(),\n          updated_at TIMESTAMPTZ DEFAULT NOW()\n        );\n      `);\n      // Add foreign key constraint to tasks if tasks table exists and has id column\n      await client.query(`\n        DO $$\n        BEGIN\n          IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'tasks') THEN\n            IF EXISTS (\n              SELECT 1 FROM information_schema.columns \n              WHERE table_name = 'tasks' AND column_name = 'id'\n            ) THEN\n              IF NOT EXISTS (\n                SELECT 1 FROM information_schema.table_constraints \n                WHERE constraint_name = 'posts_task_id_fkey' AND table_name = 'posts'\n              ) THEN\n                ALTER TABLE posts ADD CONSTRAINT posts_task_id_fkey \n                  FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE SET NULL;\n              END IF;\n            END IF;\n          END IF;\n        END$$;\n      `);\n      // Create indexes only if columns exist (safe on re-run)\n      await client.query(`\n        DO $$\n        BEGIN\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='posts' AND column_name='author_id'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_posts_author_id ON posts (author_id);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='posts' AND column_name='task_id'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_posts_task_id ON posts (task_id);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='posts' AND column_name='created_at'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_posts_created_at ON posts (created_at DESC);\n          END IF;\n          IF EXISTS (\n            SELECT 1 FROM information_schema.columns \n            WHERE table_name='posts' AND column_name='post_type'\n          ) THEN\n            CREATE INDEX IF NOT EXISTS idx_posts_post_type ON posts (post_type);\n          END IF;\n        END$$;\n      `);\n    } else {\n      // eslint-disable-next-line no-console\n      console.log(\n        \"✅ Posts table exists with correct schema - skipping creation\",\n      );\n    }\n\n    // Ensure user_activities table - required by StatsController for real-time tracking\n    await client.query(`\n      CREATE TABLE IF NOT EXISTS user_activities (\n        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n        user_id UUID,\n        activity_type VARCHAR(50) NOT NULL,\n        activity_data JSONB,\n        ip_address VARCHAR(45),\n        user_agent TEXT,\n        created_at TIMESTAMPTZ DEFAULT NOW()\n      );\n    `);\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_user_activities_user ON user_activities (user_id);`,\n    );\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_user_activities_type ON user_activities (activity_type);`,\n    );\n    await client.query(\n      `CREATE INDEX IF NOT EXISTS idx_user_activities_created ON user_activities (created_at);`,\n    );\n\n    // Seed default donation categories if empty\n    const { rows: catCountRows } = await client.query(\n      \"SELECT COUNT(*)::int as count FROM donation_categories\",\n    );\n    const catCount = catCountRows?.[0]?.count ?? 0;\n    if (catCount === 0) {\n      const categories = [\n        {\n          slug: \"money\",\n          name_he: \"כסף\",\n          name_en: \"Money\",\n          icon: \"💰\",\n          color: \"#4CAF50\",\n          sort_order: 1,\n        },\n        {\n          slug: \"trump\",\n          name_he: \"טרמפים\",\n          name_en: \"Rides\",\n          icon: \"🚗\",\n          color: \"#2196F3\",\n          sort_order: 2,\n        },\n        {\n          slug: \"knowledge\",\n          name_he: \"ידע\",\n          name_en: \"Knowledge\",\n          icon: \"📚\",\n          color: \"#9C27B0\",\n          sort_order: 3,\n        },\n        {\n          slug: \"time\",\n          name_he: \"זמן\",\n          name_en: \"Time\",\n          icon: \"⏰\",\n          color: \"#FF9800\",\n          sort_order: 4,\n        },\n        {\n          slug: \"food\",\n          name_he: \"אוכל\",\n          name_en: \"Food\",\n          icon: \"🍞\",\n          color: \"#8BC34A\",\n          sort_order: 5,\n        },\n        {\n          slug: \"clothes\",\n          name_he: \"בגדים\",\n          name_en: \"Clothes\",\n          icon: \"👕\",\n          color: \"#03A9F4\",\n          sort_order: 6,\n        },\n        {\n          slug: \"books\",\n          name_he: \"ספרים\",\n          name_en: \"Books\",\n          icon: \"📖\",\n          color: \"#607D8B\",\n          sort_order: 7,\n        },\n        {\n          slug: \"furniture\",\n          name_he: \"רהיטים\",\n          name_en: \"Furniture\",\n          icon: \"🪑\",\n          color: \"#795548\",\n          sort_order: 8,\n        },\n        {\n          slug: \"medical\",\n          name_he: \"רפואה\",\n          name_en: \"Medical\",\n          icon: \"🏥\",\n          color: \"#F44336\",\n          sort_order: 9,\n        },\n        {\n          slug: \"animals\",\n          name_he: \"חיות\",\n          name_en: \"Animals\",\n          icon: \"🐾\",\n          color: \"#4CAF50\",\n          sort_order: 10,\n        },\n        {\n          slug: \"housing\",\n          name_he: \"דיור\",\n          name_en: \"Housing\",\n          icon: \"🏠\",\n          color: \"#FF5722\",\n          sort_order: 11,\n        },\n        {\n          slug: \"support\",\n          name_he: \"תמיכה\",\n          name_en: \"Support\",\n          icon: \"💝\",\n          color: \"#E91E63\",\n          sort_order: 12,\n        },\n        {\n          slug: \"education\",\n          name_he: \"חינוך\",\n          name_en: \"Education\",\n          icon: \"🎓\",\n          color: \"#3F51B5\",\n          sort_order: 13,\n        },\n        {\n          slug: \"environment\",\n          name_he: \"סביבה\",\n          name_en: \"Environment\",\n          icon: \"🌱\",\n          color: \"#4CAF50\",\n          sort_order: 14,\n        },\n        {\n          slug: \"technology\",\n          name_he: \"טכנולוגיה\",\n          name_en: \"Technology\",\n          icon: \"💻\",\n          color: \"#009688\",\n          sort_order: 15,\n        },\n      ];\n      for (const c of categories) {\n        await client.query(\n          `INSERT INTO donation_categories (slug, name_he, name_en, icon, color, sort_order)\n           VALUES ($1, $2, $3, $4, $5, $6)\n           ON CONFLICT (slug) DO UPDATE SET name_he=EXCLUDED.name_he, name_en=EXCLUDED.name_en, icon=EXCLUDED.icon, color=EXCLUDED.color, sort_order=EXCLUDED.sort_order, updated_at=NOW()`,\n          [c.slug, c.name_he, c.name_en, c.icon, c.color, c.sort_order],\n        );\n      }\n    }\n\n    // eslint-disable-next-line no-console\n    console.log(\"✅ Database initialized\");\n  } finally {\n    client.release();\n    await pool.end();\n  }\n}\n\nrun().catch((err) => {\n  // eslint-disable-next-line no-console\n  console.error(\"❌ init-db failed\", err);\n  process.exit(1);\n});\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/run-sql.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/sync-firebase-users.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":128,"column":31,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":128,"endColumn":34,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3918,3921],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3918,3921],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":241,"column":33,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":241,"endColumn":36,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[8255,8258],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[8255,8258],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":288,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":288,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10210,10213],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10210,10213],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Sync all Firebase Authentication users to user_profiles table\n// - Usage: Run once to sync existing users, then automatic sync handles new users\n// - Run: npm run sync:firebase-users\n\nimport * as admin from \"firebase-admin\";\nimport { Pool } from \"pg\";\nimport * as dotenv from \"dotenv\";\n\n// Load environment variables\ndotenv.config();\n\n// Initialize Firebase Admin SDK\n// You need to set FIREBASE_SERVICE_ACCOUNT_KEY environment variable\n// Or use GOOGLE_APPLICATION_CREDENTIALS pointing to service account JSON file\nif (!admin.apps.length) {\n  try {\n    // Try to initialize with service account key from environment\n    if (process.env.FIREBASE_SERVICE_ACCOUNT_KEY) {\n      const serviceAccount = JSON.parse(\n        process.env.FIREBASE_SERVICE_ACCOUNT_KEY,\n      );\n      admin.initializeApp({\n        credential: admin.credential.cert(serviceAccount),\n      });\n    } else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {\n      // Use service account file path\n      admin.initializeApp({\n        credential: admin.credential.applicationDefault(),\n      });\n    } else {\n      console.error(\n        \"❌ FIREBASE_SERVICE_ACCOUNT_KEY or GOOGLE_APPLICATION_CREDENTIALS must be set\",\n      );\n      process.exit(1);\n    }\n  } catch (error) {\n    console.error(\"❌ Failed to initialize Firebase Admin SDK:\", error);\n    process.exit(1);\n  }\n}\n\n// Initialize PostgreSQL connection\nconst pool = new Pool({\n  connectionString: process.env.DATABASE_URL || process.env.POSTGRES_URL,\n  ssl:\n    process.env.NODE_ENV === \"production\"\n      ? { rejectUnauthorized: false }\n      : false,\n});\n\ninterface FirebaseUser {\n  uid: string;\n  email?: string;\n  displayName?: string;\n  photoURL?: string;\n  emailVerified: boolean;\n  providerData?: Array<{\n    providerId: string;\n    uid?: string;\n    email?: string;\n    displayName?: string;\n    photoURL?: string;\n  }>;\n  metadata: {\n    creationTime: string;\n    lastSignInTime?: string;\n  };\n}\n\nasync function syncFirebaseUsers() {\n  const client = await pool.connect();\n  try {\n    await client.query(\"BEGIN\");\n\n    console.log(\"🔄 Starting Firebase users sync...\");\n\n    // Get all users from Firebase Authentication\n    let allUsers: FirebaseUser[] = [];\n    let nextPageToken: string | undefined;\n\n    do {\n      const listUsersResult = await admin.auth().listUsers(1000, nextPageToken);\n      allUsers = allUsers.concat(listUsersResult.users);\n      nextPageToken = listUsersResult.pageToken;\n      console.log(`📥 Fetched ${allUsers.length} users from Firebase...`);\n    } while (nextPageToken);\n\n    console.log(`✅ Total users in Firebase: ${allUsers.length}`);\n\n    let created = 0;\n    let updated = 0;\n    let skipped = 0;\n    let errors = 0;\n\n    for (const firebaseUser of allUsers) {\n      try {\n        // Skip users without email\n        if (!firebaseUser.email) {\n          console.log(`⚠️ Skipping user ${firebaseUser.uid} - no email`);\n          skipped++;\n          continue;\n        }\n\n        const normalizedEmail = firebaseUser.email.toLowerCase().trim();\n\n        // Extract Google ID from provider data if available\n        let googleId: string | null = null;\n        const googleProvider = firebaseUser.providerData?.find(\n          (p) => p.providerId === \"google.com\",\n        );\n        if (googleProvider?.uid) {\n          googleId = googleProvider.uid;\n        }\n\n        // Check if user already exists in user_profiles\n        const { rows: existingUsers } = await client.query(\n          `SELECT id, email, firebase_uid, google_id FROM user_profiles \n           WHERE firebase_uid = $1 OR LOWER(email) = LOWER($1) OR email = $2\n           LIMIT 1`,\n          [firebaseUser.uid, normalizedEmail],\n        );\n\n        if (existingUsers.length > 0) {\n          // User exists - update if needed\n          const existingUser = existingUsers[0];\n          const needsUpdate: string[] = [];\n          const updateValues: any[] = [];\n          let paramCount = 1;\n\n          // Check if firebase_uid needs to be set/updated\n          if (\n            !existingUser.firebase_uid ||\n            existingUser.firebase_uid !== firebaseUser.uid\n          ) {\n            needsUpdate.push(`firebase_uid = $${paramCount++}`);\n            updateValues.push(firebaseUser.uid);\n          }\n\n          // Check if google_id needs to be set/updated\n          if (\n            googleId &&\n            (!existingUser.google_id || existingUser.google_id !== googleId)\n          ) {\n            needsUpdate.push(`google_id = $${paramCount++}`);\n            updateValues.push(googleId);\n          }\n\n          // Update name if available and different\n          if (\n            firebaseUser.displayName &&\n            existingUser.name !== firebaseUser.displayName\n          ) {\n            needsUpdate.push(`name = $${paramCount++}`);\n            updateValues.push(firebaseUser.displayName);\n          }\n\n          // Update avatar if available and different\n          if (firebaseUser.photoURL) {\n            needsUpdate.push(`avatar_url = $${paramCount++}`);\n            updateValues.push(firebaseUser.photoURL);\n          }\n\n          // Update email_verified\n          if (firebaseUser.emailVerified !== undefined) {\n            needsUpdate.push(`email_verified = $${paramCount++}`);\n            updateValues.push(firebaseUser.emailVerified);\n          }\n\n          // Update last_active from lastSignInTime\n          if (firebaseUser.metadata.lastSignInTime) {\n            needsUpdate.push(`last_active = $${paramCount++}`);\n            updateValues.push(new Date(firebaseUser.metadata.lastSignInTime));\n          }\n\n          if (needsUpdate.length > 0) {\n            needsUpdate.push(`updated_at = NOW()`);\n            updateValues.push(existingUser.id);\n\n            await client.query(\n              `UPDATE user_profiles \n               SET ${needsUpdate.join(\", \")} \n               WHERE id = $${paramCount}`,\n              updateValues,\n            );\n            updated++;\n            console.log(\n              `✅ Updated user: ${normalizedEmail} (${firebaseUser.uid})`,\n            );\n          } else {\n            skipped++;\n            console.log(`⏭️  User already up to date: ${normalizedEmail}`);\n          }\n        } else {\n          // User doesn't exist - create new\n          const creationTime = firebaseUser.metadata.creationTime\n            ? new Date(firebaseUser.metadata.creationTime)\n            : new Date();\n          const lastSignInTime = firebaseUser.metadata.lastSignInTime\n            ? new Date(firebaseUser.metadata.lastSignInTime)\n            : creationTime;\n\n          try {\n            await client.query(\n              `INSERT INTO user_profiles (\n                firebase_uid, google_id, email, name, avatar_url, bio,\n                karma_points, join_date, is_active, last_active,\n                city, country, interests, roles, email_verified, settings\n              ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13::text[], $14::text[], $15, $16::jsonb)\n              RETURNING id`,\n              [\n                firebaseUser.uid, // firebase_uid\n                googleId, // google_id (can be null)\n                normalizedEmail, // email\n                firebaseUser.displayName ||\n                  normalizedEmail.split(\"@\")[0] ||\n                  \"User\", // name\n                firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\", // avatar_url\n                \"משתמש חדש בקארמה קומיוניטי\", // bio\n                0, // karma_points\n                creationTime, // join_date\n                true, // is_active\n                lastSignInTime, // last_active\n                \"ישראל\", // city\n                \"Israel\", // country\n                [], // interests\n                [\"user\"], // roles\n                firebaseUser.emailVerified || false, // email_verified\n                JSON.stringify({\n                  language: \"he\",\n                  dark_mode: false,\n                  notifications_enabled: true,\n                  privacy: \"public\",\n                }), // settings\n              ],\n            );\n            created++;\n            console.log(\n              `✨ Created user: ${normalizedEmail} (${firebaseUser.uid})`,\n            );\n          } catch (insertError: any) {\n            // If google_id column doesn't exist, try without it\n            if (\n              insertError.message &&\n              insertError.message.includes(\"google_id\")\n            ) {\n              await client.query(\n                `INSERT INTO user_profiles (\n                  firebase_uid, email, name, avatar_url, bio,\n                  karma_points, join_date, is_active, last_active,\n                  city, country, interests, roles, email_verified, settings\n                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12::text[], $13::text[], $14, $15::jsonb)\n                RETURNING id`,\n                [\n                  firebaseUser.uid, // firebase_uid\n                  normalizedEmail, // email\n                  firebaseUser.displayName ||\n                    normalizedEmail.split(\"@\")[0] ||\n                    \"User\", // name\n                  firebaseUser.photoURL || \"https://i.pravatar.cc/150?img=1\", // avatar_url\n                  \"משתמש חדש בקארמה קומיוניטי\", // bio\n                  0, // karma_points\n                  creationTime, // join_date\n                  true, // is_active\n                  lastSignInTime, // last_active\n                  \"ישראל\", // city\n                  \"Israel\", // country\n                  [], // interests\n                  [\"user\"], // roles\n                  firebaseUser.emailVerified || false, // email_verified\n                  JSON.stringify({\n                    language: \"he\",\n                    dark_mode: false,\n                    notifications_enabled: true,\n                    privacy: \"public\",\n                  }), // settings\n                ],\n              );\n              created++;\n              console.log(\n                `✨ Created user (without google_id): ${normalizedEmail} (${firebaseUser.uid})`,\n              );\n            } else {\n              throw insertError;\n            }\n          }\n        }\n      } catch (error: any) {\n        errors++;\n        console.error(\n          `❌ Error syncing user ${firebaseUser.uid}:`,\n          error.message,\n        );\n        // Continue with next user\n      }\n    }\n\n    await client.query(\"COMMIT\");\n\n    console.log(\"\\n📊 Sync Summary:\");\n    console.log(`   ✅ Created: ${created}`);\n    console.log(`   🔄 Updated: ${updated}`);\n    console.log(`   ⏭️  Skipped: ${skipped}`);\n    console.log(`   ❌ Errors: ${errors}`);\n    console.log(`   📈 Total processed: ${allUsers.length}`);\n    console.log(\"\\n✅ Firebase users sync completed!\");\n  } catch (error) {\n    await client.query(\"ROLLBACK\");\n    console.error(\"❌ Sync failed:\", error);\n    throw error;\n  } finally {\n    client.release();\n    await pool.end();\n  }\n}\n\n// Run sync\nsyncFirebaseUsers()\n  .then(() => {\n    console.log(\"✅ Script completed successfully\");\n    process.exit(0);\n  })\n  .catch((error) => {\n    console.error(\"❌ Script failed:\", error);\n    process.exit(1);\n  });\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/update-salary-seniority.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/verify-hierarchy-migration.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":66,"column":34,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":66,"endColumn":37,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[2059,2062],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[2059,2062],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Pool } from \"pg\";\nimport * as dotenv from \"dotenv\";\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\n// Load environment\nconst envFiles = [\".env.production\", \".env.development\", \".env\"];\nfor (const file of envFiles) {\n  const envPath = path.resolve(process.cwd(), file);\n  if (fs.existsSync(envPath)) {\n    dotenv.config({ path: envPath });\n    break;\n  }\n}\n\nasync function verifyMigration() {\n  const connectionString = process.env.DATABASE_URL;\n  if (!connectionString) {\n    throw new Error(\"DATABASE_URL environment variable is required\");\n  }\n  const pool = new Pool({ connectionString });\n  const client = await pool.connect();\n\n  try {\n    console.log(\"🔍 Verifying hierarchy migration...\\n\");\n\n    // Check if hierarchy_level column exists\n    const colCheck = await client.query(`\n      SELECT column_name \n      FROM information_schema.columns \n      WHERE table_name = 'user_profiles' \n        AND column_name = 'hierarchy_level'\n    `);\n    console.log(\"✅ hierarchy_level column exists:\", colCheck.rows.length > 0);\n\n    // Check root admin\n    const rootAdmin = await client.query(`\n      SELECT email, hierarchy_level, parent_manager_id \n      FROM user_profiles \n      WHERE email = 'karmacommunity2.0@gmail.com'\n    `);\n    if (rootAdmin.rows.length > 0) {\n      const admin = rootAdmin.rows[0];\n      console.log(\"\\n✅ Root admin (karmacommunity2.0@gmail.com):\");\n      console.log(\n        \"   - hierarchy_level:\",\n        admin.hierarchy_level,\n        admin.hierarchy_level === 0 ? \"✅\" : \"❌\",\n      );\n      console.log(\n        \"   - parent_manager_id:\",\n        admin.parent_manager_id,\n        admin.parent_manager_id === null ? \"✅\" : \"❌\",\n      );\n    } else {\n      console.log(\"⚠️ Root admin not found\");\n    }\n\n    // Check super admins\n    const superAdmins = await client.query(`\n      SELECT email, hierarchy_level, parent_manager_id \n      FROM user_profiles \n      WHERE email IN ('navesarussi@gmail.com', 'mahalalel100@gmail.com')\n    `);\n    console.log(\"\\n✅ Super admins:\");\n    superAdmins.rows.forEach((r: any) => {\n      console.log(`   - ${r.email}:`);\n      console.log(\n        \"     - hierarchy_level:\",\n        r.hierarchy_level,\n        r.hierarchy_level === 1 ? \"✅\" : \"❌\",\n      );\n      console.log(\n        \"     - has_parent:\",\n        r.parent_manager_id !== null ? \"✅\" : \"❌\",\n      );\n    });\n\n    // Check history table\n    const historyCheck = await client.query(`\n      SELECT COUNT(*) as count \n      FROM information_schema.tables \n      WHERE table_name = 'user_hierarchy_history'\n    `);\n    console.log(\"\\n✅ History table exists:\", historyCheck.rows[0].count > 0);\n\n    // Check trigger\n    const triggerCheck = await client.query(`\n      SELECT trigger_name \n      FROM information_schema.triggers \n      WHERE trigger_name = 'trigger_update_hierarchy_level'\n    `);\n    console.log(\"✅ Trigger exists:\", triggerCheck.rows.length > 0);\n\n    // Check function\n    const functionCheck = await client.query(`\n      SELECT routine_name \n      FROM information_schema.routines \n      WHERE routine_name = 'calculate_hierarchy_level'\n    `);\n    console.log(\"✅ Function exists:\", functionCheck.rows.length > 0);\n\n    console.log(\"\\n✅ Migration verification complete!\");\n  } catch (error) {\n    console.error(\"❌ Verification failed:\", error);\n    process.exit(1);\n  } finally {\n    client.release();\n    await pool.end();\n  }\n}\n\nverifyMigration().catch((err) => {\n  console.error(\"❌ Fatal error:\", err);\n  process.exit(1);\n});\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/verify-import.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":56,"column":37,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":56,"endColumn":40,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1521,1524],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1521,1524],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":65,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":65,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[1771,1774],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[1771,1774],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Client } from \"pg\";\nimport * as dotenv from \"dotenv\";\n\ndotenv.config();\n\nasync function verify() {\n  const connectionString = process.env.DATABASE_URL;\n  if (!connectionString) {\n    console.error(\"❌ DATABASE_URL missing\");\n    process.exit(1);\n  }\n\n  const client = new Client({ connectionString });\n\n  try {\n    await client.connect();\n\n    const tablesResult = await client.query(`\n            SELECT table_name \n            FROM information_schema.tables \n            WHERE table_schema = 'public' \n            AND table_type = 'BASE TABLE'\n            ORDER BY table_name\n        `);\n\n    console.log(\"📊 Database Statistics:\\n\");\n\n    let totalRows = 0;\n    for (const row of tablesResult.rows) {\n      const tableName = row.table_name;\n      const countResult = await client.query(\n        `SELECT COUNT(*) FROM \"${tableName}\"`,\n      );\n      const count = parseInt(countResult.rows[0].count);\n\n      if (count > 0) {\n        console.log(\n          `  ✓ ${tableName.padEnd(35, \" \")} ${count.toString().padStart(6, \" \")} rows`,\n        );\n        totalRows += count;\n      }\n    }\n\n    console.log(`\\n  Total: ${totalRows} rows across all tables\\n`);\n\n    // Check for anonymized emails\n    try {\n      const emailCheck = await client.query(`\n                SELECT email FROM user_profiles \n                WHERE email LIKE '%@dev.test' \n                LIMIT 3\n            `);\n\n      if (emailCheck.rows.length > 0) {\n        console.log(\"✅ Emails are anonymized:\");\n        emailCheck.rows.forEach((r: any) => console.log(`   - ${r.email}`));\n      } else {\n        console.log(\"⚠️  Warning: Emails may not be anonymized!\");\n      }\n    } catch {\n      // Table might not exist\n    }\n\n    console.log(\"\\n✅ Verification complete!\\n\");\n  } catch (error: any) {\n    console.error(\"❌ Verification failed:\", error.message);\n    process.exit(1);\n  } finally {\n    await client.end();\n  }\n}\n\nverify();\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/verify-notifications.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/scripts/verify-separation.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/services/admin-tables.service.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":20,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":20,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[603,606],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[603,606],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":27,"column":29,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":27,"endColumn":32,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[746,749],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[746,749],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":31,"column":24,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":31,"endColumn":27,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[810,813],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[810,813],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":35,"column":24,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":35,"endColumn":27,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[874,877],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[874,877],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":162,"column":14,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":162,"endColumn":17,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5403,5406],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5403,5406],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":163,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":163,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[5435,5438],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[5435,5438],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":224,"column":14,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":224,"endColumn":17,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7060,7063],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7060,7063],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":225,"column":26,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":225,"endColumn":29,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7092,7095],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7092,7095],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":226,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":226,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7118,7121],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7118,7121],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":227,"column":38,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":227,"endColumn":41,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[7162,7165],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[7162,7165],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":322,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":322,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[9820,9823],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[9820,9823],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":359,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":359,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[10837,10840],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[10837,10840],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":395,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":395,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[11856,11859],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[11856,11859],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":417,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":417,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[12524,12527],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[12524,12527],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":447,"column":23,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":447,"endColumn":26,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[13266,13269],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[13266,13269],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":514,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":514,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[15451,15454],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[15451,15454],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":537,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":537,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[15957,15960],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[15957,15960],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":551,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":551,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[16317,16320],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[16317,16320],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":572,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":572,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[17004,17007],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[17004,17007],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":612,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":612,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[18178,18181],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[18178,18181],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":662,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":662,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[19525,19528],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[19525,19528],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":684,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":684,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[20037,20040],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[20037,20040],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":22,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// File overview:\n// - Purpose: Service for Admin Dynamic Tables management\n// - Used by: AdminTablesController\n// - Provides: CRUD operations for tables, columns, and rows with validation\nimport { Inject, Injectable } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\n\nexport interface CreateColumnDto {\n  name: string;\n  data_type: \"text\" | \"number\" | \"date\";\n  is_required?: boolean;\n  display_order?: number;\n}\n\nexport interface CreateTableDto {\n  name: string;\n  description?: string;\n  columns: CreateColumnDto[];\n  metadata?: Record<string, any>;\n}\n\nexport interface UpdateTableDto {\n  name?: string;\n  description?: string;\n  columns?: CreateColumnDto[];\n  metadata?: Record<string, any>;\n}\n\nexport interface CreateRowDto {\n  data: Record<string, any>;\n}\n\nexport interface UpdateRowDto {\n  data: Record<string, any>;\n}\n\n@Injectable()\nexport class AdminTablesService {\n  constructor(@Inject(PG_POOL) private readonly pool: Pool) {}\n\n  /**\n   * Ensure admin tables exist, create if needed\n   */\n  private async ensureTables() {\n    try {\n      // Check if admin_tables exists\n      const checkTable = await this.pool.query(`\n        SELECT EXISTS (\n          SELECT FROM information_schema.tables \n          WHERE table_schema = 'public' \n          AND table_name = 'admin_tables'\n        );\n      `);\n\n      if (!checkTable.rows[0].exists) {\n        console.log(\"📋 Creating admin_tables tables...\");\n\n        // Create admin_tables\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS admin_tables (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            name VARCHAR(255) NOT NULL,\n            description TEXT,\n            created_by UUID,\n            metadata JSONB DEFAULT '{}'::jsonb,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          );\n        `);\n\n        // Create admin_table_columns\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS admin_table_columns (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            table_id UUID NOT NULL,\n            name VARCHAR(255) NOT NULL,\n            data_type VARCHAR(20) NOT NULL CHECK (data_type IN ('text', 'number', 'date')),\n            is_required BOOLEAN DEFAULT false,\n            display_order INTEGER DEFAULT 0,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            CONSTRAINT unique_table_column_name UNIQUE (table_id, name)\n          );\n        `);\n\n        // Create admin_table_rows\n        await this.pool.query(`\n          CREATE TABLE IF NOT EXISTS admin_table_rows (\n            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n            table_id UUID NOT NULL,\n            data JSONB NOT NULL DEFAULT '{}'::jsonb,\n            created_by UUID,\n            updated_by UUID,\n            created_at TIMESTAMPTZ DEFAULT NOW(),\n            updated_at TIMESTAMPTZ DEFAULT NOW()\n          );\n        `);\n\n        // Create indexes\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_tables_created_by ON admin_tables(created_by);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_tables_created_at ON admin_tables(created_at DESC);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_columns_table_id ON admin_table_columns(table_id);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_columns_display_order ON admin_table_columns(table_id, display_order);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_rows_table_id ON admin_table_rows(table_id);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_rows_created_by ON admin_table_rows(created_by);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_rows_created_at ON admin_table_rows(table_id, created_at DESC);\",\n        );\n        await this.pool.query(\n          \"CREATE INDEX IF NOT EXISTS idx_admin_table_rows_data_gin ON admin_table_rows USING GIN (data);\",\n        );\n\n        // Create triggers for updated_at\n        await this.pool.query(`\n          CREATE OR REPLACE FUNCTION update_updated_at_column()\n          RETURNS TRIGGER AS $$\n          BEGIN\n            NEW.updated_at = NOW();\n            RETURN NEW;\n          END;\n          $$ language 'plpgsql';\n        `);\n\n        await this.pool.query(`\n          DROP TRIGGER IF EXISTS update_admin_tables_updated_at ON admin_tables;\n          CREATE TRIGGER update_admin_tables_updated_at \n          BEFORE UPDATE ON admin_tables \n          FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n        `);\n\n        await this.pool.query(`\n          DROP TRIGGER IF EXISTS update_admin_table_rows_updated_at ON admin_table_rows;\n          CREATE TRIGGER update_admin_table_rows_updated_at \n          BEFORE UPDATE ON admin_table_rows \n          FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n        `);\n\n        console.log(\"✅ admin_tables tables created successfully\");\n      }\n    } catch (error) {\n      console.error(\"❌ Error ensuring admin_tables tables:\", error);\n      throw error;\n    }\n  }\n\n  /**\n   * Validate row data according to column definitions\n   */\n  private validateRowData(\n    columns: any[],\n    data: Record<string, any>,\n  ): { valid: boolean; error?: string } {\n    for (const column of columns) {\n      const value = data[column.name];\n\n      // Check required fields\n      if (\n        column.is_required &&\n        (value === undefined || value === null || value === \"\")\n      ) {\n        return { valid: false, error: `שדה חובה: ${column.name}` };\n      }\n\n      // Skip validation if value is empty and not required\n      if (value === undefined || value === null || value === \"\") {\n        continue;\n      }\n\n      // Validate data types\n      switch (column.data_type) {\n        case \"text\":\n          if (typeof value !== \"string\") {\n            return {\n              valid: false,\n              error: `שדה ${column.name} חייב להיות טקסט`,\n            };\n          }\n          break;\n        case \"number\":\n          if (typeof value !== \"number\" && isNaN(Number(value))) {\n            return {\n              valid: false,\n              error: `שדה ${column.name} חייב להיות מספר`,\n            };\n          }\n          break;\n        case \"date\": {\n          const dateValue = value instanceof Date ? value : new Date(value);\n          if (isNaN(dateValue.getTime())) {\n            return {\n              valid: false,\n              error: `שדה ${column.name} חייב להיות תאריך תקין`,\n            };\n          }\n          break;\n        }\n        default:\n          return {\n            valid: false,\n            error: `סוג נתון לא נתמך: ${column.data_type}`,\n          };\n      }\n    }\n\n    return { valid: true };\n  }\n\n  /**\n   * Normalize row data according to column data types\n   */\n  private normalizeRowData(\n    columns: any[],\n    data: Record<string, any>,\n  ): Record<string, any> {\n    const normalized: Record<string, any> = {};\n\n    for (const column of columns) {\n      const value = data[column.name];\n\n      if (value === undefined || value === null || value === \"\") {\n        if (!column.is_required) {\n          normalized[column.name] = null;\n        }\n        continue;\n      }\n\n      switch (column.data_type) {\n        case \"text\":\n          normalized[column.name] = String(value);\n          break;\n        case \"number\":\n          normalized[column.name] = Number(value);\n          break;\n        case \"date\": {\n          const dateValue = value instanceof Date ? value : new Date(value);\n          normalized[column.name] = dateValue.toISOString();\n          break;\n        }\n        default:\n          normalized[column.name] = value;\n      }\n    }\n\n    return normalized;\n  }\n\n  /**\n   * Create a new table with columns\n   */\n  async createTable(dto: CreateTableDto, userId: string) {\n    await this.ensureTables();\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Validate columns\n      if (!dto.columns || dto.columns.length === 0) {\n        throw new Error(\"חייב להגדיר לפחות עמודה אחת\");\n      }\n\n      // Check for duplicate column names\n      const columnNames = dto.columns.map((c) => c.name);\n      if (new Set(columnNames).size !== columnNames.length) {\n        throw new Error(\"לא ניתן להגדיר עמודות עם אותו שם\");\n      }\n\n      // Insert table\n      const tableResult = await client.query(\n        `INSERT INTO admin_tables (name, description, created_by, metadata)\n         VALUES ($1, $2, $3::UUID, $4::jsonb)\n         RETURNING *`,\n        [\n          dto.name,\n          dto.description || null,\n          userId,\n          JSON.stringify(dto.metadata || {}),\n        ],\n      );\n\n      const table = tableResult.rows[0];\n\n      // Insert columns\n      for (let i = 0; i < dto.columns.length; i++) {\n        const column = dto.columns[i];\n        await client.query(\n          `INSERT INTO admin_table_columns (table_id, name, data_type, is_required, display_order)\n           VALUES ($1::UUID, $2, $3, $4, $5)`,\n          [\n            table.id,\n            column.name,\n            column.data_type,\n            column.is_required || false,\n            column.display_order !== undefined ? column.display_order : i,\n          ],\n        );\n      }\n\n      // Fetch columns\n      const columnsResult = await client.query(\n        `SELECT * FROM admin_table_columns WHERE table_id = $1::UUID ORDER BY display_order, created_at`,\n        [table.id],\n      );\n\n      await client.query(\"COMMIT\");\n\n      return {\n        ...table,\n        columns: columnsResult.rows,\n      };\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      throw error;\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Get all tables with their columns\n   */\n  async getAllTables() {\n    await this.ensureTables();\n    try {\n      const tablesResult = await this.pool.query(\n        `SELECT * FROM admin_tables ORDER BY created_at DESC`,\n      );\n\n      const tables = tablesResult.rows;\n\n      // Fetch columns for each table\n      for (const table of tables) {\n        const columnsResult = await this.pool.query(\n          `SELECT * FROM admin_table_columns WHERE table_id = $1::UUID ORDER BY display_order, created_at`,\n          [table.id],\n        );\n        table.columns = columnsResult.rows;\n\n        // Get row count\n        const countResult = await this.pool.query(\n          `SELECT COUNT(*) as count FROM admin_table_rows WHERE table_id = $1::UUID`,\n          [table.id],\n        );\n        table.row_count = parseInt(countResult.rows[0].count);\n      }\n\n      return tables;\n    } catch (error: any) {\n      throw new Error(`שגיאה בטעינת טבלאות: ${error.message}`);\n    }\n  }\n\n  /**\n   * Get table by ID with columns and optionally rows\n   */\n  async getTableById(\n    id: string,\n    includeRows: boolean = false,\n    pagination?: { page: number; limit: number },\n  ) {\n    await this.ensureTables();\n    try {\n      const tableResult = await this.pool.query(\n        `SELECT * FROM admin_tables WHERE id = $1::UUID`,\n        [id],\n      );\n\n      if (tableResult.rows.length === 0) {\n        throw new Error(\"טבלה לא נמצאה\");\n      }\n\n      const table = tableResult.rows[0];\n\n      // Fetch columns\n      const columnsResult = await this.pool.query(\n        `SELECT * FROM admin_table_columns WHERE table_id = $1::UUID ORDER BY display_order, created_at`,\n        [id],\n      );\n      table.columns = columnsResult.rows;\n\n      // Fetch rows if requested\n      if (includeRows) {\n        let rowsQuery = `SELECT * FROM admin_table_rows WHERE table_id = $1::UUID ORDER BY created_at DESC`;\n        const params: any[] = [id];\n\n        if (pagination) {\n          rowsQuery += ` LIMIT $${params.length + 1} OFFSET $${params.length + 2}`;\n          params.push(\n            pagination.limit,\n            (pagination.page - 1) * pagination.limit,\n          );\n        }\n\n        const rowsResult = await this.pool.query(rowsQuery, params);\n        table.rows = rowsResult.rows;\n\n        // Get total count\n        const countResult = await this.pool.query(\n          `SELECT COUNT(*) as count FROM admin_table_rows WHERE table_id = $1::UUID`,\n          [id],\n        );\n        table.total_rows = parseInt(countResult.rows[0].count);\n      }\n\n      return table;\n    } catch (error: any) {\n      throw new Error(`שגיאה בטעינת טבלה: ${error.message}`);\n    }\n  }\n\n  /**\n   * Update table structure\n   */\n  async updateTable(id: string, dto: UpdateTableDto, _userId: string) {\n    const client = await this.pool.connect();\n    try {\n      await client.query(\"BEGIN\");\n\n      // Check if table exists\n      const tableCheck = await client.query(\n        `SELECT id FROM admin_tables WHERE id = $1::UUID`,\n        [id],\n      );\n\n      if (tableCheck.rows.length === 0) {\n        throw new Error(\"טבלה לא נמצאה\");\n      }\n\n      // Update table fields\n      if (\n        dto.name ||\n        dto.description !== undefined ||\n        dto.metadata !== undefined\n      ) {\n        const updates: string[] = [];\n        const params: any[] = [];\n        let paramIndex = 1;\n\n        if (dto.name) {\n          updates.push(`name = $${paramIndex++}`);\n          params.push(dto.name);\n        }\n        if (dto.description !== undefined) {\n          updates.push(`description = $${paramIndex++}`);\n          params.push(dto.description || null);\n        }\n        if (dto.metadata !== undefined) {\n          updates.push(`metadata = $${paramIndex++}::jsonb`);\n          params.push(JSON.stringify(dto.metadata));\n        }\n\n        if (updates.length > 0) {\n          params.push(id);\n          await client.query(\n            `UPDATE admin_tables SET ${updates.join(\", \")}, updated_at = NOW() WHERE id = $${paramIndex}::UUID`,\n            params,\n          );\n        }\n      }\n\n      // Update columns if provided\n      if (dto.columns) {\n        // Validate columns\n        if (dto.columns.length === 0) {\n          throw new Error(\"חייב להגדיר לפחות עמודה אחת\");\n        }\n\n        const columnNames = dto.columns.map((c) => c.name);\n        if (new Set(columnNames).size !== columnNames.length) {\n          throw new Error(\"לא ניתן להגדיר עמודות עם אותו שם\");\n        }\n\n        // Delete existing columns\n        await client.query(\n          `DELETE FROM admin_table_columns WHERE table_id = $1::UUID`,\n          [id],\n        );\n\n        // Insert new columns\n        for (let i = 0; i < dto.columns.length; i++) {\n          const column = dto.columns[i];\n          await client.query(\n            `INSERT INTO admin_table_columns (table_id, name, data_type, is_required, display_order)\n             VALUES ($1::UUID, $2, $3, $4, $5)`,\n            [\n              id,\n              column.name,\n              column.data_type,\n              column.is_required || false,\n              column.display_order !== undefined ? column.display_order : i,\n            ],\n          );\n        }\n\n        // Note: Existing rows are not automatically updated - their data might become invalid\n        // This is intentional - admins should be careful when changing table structure\n      }\n\n      await client.query(\"COMMIT\");\n\n      // Fetch updated table\n      return await this.getTableById(id, false);\n    } catch (error: any) {\n      await client.query(\"ROLLBACK\");\n      throw error;\n    } finally {\n      client.release();\n    }\n  }\n\n  /**\n   * Delete table (CASCADE will delete columns and rows)\n   */\n  async deleteTable(id: string) {\n    try {\n      const result = await this.pool.query(\n        `DELETE FROM admin_tables WHERE id = $1::UUID RETURNING id`,\n        [id],\n      );\n\n      if (result.rows.length === 0) {\n        throw new Error(\"טבלה לא נמצאה\");\n      }\n\n      return { success: true };\n    } catch (error: any) {\n      throw new Error(`שגיאה במחיקת טבלה: ${error.message}`);\n    }\n  }\n\n  /**\n   * Get table rows with pagination\n   */\n  async getTableRows(\n    tableId: string,\n    pagination?: { page: number; limit: number },\n  ) {\n    try {\n      let query = `SELECT * FROM admin_table_rows WHERE table_id = $1::UUID ORDER BY created_at DESC`;\n      const params: any[] = [tableId];\n\n      if (pagination) {\n        query += ` LIMIT $${params.length + 1} OFFSET $${params.length + 2}`;\n        params.push(pagination.limit, (pagination.page - 1) * pagination.limit);\n      }\n\n      const rowsResult = await this.pool.query(query, params);\n\n      // Get total count\n      const countResult = await this.pool.query(\n        `SELECT COUNT(*) as count FROM admin_table_rows WHERE table_id = $1::UUID`,\n        [tableId],\n      );\n\n      return {\n        rows: rowsResult.rows,\n        total: parseInt(countResult.rows[0].count),\n        page: pagination?.page || 1,\n        limit: pagination?.limit || rowsResult.rows.length,\n      };\n    } catch (error: any) {\n      throw new Error(`שגיאה בטעינת רשומות: ${error.message}`);\n    }\n  }\n\n  /**\n   * Create a new row\n   */\n  async createRow(tableId: string, dto: CreateRowDto, userId: string) {\n    try {\n      // Get table columns\n      const columnsResult = await this.pool.query(\n        `SELECT * FROM admin_table_columns WHERE table_id = $1::UUID ORDER BY display_order`,\n        [tableId],\n      );\n\n      if (columnsResult.rows.length === 0) {\n        throw new Error(\"טבלה לא נמצאה או שאין בה עמודות\");\n      }\n\n      const columns = columnsResult.rows;\n\n      // Validate row data\n      const validation = this.validateRowData(columns, dto.data);\n      if (!validation.valid) {\n        throw new Error(validation.error || \"נתונים לא תקינים\");\n      }\n\n      // Normalize row data\n      const normalizedData = this.normalizeRowData(columns, dto.data);\n\n      // Insert row\n      const result = await this.pool.query(\n        `INSERT INTO admin_table_rows (table_id, data, created_by)\n         VALUES ($1::UUID, $2::jsonb, $3::UUID)\n         RETURNING *`,\n        [tableId, JSON.stringify(normalizedData), userId],\n      );\n\n      return result.rows[0];\n    } catch (error: any) {\n      throw new Error(`שגיאה ביצירת רשומה: ${error.message}`);\n    }\n  }\n\n  /**\n   * Update a row\n   */\n  async updateRow(\n    tableId: string,\n    rowId: string,\n    dto: UpdateRowDto,\n    userId: string,\n  ) {\n    try {\n      // Get table columns\n      const columnsResult = await this.pool.query(\n        `SELECT * FROM admin_table_columns WHERE table_id = $1::UUID ORDER BY display_order`,\n        [tableId],\n      );\n\n      if (columnsResult.rows.length === 0) {\n        throw new Error(\"טבלה לא נמצאה או שאין בה עמודות\");\n      }\n\n      const columns = columnsResult.rows;\n\n      // Validate row data\n      const validation = this.validateRowData(columns, dto.data);\n      if (!validation.valid) {\n        throw new Error(validation.error || \"נתונים לא תקינים\");\n      }\n\n      // Normalize row data\n      const normalizedData = this.normalizeRowData(columns, dto.data);\n\n      // Update row\n      const result = await this.pool.query(\n        `UPDATE admin_table_rows \n         SET data = $1::jsonb, updated_by = $2::UUID, updated_at = NOW()\n         WHERE id = $3::UUID AND table_id = $4::UUID\n         RETURNING *`,\n        [JSON.stringify(normalizedData), userId, rowId, tableId],\n      );\n\n      if (result.rows.length === 0) {\n        throw new Error(\"רשומה לא נמצאה\");\n      }\n\n      return result.rows[0];\n    } catch (error: any) {\n      throw new Error(`שגיאה בעדכון רשומה: ${error.message}`);\n    }\n  }\n\n  /**\n   * Delete a row\n   */\n  async deleteRow(tableId: string, rowId: string) {\n    try {\n      const result = await this.pool.query(\n        `DELETE FROM admin_table_rows \n         WHERE id = $1::UUID AND table_id = $2::UUID \n         RETURNING id`,\n        [rowId, tableId],\n      );\n\n      if (result.rows.length === 0) {\n        throw new Error(\"רשומה לא נמצאה\");\n      }\n\n      return { success: true };\n    } catch (error: any) {\n      throw new Error(`שגיאה במחיקת רשומה: ${error.message}`);\n    }\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/services/services.module.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/services/user-resolution.service.ts","messages":[{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":113,"column":21,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":113,"endColumn":24,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[3394,3397],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[3394,3397],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]},{"ruleId":"@typescript-eslint/no-explicit-any","severity":1,"message":"Unexpected any. Specify a different type.","line":167,"column":19,"nodeType":"TSAnyKeyword","messageId":"unexpectedAny","endLine":167,"endColumn":22,"suggestions":[{"messageId":"suggestUnknown","fix":{"range":[4910,4913],"text":"unknown"},"desc":"Use `unknown` instead, this will force you to explicitly, and safely assert the type is correct."},{"messageId":"suggestNever","fix":{"range":[4910,4913],"text":"never"},"desc":"Use `never` instead, this is useful when instantiating generic type parameters that you don't need to know the type of."}]}],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import { Injectable, Inject, NotFoundException } from \"@nestjs/common\";\nimport { Pool } from \"pg\";\nimport { PG_POOL } from \"../database/database.module\";\nimport { RedisCacheService } from \"../redis/redis-cache.service\";\n\n/**\n * UserResolutionService\n *\n * Unified service for resolving user identifiers to UUIDs.\n * Replaces 3 different implementations across the codebase:\n * - chat.controller.ts resolveUserId (throws on not found, has caching)\n * - tasks.controller.ts resolveUserIdToUUID (returns null on not found)\n * - users.controller.ts resolveUserId endpoint (creates user - REMOVED!)\n *\n * This service provides:\n * - Consistent behavior across all controllers\n * - Centralized caching\n * - Support for multiple identifier types (UUID, email, firebase_uid, google_id)\n * - Configurable error handling\n */\n@Injectable()\nexport class UserResolutionService {\n  private readonly CACHE_TTL = 10 * 60; // 10 minutes\n\n  constructor(\n    @Inject(PG_POOL) private readonly pool: Pool,\n    private readonly redisCache: RedisCacheService,\n  ) {}\n\n  /**\n   * Resolve user identifier to UUID\n   *\n   * @param identifier - Can be UUID, email, firebase_uid, or google_id\n   * @param options - Resolution options\n   * @returns User UUID or null (if throwOnNotFound is false)\n   * @throws NotFoundException if user not found and throwOnNotFound is true\n   */\n  async resolveUserId(\n    identifier: string,\n    options: {\n      throwOnNotFound?: boolean;\n      cacheResult?: boolean;\n      logError?: boolean;\n    } = {},\n  ): Promise<string | null> {\n    // Default options\n    const {\n      throwOnNotFound = true,\n      cacheResult = true,\n      logError = true,\n    } = options;\n\n    if (!identifier) {\n      if (throwOnNotFound) {\n        throw new NotFoundException(\"User identifier is required\");\n      }\n      return null;\n    }\n\n    // Normalize identifier (lowercase for emails)\n    const normalizedId = identifier.includes(\"@\")\n      ? identifier.trim().toLowerCase()\n      : identifier.trim();\n\n    // Check if already a valid UUID\n    const uuidRegex =\n      /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n\n    // Check cache first\n    if (cacheResult) {\n      const cacheKey = `user_id_resolve_${normalizedId}`;\n      const cached = await this.redisCache.get<string>(cacheKey);\n      if (cached && uuidRegex.test(cached)) {\n        return cached;\n      }\n    }\n\n    try {\n      // Query database - support UUID, email, firebase_uid ONLY\n      // We do NOT use google_id - only our own UUID (user_profiles.id)\n      const { rows } = await this.pool.query(\n        `\n        SELECT id FROM user_profiles\n        WHERE id::text = $1\n           OR LOWER(email) = LOWER($1)\n           OR firebase_uid = $1\n        LIMIT 1\n      `,\n        [normalizedId],\n      );\n\n      if (rows.length === 0) {\n        if (throwOnNotFound) {\n          if (logError) {\n            console.warn(\n              `User not found for identifier: ${normalizedId.substring(0, 10)}...`,\n            );\n          }\n          throw new NotFoundException(`User not found: ${normalizedId}`);\n        }\n        return null;\n      }\n\n      const uuid = rows[0].id;\n\n      // Cache the result\n      if (cacheResult) {\n        const cacheKey = `user_id_resolve_${normalizedId}`;\n        await this.redisCache.set(cacheKey, uuid, this.CACHE_TTL);\n      }\n\n      return uuid;\n    } catch (error: any) {\n      // If it's a NotFoundException we threw, re-throw it\n      if (error instanceof NotFoundException) {\n        throw error;\n      }\n\n      // Handle database errors\n      if (logError) {\n        console.error(\"UserResolutionService - Database error:\", error);\n      }\n\n      if (throwOnNotFound) {\n        throw new NotFoundException(`Failed to resolve user: ${error.message}`);\n      }\n      return null;\n    }\n  }\n\n  /**\n   * Resolve multiple user identifiers to UUIDs in a single operation\n   * More efficient than calling resolveUserId multiple times\n   *\n   * @param identifiers - Array of user identifiers\n   * @param options - Resolution options\n   * @returns Array of UUIDs in the same order as input (null for not found if throwOnNotFound is false)\n   */\n  async resolveUserIds(\n    identifiers: string[],\n    options: {\n      throwOnNotFound?: boolean;\n      cacheResult?: boolean;\n    } = {},\n  ): Promise<(string | null)[]> {\n    return Promise.all(\n      identifiers.map((id) => this.resolveUserId(id, options)),\n    );\n  }\n\n  /**\n   * Link external IDs (firebase_uid) to an existing user\n   * Should only be called from authenticated endpoints\n   *\n   * NOTE: We only link firebase_uid. We do NOT use google_id.\n   *\n   * @param userId - UUID of the user to update\n   * @param externalIds - External IDs to link\n   */\n  async linkExternalIds(\n    userId: string,\n    externalIds: {\n      firebase_uid?: string;\n    },\n  ): Promise<void> {\n    const updates: string[] = [];\n    const values: any[] = [];\n    let paramCount = 1;\n\n    if (externalIds.firebase_uid) {\n      updates.push(`firebase_uid = $${paramCount++}`);\n      values.push(externalIds.firebase_uid);\n    }\n\n    if (updates.length === 0) {\n      return; // Nothing to update\n    }\n\n    values.push(userId);\n\n    try {\n      await this.pool.query(\n        `\n        UPDATE user_profiles\n        SET ${updates.join(\", \")}, updated_at = NOW()\n        WHERE id = $${paramCount}\n      `,\n        values,\n      );\n\n      // Clear cache for this user\n      await this.redisCache.delete(`user_profile_${userId}`);\n      if (externalIds.firebase_uid) {\n        await this.redisCache.delete(\n          `user_id_resolve_${externalIds.firebase_uid}`,\n        );\n      }\n    } catch (error) {\n      console.error(\n        \"UserResolutionService - Failed to link external IDs:\",\n        error,\n      );\n      throw error;\n    }\n  }\n\n  /**\n   * Check if a given string is a valid UUID format\n   */\n  isValidUUID(uuid: string): boolean {\n    const uuidRegex =\n      /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;\n    return uuidRegex.test(uuid);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"/Users/navesarussi/KC/DEV/KC-MVP-server/src/types/global.d.ts","messages":[],"suppressedMessages":[],"errorCount":0,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":[]}]
